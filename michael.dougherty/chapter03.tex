\setcounter{page}{159}
%\setcounter{chapter}{3}
\chapter{Continuity and Limits of Functions\label{LimitsAndContinuityChapter}} 
The concept of continuity is an important first step in the analysis
leading to differential and integral calculus.  Continuity is
also an important analytical tool in its own right, with significant
practical applications.  Fortunately the main theorems
are intuitive, though their proofs are often challenging.
We will prove most of the continuity theorems stated here.
The remaining theorems we will state and apply without proof, since
they are intuitive---and quite useful---but require at least 
a junior level real analysis or topology course's background material
to be proved easily.

%The chapter begins with the definition of continuity at a point,
%with a library of functions known to be continuous then constructed.  
%Next this is dissected into left and right continuity at a point.
%Then naturally comes a discussion of types of {\it discontinuities. }
%The climax of the chapter is the discussion of continuity on
%intervals, both closed and open, and  the ramifications with 
%practical applications.

Related to continuity is the concept of limit, which
is vital for calculus since it puts calculus
on the same rigorous footing as other mathematical disciplines
such as algebra and geometry.  In our more modern times
it has further conceptual appeal, as it is often only 
possible to approximate
the solution to some problem, even though our method of 
approximation may be arbitrarily close to the actual solution
if given enough computing time.  In mathematics we employ
limits in cases where
our analysis (algebraic, geometric, etc.) breaks down at 
exactly the point we are interested in, and so we can only
``approach'' that point as closely as we would like.  We
then employ this tool called limit to break through the
analytic barrier at that point.  All of our subsequent
calculus flows from this ability which limits provide.
%Initially we will only discuss finite limits of 
%functions at a point on the real line.  However, the concept
%of limit can be generalized in many ways.  We will discuss
%infinite limits, limits at infinity, and finally limits
%of sequences.  We will have much use for all of these
%as we proceed.


Many examples of continuity and limit in action
seem straightforward  enough, but
there are numerous cases and technicalities to 
watch for. 
% It 
%goes without mentioning that the student will be required to
%put forth the effort needed to wade through the technicalities,
%and to practice as many problems as possible to achieve
%precision and fluency in these topics. 
%
 Both topics will be employed
explicitly in several places in the text, and will
be implicitly present in nearly all discussions of 
calculus topics.









\newpage

\section{Definition of Continuity at a Point\label{FirstContinuitySection}}

The function $f(x)$ is
continuous at $x=a$ if we can guarantee $f(x)$ to be close
to the value $f(a)$ by restricting $x$ to be close to $a$.
To rephrase, we say $f(x)$ is continuous at $x=a$ if,
given any positive tolerance $\epsilon>0$ we choose for $f(x)$
as an approximation for $f(a)$,
we can then find a positive tolerance $\delta>0$ for $x$ as an
approximation for $a$ so that $\delta$-tolerance in $x$
allows at most $\epsilon$ tolerance in $f(x)$.
The definition below is very technical, but through reflection,
and after exposure to the subsequent examples,
one sees  that this  is  exactly what is required. 
\begin{definition} The function $f(x)$ is continuous at the point $x=a$ 
if and only if\,\footnotemark
%
%%%%%%%%%%%%%%%%% FOOTNOTE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext{Many texts abbreviate statements like (\ref{continuity})
as follows:
$$(\forall\epsilon>0)(\exists\delta>0)\left(
|x-a|<\delta\longrightarrow |f(x)-f(a)|<\epsilon\right),$$
the idea being that the $\forall x$ is understood
when we make an unquantified (in $x$) statement like 
$|x-a|<\delta\longrightarrow|f(x)-f(a)|<\epsilon.$
For a similar example in English, consider the following
two statements, usually deemed equivalent:
\begin{quote}All Americans have trouble speaking English.

If $X$ is an American, then $X$ has trouble speaking English.
\end{quote}
Most see both as false exactly when
we can find one American (counterexample) who has no such trouble. 
In other words, the second statement is as much 
a   ``blanket''
statement as the first, and is in fact
equivalent to the first.
We leave the $\forall x$ in (\ref{continuity}) for
precision and to aid in negating the statement, using rules from
Section~\ref{QuantifiersAndSets}.
}
%%%%%%%%%%%%%%%%%%%%%%%%% END FOOTNOTE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{equation}
(\forall\epsilon>0)(\exists\delta>0)(\forall x)\left(
|x-a|<\delta\longrightarrow |f(x)-f(a)|<\epsilon\right).\label{continuity}
\end{equation}

\end{definition}
%\footnotetext{
%From now on we will almost exclusively use ``$\implies$"
%instead of ``$\longrightarrow"$ for implication, to avoid
%confusion  with the arrow later used in the limit notation ``$x\to a$."}
This is sometimes called the epsilon-delta ($\epsilon$-$\delta$)
definition of continuity.  
 Now let us examine the various parts of the definition.
\begin{eqnarray}
|f(x)-f(a)|&<&\epsilon\label{epspart}\\
|x-a|&<&\delta\label{delpart}\\
(\forall x)
\left(\vphantom{}|x-a|<\delta\right.&
\longrightarrow&
\left.\vphantom{}|f(x)-f(a)|<\epsilon\right)\label{d-e cont impl}\\
(\forall\epsilon>0)&&(\exists\delta>0)\label{forallepsexistsdel}\end{eqnarray}
\begin{description}
\item (\ref{epspart}): $f(x)$ will be {\it within} $\epsilon$ of
$f(a)$.  In other words, the function at $x$ will be near in value to
the value of the function at $a$. How near?  Less than
$\epsilon$ distance away.
\item (\ref{delpart}): $x$ is within $\delta$ of $a$.
(Otherwise the implication holds true vacuously, but that case is useless.
What is important is what occurs when $|x-a|<\delta$.)
\item (\ref{d-e cont impl}): The condition that $x$ be within
$\delta$ of $a$  forces $f(x)$ to be within $\epsilon$ of $f(a)$.
In other words, allowing $x$ to stray by less than $\delta$ from $a$
keeps $f(x)$ within $\epsilon$ of $f(a)$.  By controlling 
$x$ by allowing it a tolerance of less than $\delta$, we control
$f(x)$ to have a tolerance of less than $\epsilon$.
\item (\ref{forallepsexistsdel}): Whatever positive value of $\epsilon$  
we choose, we can find a $\delta$ which satisfies
(\ref{d-e cont impl}).  In particular, {\it no matter how small}
we choose $\epsilon>0$ , we can find a positive $\delta$ so that
(\ref{d-e cont impl}) is satisfied.  
\end{description}
For a final rephrasing, we
have the statement that  
{\bf we can control the tolerance $\epsilon$ in the output $f(x)$ as
much as we would like, so long as $\epsilon>0$, by controlling
the tolerance $\delta$ (which must also be positive\footnotemark)
in the input variable $x$.}  
\footnotetext{Notice that $\delta=0$ 
would be  worthless for
several reasons. First, the implication would be
vacuously true and all functions
would be continuous everywhere, since $|x-a|<0$ would never be satisfied.
Second, when---in reality---do we ever have a tolerance of zero
in a measurement?  Finally, as we explore the implications of 
continuity, we will see that having positive $\delta$ is 
central to the spirit of what follows, particularly with
regards to limits.}


\begin{figure}
\begin{center}
\begin{pspicture}(0,0)(5,5)
\psline{<->}(1,0)(1,5)
\psline{<->}(0,1)(4,1)
\pscurve(1.5,1.5)(2.5,3)(2.8,3.3)(3.5,2)(4,3.5)
\pscircle[fillstyle=solid,fillcolor=black](2.5,3){.08}
\psline(2.5,.8)(2.5,1.2)
\rput(2.5,.5){$a$}
\rput(2.3,1){(}
\rput(2.7,1){)}
\rput(.92,3.5){\begin{rotate}{-90}(\end{rotate}}
\rput(.2,3.4){\scriptsize $f(a)+\epsilon$}
\rput(1.1,2.5){\begin{rotate}{90}(\end{rotate}}
\rput(.2,2.6){\scriptsize $f(a)-\epsilon$}
\psline(.8,3)(1.2,3)
\rput(.2,3){$f(a)$}
\psline[linestyle=dotted,dotsep=0.01](2.5,1)(2.5,3)(1,3)
\psline[linestyle=dotted,dotsep=.05](2.33,1)(2.33,2.8)(1,2.8)
\psline[linestyle=dotted,dotsep=.05](2.67,1)(2.67,3.25)(1,3.25)

\rput(1.9,0.75){\scriptsize $a-\delta$}
\rput(3.1,0.75){\scriptsize $a+\delta$}

\end{pspicture}
\qquad
\begin{pspicture}(0,0)(5,5)
\psline{<->}(1,0)(1,5)
\psline{<->}(0,1)(4,1)
\pscurve(1.5,1.5)(2,2)(2.5,3)
\pscurve(2.5,4)(3.5,3.8)(4,3.5)
\pscircle[fillstyle=solid,fillcolor=white](2.5,4){.07}
\pscircle[fillstyle=solid,fillcolor=black](2.5,3){.07}
\psline(2.5,.8)(2.5,1.2)
\rput(2.5,.5){$a$}
\rput(2.35,1){(}
%
%
%
%
\rput(2.65,1){)}
\rput(.92,3.5){\begin{rotate}{-90}(\end{rotate}}
\rput(.2,3.4){\scriptsize $f(a)+\epsilon$}
\rput(1.1,2.5){\begin{rotate}{90}(\end{rotate}}
\rput(.2,2.6){\scriptsize $f(a)-\epsilon$}
\psline(.8,3)(1.2,3)
\rput(.2,3){$f(a)$}
\psline[linestyle=dotted,dotsep=0.01](2.5,1)(2.5,3)(1,3)
\psline[linestyle=dotted,dotsep=.05](2.38,1)(2.38,2.7)(1,2.7)
\psline[linestyle=dotted,dotsep=.05](2.62,1)(2.62,3.97)(1,3.97)

\rput(1.9,0.75){\scriptsize $a-\delta$}
\rput(3.1,0.75){\scriptsize $a+\delta$}

\end{pspicture}


\end{center}

\caption{The first graph shows a function continuous at $x=a$,
illustrating that we can force $f(x)$ to be within any
fixed $\epsilon>0$ of $f(a)$ by keeping $x$ to within 
some  $\delta>0$
(depending upon the $\epsilon$) of $a$.  On the other hand,
in the second graph we see an $\epsilon>0$ for which no
$\delta>0$-tolerance in $x$ can force $f(x)$ to be within
$\epsilon$-tolerance of $f(a)$, and so $f(x)$ is not continuous at $x=a$.
}
\label{ContinuityDefinitionFigure}
\end{figure}





\bex Show that the function $\ds{f(x)=5x-9}$ is
continuous at the point $x=2$. 

\underline{\bf Solution}:  
First we notice that $f(2)=1$, so we are trying to show 
the truth of the statement
$$(\forall\epsilon>0)(\exists\delta>0)(\forall x)\left(
|x-2|<\delta\longrightarrow|f(x)-1|<\epsilon\right).$$
{\rm We insert here
the following, which will be the general strategy for all such proofs.

\begin{center}\underline{\large Strategy for Writing $\epsilon$-$\delta$
Proofs}\end{center}

\begin{enumerate}
\item Use the statement $|f(x)-f(a)|<\epsilon$ to see how
it can be controlled by $|x-a|$, in particular if $|x-a|$
is a factor of $|f(x)-f(a)|$.
\item If necessary, assume {\it a priori\footnotemark}
%%%%%%%%%%%%%%% FOOTNOTE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext{Presumptive; before observations.  We make the
assumption not based on observation, but to focus our
search for $\delta$.  We will find that
a legitimate $\delta$ is still available even with the
restriction.  In fact, if the limit definition holds for a value
of $\delta>0$, it holds for any smaller, positive value $\delta$, so this
is not a fatal restriction at all.  %See Exercise ???}
}
%%%%%%%%%%%%%%% END FOOTNOTE  %%%%%%%%%%%%%%%%%%%%%%%%%%%
 that $\delta$ is
smaller than some fixed positive number to control the other
factors contained in $|f(x)-f(a)|$.
\item Find $\delta$ as a function of $\epsilon$, i.e.,
\begin{equation}
\delta=\delta(\epsilon)\end{equation}
with domain $(0,\infty)$ and range contained in the positive reals,
and so that the analysis indicates that choice of $\delta$ satisfies
the definition (\ref{continuity}).
\item Verify that (\ref{continuity}) holds with this choice of $\delta$
to complete the proof. 
\end{enumerate}
The first three steps are analysis, or ``scratch-work" to determine
the form of $\delta$.  The final step is the actual proof, though
elements of it are often contained in the analysis/scratch-work.  
Let us apply this strategy to the problem at hand.}

\qquad\underline{Scratch-work}:  We 
want $|f(x)-f(a)|<\epsilon$ to follow from
our choice of $\delta$.  We work backwards from that statement,
with $f(x)=5x-9$, $a=2$, and $f(a)=f(2)=1$. 
$$\begin{array}{crcl}&|f(x)-f(a)|&<&\epsilon\qquad\text{(what we need)}\\
\bimplies&|f(x)-1|&<&\epsilon\\
\bimplies&|5x-9-1|&<&\epsilon\\
\bimplies&|5x-10|&<&\epsilon\\
\bimplies&5|x-2|&<&\epsilon\\
\bimplies&|x-2|&<&\frac15\epsilon\qquad\text{(how to get it).}\end{array} 
$$
We can see from this that, if we take $\delta=\frac15\epsilon$,
then $\delta>0$ (since $\epsilon>0$ is assumed), and the bottom
could be written $|x-2|<\delta$.  Then the implication could be read
from that statement upwards to get $|f(x)-1|<\epsilon$.
We summarize this in the proof.

\begin{proof} For any $\epsilon>0$ choose $\delta=\frac15\epsilon$.
Then $\delta>0$ exists and satisfies 
\begin{align*}|x-2|<\delta
\implies&|f(x)-f(2)|=|(5x-9)-1|\\ 
&=|5x-10|=\underbrace{5|x-2|<5\delta}_{
\text{since }|x-2|<\delta}=
5\cdot\frac15\epsilon=\epsilon,\mathrm{\ q.e.d.}
\end{align*} 
\end{proof}\eex
Note that the final line of the proof does imply that
$|f(x)-f(2)|<\epsilon$, with intermediate calculations, some of which
one may wish to omit with practice. 


\bex Show that $f(x)=2x+3$ is continuous at $x=-5$.

\qquad \underline{Scratch-work}: Here $a=-5$ and $f(a)=f(-5)=-7$.
Hence we wish to find $\delta>0$ so that
$$|x-(-5)|<\delta\implies|f(x)-(-7)|<\epsilon,$$
i.e.,
$$|x+5|<\delta\implies|f(x)+7|<\epsilon.$$

Again we work backwards from the
conclusion we wish to justify.
$$\begin{array}{crcl}&|f(x)+7|&<&\epsilon\\
\bimplies&|2x+3+7|&<&\epsilon\\
\bimplies&|2x+10|&< &\epsilon\\
\bimplies&2|x+5|&<&\epsilon\\
\bimplies&|x+5|&<&\frac12\epsilon.\end{array}$$ 
This time we take $\delta=\frac12\epsilon$, and write the proof.

\begin{proof} For $\epsilon>0$, set $\delta=\frac12\epsilon$.  Then
$\delta>0$ exists and satisfies 
$$
|x+5|<\delta\implies|f(x)+7|=|2x+3+7|=|2x+10|
=2\underbrace{|x+5|}_{<\delta}<2\delta=2\cdot\frac{\epsilon}2=\epsilon,
\mathrm{\ q.e.d.}
$$
\end{proof}
\eex
Continuity for these first degree polynomials is a rather routine
proof at any $x=a$.  For completeness we include one more.

\bex Show that $f(x)=9-4x$ is continuous at $x=2$.

\qquad\underline{Scratch-work}: Here $a=2$, $f(a)=f(2)=1$.
Now we must be a little more
careful, and will make use of the fact that $|a\cdot b|=|a|\cdot|b|$. 
$$\begin{array}{crcl}&|f(x)-1|&<&\epsilon\\
\bimplies&|9-4x-1|&<&\epsilon\\
\bimplies&|-4x+8|&<&\epsilon\\
\bimplies&|(-4)(x-2)|&<&\epsilon\\
\bimplies&4|x-2|&<&\epsilon\\
\bimplies&|x-2|&<&\frac14\epsilon.\end{array}$$

\begin{proof} For $\epsilon>0$, choose $\delta=\frac14\epsilon$.
Then $\delta>0$ (exists) and
\begin{align*}
|x-2|<\delta\implies|f(x)-1|&=|9-4x-1|=|-4x+8|\\
&=|(-4)(x-2)|=4|x-2|<4\delta=4\cdot\frac{\epsilon}4=\epsilon,
\mathrm{\ q.e.d.}\end{align*}
\end{proof}
\eex

The function which represents a line is the easiest to confirm
continuity at every point.  If $f(x)=mx+b$, where $m\ne0$, it is
clear from the geometric meaning of slope $m$ 
that a variation (absolute value of
``rise'') of less than $\epsilon$ in height $f(x)$
can be achieved by allowing a variation (absolute value of ``run'') 
of less than
$\frac1{|m|}\epsilon$ in $x$.  Thus $\delta=\frac1{|m|}\epsilon$
is the largest $\delta$ which satisfies the definition of
continuity for such a function $f(x)$. (See again
our three ``linear'' examples above, and compare their slopes
with our choices of $\delta$.)

%%%%%%%%%%%PLACE LINE GRAPHIC HERE%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bex Show that $f(x)=x^2$ is continuous at $x=0$.

\qquad\underline{Scratch-work}: Here $a=0$ and $f(a)=f(0)=0$.
We therefore want to choose $\delta>0$ such that
\begin{align*}|x-0|<\delta&\implies|f(x)-0|<\epsilon, \quad\text{i.e.,}\\
|x|<\delta&\implies |x|^2<\epsilon.\end{align*}
Again we begin with the inequality we would like to result, and see
how we might get it.
$$|x|^2<\epsilon\iff|x|<\sqrt{\epsilon}.$$
Here we do have $\iff$ because we are dealing with only positive 
quantities (recall that $\sqrt\cdot$ is an increasing function
on $[0,\infty)$).
Thus we have a good choice for $\delta$, namely $\delta=\sqrt{\epsilon}$.

\begin{proof}
For $\epsilon>0$, set $\delta=\sqrt\epsilon$.  Then $\delta>0$ exists
and satisfies
$$|x-0|<\delta\implies
|f(x)-f(0)|=|x^2|=|x|^2<\delta^2=\left(\sqrt{\epsilon}\right)^2=\epsilon,
\quad\text{q.e.d.}$$
\end{proof}\label{x^2contat0}\eex
It should be clear that we could easily modify this example to show
that $f(x)=x^n$ is continuous at $x=0$ for
$n\in \mathbb{N}$.  From there it is not hard to show
$f(x)=x^{m/n}$ is also continuous at $x=0$, as long as $n$ is odd
and $m,n\in\mathbb{Z}$.\footnote{%%
%%% FOOTNOTE
It is false if $n$ is even, assuming $m/n$ is a reduced fraction.
The trouble there is that $x^{m/n}$ is undefined for $x<0$, so the
second part of $(|x-0|<\delta)\longrightarrow(|f(x)-f(0)|<\epsilon)$
is false for such values of $x$.%
%%% END FOOTNOTE
} %
Once we 
stray from $x=0$, we begin to have more difficulties, as
illustrated in the next example. 






\bex Show that $f(x)=x^2$ is continuous at $x=4$.

\underline{Scratch-work}: This has a complication that the previous 
problem did not.  Let us first attempt to proceed as in the
Example \ref{x^2contat0}.  Here $a=4$ and $f(a)=16$. 
We therefore want to choose $\delta>0$ such that
$$|x-4|<\delta\implies|f(x)-16|<\epsilon.$$
Working backwards as before we get
\begin{alignat*}{2}
&&|f(x)-16|&<\epsilon\\
&\iff\qquad&|x^2-16|&<\epsilon\\
&\iff\qquad&|x+4||x-4|&<\epsilon. 
\end{alignat*} 
We would like to be able to divide both sides by $|x+4|$, except
that {\bf it is not a constant}.  Here Step 2 in our 
strategy comes into
play.  We will control the $|x+4|$ term by assuming
that $\delta\le1$.  Then\footnotemark
\footnotetext{Here we chose $\delta\le1$, but we could have 
chosen any positive number for the maximum we allow $\delta$ to
be.  We just need to restrict $\delta$ (though keeping it positive)
to control the other factors of $|f(x)-16|$}
$$ (|x-4|<\delta)\wedge(\delta\le1)
\implies|x-4|<1\implies-1<x-4<1\implies3<x<5.$$
Now we add $4$ to this inequality to get
$$7<x+4<9.$$
With $x+4$ between $7$ and $9$, its absolute size is strictly
bounded by the number with the largest absolute value, $9$, i.e.,
$$|x+4|<9.$$
Continuing the scratch-work, we would get
$$|f(x)-16|=|x+4||x-4|<9|x-4|,$$
and now this looks similar to the earlier examples.  To achieve
$|f(x)-16|<\epsilon$ it would be sufficient to have $9|x-4|<\epsilon$,
which is to say $|x-4|<\frac19\epsilon$.  

Picking $\delta=\frac19\epsilon$ {\bf is not quite enough}, since we 
assumed $\delta\le1$ (to get our estimate $|x+4|<9$), and
this would be false if $\epsilon>9$.  To cover both
these requirements for $\delta$ for every given $\epsilon$
(as the definition requires),  we choose $\delta=\min\left\{
1,\frac19\epsilon\right\}$.
Now we write the proof.

\begin{proof} For $\epsilon>0$, choose $\delta=
\min\left\{1,\frac19\epsilon\right\}$.  Then $\delta>0$ 
exists and satisfies 
$$|x-4|<\delta\implies
|f(x)-16|=|x+4||x-4|<9|x-4|<9\delta\le9\cdot\frac19\epsilon=\epsilon,
\mathrm{\ q.e.d.}$$
\end{proof}
\eex 
Notice that in our proof 
the requirement $\delta\le1$ (implying $|x+4|<9$)
was used first, and then we used 
the fact that $\delta\le\frac19\epsilon$.  Although there are other
choices we could have made, the obvious possibilities
would still have required $\delta$ to have been a similar type of  minimum. 

\newpage
\bex Show that $\ds{f(x)=\frac1x}$ is continuous at $x=5$.
\label{ReciprocalContinuityExample}

\underline{Scratch-work}: Here $a=5$ and $f(a)=f(5)=\frac15$.
Again we work backwards:
\begin{alignat*}{2}
&&\left|f(x)-\frac15\right|&<\epsilon\\
&\iff&\left|\frac1x-\frac15\right|&<\epsilon\\
&\iff&\left|\frac{5-x}{5x}\right|&<\epsilon\\
&\iff&\frac15\cdot\frac1{|x|}\cdot|x-5|&<\epsilon.
\end{alignat*}
As before, the $|x-5|$ will be controlled by $\delta$,
but we need to also use $\delta$ to control the factor
$\frac1{|x|}$.  Again we will assume {\it a priori}
that $\delta\le1$.
$$|x-5|<\delta\implies|x-5|<1\iff -1<x-5<1
\iff 4<x<6\iff 4<|x|<6.$$
With these bounds on $|x|$, we also get bounds on $\frac1{|x|}$:
$$|x-5|<1\implies4<|x|<6\iff\frac16<\frac1{|x|}<\frac14.$$
With all these assumptions, then, we have (continuing from before)
$$\left|f(x)-\frac15\right|=\frac15\cdot\frac1{|x|}\cdot|x-5|<
\underbrace{\frac15\cdot\frac14|x-5|}_{<\frac1{20}\delta}.$$
This is less than $\epsilon$
if $\delta$ is no bigger than $20\epsilon$.  Now the 
analysis above also assumed $\delta\le 1$, so
we take
$$\delta=\min\left\{1,20\epsilon\right\}.$$
Now we state the proof.

\begin{proof} For $\epsilon>0$, choose
 $\delta=\min\left\{1,20\epsilon\right\}.$
Then $\delta>0$ exists and satisfies
\begin{align*}|x-5|<\delta\implies
|f(x)-f(5)|&=\left|\frac1x-\frac15\right|=
\left|\frac{5-x}{5x}\right|\\
&=\frac15\cdot\frac1{|x|}\cdot|x-5|
<\frac15\cdot\frac14\cdot\delta\le\frac{1}{20}\cdot20\epsilon
=\epsilon, \qquad\text{q.e.d.}
\end{align*}
\end{proof}
\eex
We should note here that if we had chosen $a=0.5$, then
we could not use $1$ as the upper bound for $\delta$,
since the function is undefined at a point
within $1$ of $0.5$ (namely at $x=0$).  For such an
$a$ we should instead assume {\it a priori} that
$\delta<0.25$, or a similar number to be sure
to avoid any problems with the definition of the function.

\newpage
\bex Show that $f(x)=x^4$ is continuous at $x=-2$.

\underline{Scratch-work}: Here $a=-2$ and $f(a)=16$.
Again we will attempt to work backwards.
\begin{alignat*}{2}
&&|f(x)-f(-2)|&<\epsilon\\
&\iff&|x^4-16|&<\epsilon\\
&\iff&|x^2+4|\cdot|x-2|\cdot|x+2|&<\epsilon.\end{alignat*}
Now our ``$|x-a|$'', namely $|x+2|$ 
is controlled by $\delta$, so we need
to control the other two factors.  Again let us assume
that $\delta\le1$. Then
$$|x+2|<\delta\implies |x+2|<1\iff
-1<x+2<1\iff -3<x<-1.$$
Note for later reference that $|x|<3$.

For the $|x-2|$ term we can subtract $2$ from the above
to get $-5<x-2<-3$, giving $|x-2|<5$.\footnotemark%
\hphantom{. }For the $|x^2+4|$ term, we have $x^2+4>0$, so 
$$|x^2+4|=x^2+4=|x|^2+4<(3)^2+4=13.$$
(Note that this was because $|x|<3$.)
So far we have
$$\delta\le1\implies
|f(x)-f(-2)|=(x^2+4)|x-2|\cdot|x+2|
\underbrace{<13\cdot5\cdot\delta}_{\text{want} <\epsilon}.$$
Taking $\delta=\min\left\{\frac{\epsilon}{65},1\right\}$
should give us a proof.

\begin{proof}
Let $\epsilon>0$ and choose 
$\delta=\min\left\{\frac{\epsilon}{65},1\right\}$.
Then $\delta>0$ and
\begin{align*}
|x-(-2)|<\delta\implies
|f(x)-f(-2)|&=|x^4-16|=(x^2+4)|x-2|\cdot|x+2|\\
&=(x^2+4)|x-2|\cdot|x-(-2)|\\
&<13\cdot 5\cdot\delta\\
&\le26\cdot\frac{\epsilon}{65}=\epsilon,\qquad\text{q.e.d.}
\end{align*}
\end{proof}\eex
Note that ultimately the above equalities and inequalities
do yield $|f(x)-f(-2)|<\epsilon$.
\footnotetext{We could also use the triangle inequality
to get $|x-2|\le|x|+|-2|<3+2=5$.  This happens to give the same bound,
but in more complicated cases that might not happen.  Either bound would
then work.  For an engineering application, one would likely prefer
whatever gives the larger $\delta$, which indicates less
sensitivity to tolerance in $x$ to achieve $\epsilon$ tolerance in
$f(x)$.}











\newpage
\begin{center}
\underline{\Large{\bf Exercises\footnotemark}}\end{center}
\bigskip
\footnotetext{%%%% 
%%%% FOOTNOTE
In all fairness, it should be pointed out to the reader that
some of the exercises here are likely to be quite difficult,
particularly for beginning calculus students. This is because
the proofs are very involved and use a large variety of methods.
Furthermore, reading the proofs of the examples is very different
from producing one's own proofs from scratch.

With these exercises, students are thus advised to adopt the 
following general approach:
\begin{enumerate}[(a)]
\item attempt as many problems as possible,
looking back on earlier examples for ideas; 
\item move on to 
the rest of the text even if few problems are completed 
on the first attempt; and
\item revisit this section and its problems from time to time
to attempt complete proofs for the results which were not  
finished previously.  
\end{enumerate}
With further calculus experience, the ideas and techniques should
become clearer, just as the inner workings of an automobile
likely make more sense---and seem more important---as one 
gains experience from actually driving.
%%%% END FOOTNOTE
}



\setlength{\columnsep}{1cm}
\begin{multicols}{2}
\begin{enumerate}
\item Show that $f(x)=9x-11$ is continuous at $x=2$.
\item Show that $f(x)=6-2x$ is continuous at $x=-8$.
\item Show that if $m\ne 0$, then $f(x)=mx+b$ is continuous at every $x=a$.
\item Show that $f(x)=5x^2-3$ is continuous at $x=2$.
\item Show that $f(x)=\frac1{x^2}$ is continuous at $x=5$.
\item Show that $f(x)=b $ (i.e., a line with slope zero)\label{HWConstAreCont}
is continuous at every point. (\underline{Hint}:
show any $\delta>0$ will work for the definition.)
\item Show that $f(x)=x^3$ is continuous at $x=1$.
\item Show that $f(x)=\sqrt{x}$ is continuous at $x=9$.
\item Show that $f(x)=\sqrt{x}$ is continuous at
any $a>0$.
\item Show that $f(x)=\frac1x$ is continuous at any
$a\ne 0$. (Letting $\delta\le1$ as in Example~\ref{ReciprocalContinuityExample}
works fine until $0<|a|\le1$.  For this more general case
desired here, one approach is to assume 
a priori that $\delta\le\frac12|a|$,
so that 
\begin{multline*}
|x-a|<\delta\implies |x-a|<\frac12|a|\\ \implies |x|>\frac12|a|
\implies\frac1{|x|}<\frac2{|a|}.\end{multline*}
There is some detail to showing the second implication.
From this a $\delta$ can be chosen, using some minimum of
two values, for each $\epsilon>0$.)
\label{ReciprocalContinuityHomework}
\item Consider $f(x)=\sqrt[3]{x}$.
\begin{enumerate}[(a)]
\item Show that $f(x)$ is continuous at $x=0$.
\item Show that $f(x)$ is continuous at $x=8$.
\item Show that $f(x)$ is continuous at $a$ for any $a>0$.
\item Show that $f(x)$ is continuous at any $a\ne0$.
\end{enumerate}
Conclude from a--d that $f(x)$ is continuous for all $x\in\Re$.
\item\label{ContinuityOfRadicalsHomework} 
Recall that $x^n-a^n=(x-a)(x^{n-1}+ax^{n-2}+a^2x^{n-3}
+\cdots+a^{n-1})$.  Use this to show that
$f(x)=\sqrt[n]{x}$ is continuous for all $x>0$ if $n\in\mathbb{N}$ is even,
and continuous for all $x\in\Re$ if $n\in\mathbb{N}$ is odd.
(For the latter you should do the case $x=0$ separately.)
Notice why the even case does not allow $x=0$ or $x<0$.
\underline{Hint}: the triangle inequality is needed, as 
is the fact that $\ds{\sqrt[n]{\left|x_1\right|}
<\sqrt[n]{\left|x_2\right|}}$ if $|x_1|<|x_2|$. 
\end{enumerate}

\end{multicols}








\newpage
\section[Continuity Theorems]%
{Continuity Theorems\label{ContinuityTheoremsSection}}
Though fundamental and technically important, using 
the $\epsilon$-$\delta$ definition to 
locate where a function is continuous is an unwieldy
approach.  Fortunately there are many very general theorems
which allow us to see  where a function is continuous
by simple inspection.  The theorems below are of
great use, collectively and individually,  for doing just that.
Here we list and prove these theorems, and later in
the section we will show how to make use of them.
The proofs are interesting but not crucial for most of
what we do.  We include them here for completeness.
The reader is advised to first concentrate on the theorems.


\begin{theorem}Suppose that $f(x)$ and $g(x)$
are continuous at $x=a$.  Then so is 
$f(x)+g(x)$.
\end{theorem}

\begin{proof}

We are beginning under the assumption that
$f(x)$ and $g(x)$ are continuous at $x=a$, i.e., 
\begin{align*}
&(\forall \epsilon_1>0)(\exists \delta_1>0)(\forall x)(|x-a|<\delta_1
  \longrightarrow|f(x)-f(a)|<\epsilon_1),\\
&(\forall \epsilon_2>0)(\exists \delta_2>0)(\forall x)(|x-a|<\delta_2
  \longrightarrow|g(x)-g(a)|<\epsilon_2).\end{align*}
Define $h(x)=f(x)+g(x)$. 
We want to show that
$h(x)$ is also continuous at $x=a$.
For a given $\epsilon>0$, set $\epsilon_1=\epsilon_2=
{\epsilon}/2$.  Next find corresponding $\delta_1,
\delta_2$ satisfying the definition of continuity
for $f$ and $g$ at $x=a$, respectively.
Finally,  pick $\delta=\min\{\delta_1,\delta_2\}.$
Recalling the triangle inequality, $|a+b|\le|a|+|b|$, we have
\begin{multline*}
|x-a|<\delta\implies
|h(x)-h(a)|=|f(x)+g(x)-f(a)-g(a)|\\
=|f(x)-f(a)+g(x)-g(a)|\le|f(x)-f(a)|+|g(x)-g(a)|\\
<\epsilon_1+\epsilon_2=\frac{\epsilon}2+\frac{\epsilon}2=\epsilon,
\qquad\text{q.e.d.}\end{multline*}
\end{proof}
It is not difficult to see that this can be extended
to include sums of more functions.  The next theorem's
proof is less difficult, and is left as an exercise:

\begin{theorem}If $f(x)$ is continuous at $x=a$, then
so is $Cf(x)$ for any constant $C$.
\label{MultiplicativeConstantsPreserveContinuity}\end{theorem}
The next theorem is the most difficult of these to prove,
but will also be one of the most useful in practice.

\begin{theorem}
\label{ProductOfContinuousFunctionsIsContinuous}Suppose that $f(x)$ and $g(x)$ are continuous
at $x=a$.  Then so is $f(x)g(x)$.
\end{theorem}

\begin{proof}
Now choose $\epsilon>0$ for the product $h(x)=f(x)g(x)$.
Now we carefully construct a $\delta>0$ so that
$$|x-a|<\delta\implies|h(x)-h(a)|=|f(x)g(x)-f(a)g(a)|<\epsilon.$$

As before we are assuming that 
\begin{align}
&(\forall \epsilon_1>0)(\exists \delta_1>0)(\forall x)(|x-a|<\delta_1
  \longrightarrow|f(x)-f(a)|<\epsilon_1),\label{ContinuityOfF}\\
&(\forall \epsilon_2>0)(\exists \delta_2>0)(\forall x)(|x-a|<\delta_2
  \longrightarrow|g(x)-g(a)|<\epsilon_2).\label{ContinuityOfG}\end{align}
First we note that what we need to control is $|f(x)g(x)-f(a)g(a)|$,
which can be expanded and then bounded  using the triangle 
inequality as follows:
\begin{align*}&|f(x)g(x)-f(a)g(a)|\\
&\quad=\frac12|(f(x)-f(a))(g(x)+g(a))+(f(x)+f(a))(g(x)-g(a))|\\
&\quad\le\frac12|(f(x)-f(a))(g(x)+g(a))|+\frac12|(f(x)+f(a))(g(x)-g(a))|\\
&\quad=\frac12|f(x)-f(a)|\cdot|g(x)+g(a)|+\frac12|f(x)+f(a)|\cdot|g(x)-g(a)|.
\end{align*}
It is enough that the final line in the above be less than $\epsilon$.

We will choose $\epsilon_1,\epsilon_2$ based on the choice of $\epsilon$.
Let us first assume {\it a priori} that any $\epsilon_1,\epsilon_2\le1$
and so with $|x-a|<\min\{\delta_1,\delta_2\}$ we get
by the triangle inequality
\begin{align}
|f(x)-f(a)|<1&\implies|f(x)|=|f(a)+(f(x)-f(a))|<|f(a)|+1,\label{LNeeded}\\
|g(x)-g(a)|<1&\implies|g(x)|=|g(a)+(g(x)-g(a))|<|g(a)|+1.\label{MNeeded}
\end{align}
Now define $L$ and $M$ as follow:
\begin{align}L&=|f(a)|+1>0,\label{L}\\ M&=|g(a)|+1>0.\label{M}\end{align}
From (\ref{LNeeded}), (\ref{MNeeded}) and (\ref{L}), (\ref{M}) we get
$|x-a|<\min\left\{\delta_1,\delta_1\right\}\Longrightarrow$
\begin{alignat}{2}
|f(x)|&<L+1,&\qquad |f(a)|&<L,\label{L+1,L}\\
|g(x)|&<M+1,&|g(a)|&<M.\label{M+1,M}\end{alignat}
Now we prove the statement of the continuity of $f(x)g(x)$ at $x=a$.
For any $\epsilon>0$ define
\begin{alignat}{2}
\epsilon_1&=\min\left\{1,\ \epsilon,\ \frac{\epsilon}{2M+1}\right\}
    &&=\min\left\{1,\ \frac{\epsilon}{2M+1}\right\}\label{epsilon1},\\
\epsilon_2&=\min\left\{1,\ \epsilon,\ \frac{\epsilon}{2L+1}\right\}
    &&=\min\left\{1,\ \frac{\epsilon}{2L+1}\right\},
    \label{epsilon2}\end{alignat}
and the respective $\delta_1$, $\delta_2$ from these
$\epsilon_1,\epsilon_2$ as appear in the continuity conditions
on $f(x)$ and $g(x)$ at $x=a$, namely (\ref{ContinuityOfF})
and (\ref{ContinuityOfG}). Note that we used the fact
that $\epsilon=\epsilon/1<\epsilon/(2M+1)$, and similarly
$\epsilon<\epsilon/(2L+1)$,
in (\ref{epsilon1}) and  (\ref{epsilon2}) respectively.
Finally, choose $\delta=\min\{\delta_1,\delta_2\}.$
Then
\begin{align*}
&|x-a|<\delta\implies\\
&\quad|f(x)g(x)-f(a)g(a)|\\
&\quad\le\frac12|f(x)-f(a)|\cdot|g(x)+g(a)|
+\frac12|f(x)+f(a)|\cdot|g(x)-g(a)|\\
&\quad
<\frac12\epsilon_1\cdot(|g(x)|+|g(a)|)+\frac12\epsilon_2\cdot(|f(x)|+|f(a)|)\\
&\quad\le
\frac12\epsilon_1(2M+1)+\frac12\epsilon_2(2M+1)\\
&\quad\le
\frac12\cdot\frac{\epsilon}{2M+1}\cdot(2M+1)+\frac12\cdot\frac{\epsilon}{2L+1}
\cdot(2L+1)\\
&\quad=\frac{\epsilon}2+\frac{\epsilon}2=\epsilon,\qquad\text{q.e.d.}
\end{align*}
\end{proof}
The above proof is more difficult than most in this text, and requires
careful examination.  In it lies a general method for controlling
$|f(x)g(x)-f(a)g(a)|$ by controlling $|x-a|$ which is worth
tracing.  In particular we used the identity
$$f(x)g(x)-f(a)g(a)=\frac12(f(x)-f(a))(g(x)+g(a))
+\frac12(f(x)+f(a))(g(x)-g(a)).$$
All three continuity theorems so far can be
described intuitively as saying, respectively
(for functions continuous at $x=a$):
{\bf\begin{itemize}
\item a sum of functions which are continuous at $a$ 
will also be continuous at $a$;
\item a constant multiple of a function which is continuous
at $a$ will also be continuous at $a$;
\item a product of functions which are continuous at $a$
will also be continuous at $a$.
\end{itemize}}
Rephrased, if we can control how far functions stray from their
values at $x=a$---by controlling how far $x$ strays from $a$---then
we can control how far their sums, products, and constant multiples
of the functions stray from their respective values at $x=a$ as
well. 
With repeated applications of
the above three theorems, we then get the following:

\begin{theorem}Polynomial functions are continuous at every $a\in\Re$.
\label{PolynomialsContinuousEverywhere}\end{theorem}
Hence the functions $f(x)=x^2+1$, $g(x)=55x^{39}+101x-10,000,000$,
and $h(x)=(9-23x)^{15}$ are all continuous.  Certainly this 
theorem gives a welcome relief from trying to prove 
these functions are continuous using $\epsilon$-$\delta$.
The proof is really quite simple (and may even sound
a bit flippant).

\begin{proof}
Any polynomial can be written
$$f(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots+a_1x+a_0.$$
Now each $x^k$ can be written as a product of $k$ factors
of the continuous function $g(x)=x$, so the $x^k$ are all continuous
for every $x=a$, 
as are constant multiples of these, i.e., the $a_kx^k$ terms.
Of course $h(x)=a_0$ is a constant function and is therefore
continuous (see Exercise~\ref{HWConstAreCont}, page~\pageref{HWConstAreCont}), 
so a polynomial is just the sum of continuous
functions, and is therefore continuous.
\end{proof}

The next theorem is also very useful, and deals with
compositions of functions.
Compared with, say
Theorem~\ref{ProductOfContinuousFunctionsIsContinuous},
this is surprisingly simple to prove.

\begin{theorem}
Suppose that $f(x)$ is continuous at $x=L=g(a)$,
and that $g(x)$ is continuous at $x=a$.  Then
$f(g(x))$ is continuous at $x=a$.
\label{CompositionOfContinuousFunctionsIsContinuous}\end{theorem}
Put concisely, the composition of continuous functions is continuous.

\begin{proof}
Let $\epsilon>0$.  We need to construct a $\delta>0$
such that
$$|x-a|<\delta\implies|f(g(x))-f(g(a))|<\epsilon.$$
By our continuity assumptions, we know that
\begin{align*}
&(\forall\epsilon_1>0)(\exists\delta_1>0)(\forall x)(|x-L|<\delta_1
  \longrightarrow|f(x)-f(L)|<\epsilon_1),\\
&(\forall\epsilon_2>0)(\exists\delta_2>0)(\forall x)(|x-a|<\delta_2
  \longrightarrow|g(x)-g(a)|<\epsilon_2).\end{align*}
So for this $\epsilon$, choose $\epsilon_1=\epsilon$,
which gives a $\delta_1>0$ so that
$$|x-L|<\delta_1\implies|f(x)-f(L)|<\epsilon.$$
Next set $\epsilon_2=\delta_1>0$. This gives a $\delta_2>0$
so that 
$$|x-a|<\delta_2\implies|g(x)-g(a)|<\epsilon_2=\delta_1.$$
Finally, let $\delta=\delta_2$, corresponding to $\epsilon_2$
in the continuity requirement for $g$. This gives
\begin{align*}
|x-a|<\delta&\iff|x-a|<\delta_2\\
&\implies|g(x)-g(a)|<\epsilon_2\\
&\iff |g(x)-L|<\delta_1\\
&\implies |f(g(x))-f(L)|<\epsilon_1\\
&\iff |f(g(x))-f(g(a))|<\epsilon,\qquad\text{q.e.d.}
\end{align*}
\end{proof} 
Intuitively, if $g(x)$ is changing continuously at $x=a$,
and $f$ changes continuously at $g(a)$, it seems
reasonable that $f(g(x))$ should change continuously
at $x=a$.  Of course now we have a proof of this fact.

For an important corollary, we first recall from 
Exercise~\ref{ReciprocalContinuityHomework}, 
page~\pageref{ReciprocalContinuityHomework} that
\begin{equation}
f(x)=\frac1{x}\qquad\text{is continuous for all }a\ne0.
\label{1/xContinuousExceptAtZero}\end{equation}
Now suppose that $g(x)$ is continuous at $x=a$, and
that $g(a)\ne0$.  Then (\ref{1/xContinuousExceptAtZero})
and the previous theorem
(Theorem~\ref{CompositionOfContinuousFunctionsIsContinuous} above)
with $f(x)=\frac1x$
give $f(g(x))=1/g(x)$ continuous at $x=a$. This is worth 
mentioning as a theorem:
\begin{theorem}
\begin{equation}
(g(x)\text{ continuous at }x=a)\wedge
(g(a)\ne 0)\implies\frac{1}{g(x)}\text{ continuous at }x=a.
\end{equation}
\end{theorem}
For arbitrary functions $f(x)$ and $g(x)$ which are continuous at
$x=a$, if $g(a)\ne 0$ we can 
always write ${\frac{f(x)}{g(x)}=f(x)\cdot\frac1{g(x)}}$, 
a product of two functions now known to be  continuous
at $x=a$ so we get another theorem:
\begin{theorem}
If $f(x)$ and $g(x)$ are continuous at $x=a$, and
$g(a)\ne 0$, then $f(x)/g(x)$ is also continuous at $x=a$.
\end{theorem}
This gives us a quick result on rational functions:
\begin{theorem}
If $\ds{f(x)=\frac{p(x)}{q(x)}}$, where $p$ and $q$ are
polynomials, then $f(x)$ is continuous at every
$a\in\Re$  except where $q(a)=0$,
at which points $f(x)$ is undefined and therefore
discontinuous.\end{theorem}
In other words, {\it rational functions are continuous where defined. }
(The proofs of both of these are contained in the discussion above.)
Though we have already used the next,  rather obvious
definition we include it here for completeness.

\begin{definition}If $f(x)$ is is not continuous at some point
$c$, then $f(x)$ is called {\bf discontinuous} at $x=c$, and
$c$ is called a {\bf point of discontinuity} of $f(x)$.
\end{definition}

It is sometimes easier to list those points at which a function is 
discontinuous  than the set of points at which it
is continuous.  Of course continuity at a point, and
discontinuity at a point, are negations of each other.
\bex Find where the function $\ds{f(x)=\frac{3x-5}{x^2-1}}$
is continuous.

\underline{Solution: }

As a rational function, $f(x)$ is continuous
{\bf except} where $x^2-1=0$, i.e., except where $x^2=1$, i.e., except
where $x=-1,1$.  We can effectively describe where $f(x)$ is continuous
in the following ways (all of which are equivalent):
\begin{description}
\item[a.] $f(x)$ is continuous except at $x=-1,1$;
\item[b.] $f(x)$ is continuous for $x\in(-\infty,-1)
\cup(-1,1)\cup(1,\infty)$;
\item[c.] $f(x)$ is continuous for all $x\ne\pm1$.
\end{description}\eex

It is important that we not simplify $f(x)$ in any way
before describing where it is continuous.  For instance,
consider the following:
\bex Find where $\ds{f(x)=\frac{x^2-25}{x-5}}$ is continuous.

\underline{Solution:} 

Clearly $f(x)$ is not defined at $x=5$, and therefore
cannot possibly be continuous there. (The definition
of continuity includes $f(a)$ in a way requiring that
$f(a)$ be defined.)  Simplifying is
desirable, but we must be sure to notice that $x=5$
is not in the domain.  What we can write, of course, is
$$f(x)=\frac{x^2-25}{x-5}=\frac{(x+5)(x-5)}{x-5}
=x+5,\qquad x\ne5.$$
(Note that the cancellation step indeed required that $x-5\ne0$,
because there we would be dividing numerator and denominator by
zero---not a valid arithmetic operation---at $x=5$ 
when we canceled the $x-5$ factors).
Such a function is defined and continuous for 
$x\in(-\infty,5)\cup(5,\infty)$.  \eex

The proof of the next theorem was the subject
of Exercise~\ref{ContinuityOfRadicalsHomework}, 
page~\pageref{ContinuityOfRadicalsHomework}.

\begin{theorem}
Suppose that $\ds{f(x)=\sqrt[n]{x}=x^{1/n}}$, with 
$n\in\mathbb{N}$. 
\begin{description}
\item[i.] If $n$ is odd, then $f(x)$ is continuous at each $x\in\Re$.
\item[ii.] If $n$ is even, then $f(x)$ is continuous at each
$x>0$, and discontinuous otherwise.
\end{description}
\label{ContinuityOfRoots}\end{theorem}

Thus $f(x)=\sqrt[3]{x}$ is continuous for all $x\in\Re$, where
$g(x)=\sqrt{x}$ is only continuous for $x>0$. Note that
$g(x)$ is actually  defined at $x=0$, but there is no room to the
left of zero, so the interval $(0-\delta,0+\delta)$ will
always have elements outside the domain of $g$ (namely
$x\in(0-\delta,0)$). Thus with even roots we need to look
at more than where they are defined to determine continuity.

At this point it is useful to introduce the concept of
one-sided continuity.  

\begin{definition}
We call $f(x)$ {\bf left-continuous} at $x=a$ if and only if
\begin{equation}
(\forall\epsilon>0)(\exists\delta>0)(\forall x)
(x\in(a-\delta,a]\longrightarrow|f(x)-f(a)|<\epsilon).\quad
\label{Left-ContDef}\end{equation}
Similarly, we call $f(x)$ {\bf right-continuous} at $x=a$
if and only if
\begin{equation}
(\forall\epsilon>0)(\exists\delta>0)(\forall x)
(x\in[a,a+\delta)\longrightarrow|f(x)-f(a)|<\epsilon).
\label{Right-ContDef}\end{equation}
\end{definition}
Recalling that the definition of continuity, (\ref{continuity}) is
$$(\forall\epsilon>0)(\exists\delta>0)(\forall x)
  (|x-a|<\delta\longrightarrow|f(x)-f(a)|<\epsilon,$$
we can see how left-continuity (\ref{Left-ContDef}) and 
right-continuity (\ref{Right-ContDef})
are related to continuity.  Indeed,
the original definition of
continuity 
could have been written
\begin{equation}
(\forall\epsilon>0)(\exists\delta>0)(\forall x)
(x\in(a-\delta,a+\delta)\longrightarrow|f(x)-f(a)|<\epsilon),
\label{ContWithXIn(a-delta,a+delta)}\end{equation}
and so these one-sided continuity conditions are
effectively two halves of the continuity requirement
(\ref{ContWithXIn(a-delta,a+delta)}).
We leave for an exercise the following theorem:
\begin{theorem}
 $f(x)$ is continuous at $x=a$ if and only if
$f(x)$ is both left- and right-continuous at $x=a$.
\label{NeedLeftAndRightContinuityForContinuityTheorem}\end{theorem}
If we return again to the even roots $f(x)=\sqrt[n]{x}$,
$n$ even we  see that, though these functions are not
continuous at $x=0$, they are right-continuous at $x=0$.
When dealing with functions which contain radicals, for continuity
we often need only see where the functions are defined, and
where we have some ``wiggle room'' on both sides of a 
particular $x=a$. Consider the following:
\bex For each function, find where it is continuous.
\begin{align*}f(x)&=\frac{1}{\sqrt[3]{x-1}},\\
              g(x)&=\sqrt{2x+1},\\
              h(x)&=\sqrt{20-4x},\\
              i(x)&=\sqrt{x^2+1},\\
              j(x)&=\frac{1}{\sqrt{x^2-1}},\\
              k(x)&=\sqrt[3]{x^9-27x^4+x-11}.\end{align*}

\underline{Solution:}

The function $f(x)$ is a ratio of functions which are continuous
everywhere, so we need only check where the denominator is zero.
Thus $f(x)$ is discontinuous only at $x=1$.

The function $g(x)$ is definitely continuous where $2x+1>0$, i.e., $2x>-1$,
i.e., $x>-1/2$.  It is not continuous at $x=-1/2$ because
it $g(x)$ is undefined to the left of $x=-1/2$ as a quick check
will show.  ($g(x)$ is right-continuous at $x=-1/2$, but not
continuous.) Conclude $g(x)$ is continuous for $x>-1/2$.

The function $h(x)$ is definitely  continuous for $20-4x>0$,
i.e., $-4x>-20$, i.e., $x<5$.  It is not continuous at $x=5$
since it is undefined to the right of that point. (It 
is left-continuous at $x=5$, but again, that was not the
question.) Conclude $h(x)$ is continuous where $x<5$.

The function $i(x)$ is continuous everywhere, since
$x^2+1$ is continuous everywhere and for all $x\in\Re$
we also have $x^2+1>0$. (In fact $x^2+1\ge1>0$.)


The functions $j(x)$ is definitely discontinuous at $x=\pm 1$ because
the denominator is zero there.  Thus we need $x^2>1$, which
occurs when $x>1$ or $x<-1$.

The function $k(x)$ is continuous everywhere, being an odd
root of a (continuous) polynomial.

\eex

\bex Find where the function $\ds{f(x)=\frac{\sqrt{9-x^2}}{x^2-1}}$
is continuous.

\underline{Solution:} From the denominator, we need $x\ne\pm1$.
The numerator is definitely continuous for $9-x^2>0$, i.e.,
$9>x^2$, i.e., $-3<x<3$.  It is not continuous at $x=\pm3$
since both are on the edge of the domain (no ``wiggle room'').
Putting this together, we see $f(x)$ is continuous
for $x\in(-3,-1)\cup(-1,1)\cup(1,3)$.
\eex



A useful corollary to Theorem~\ref{ContinuityOfRoots} is the fact
that 
$$f(x)=|x|=\sqrt{x^2}$$
is continuous for all $x\in\Re$.  To see this, note that 
clearly $|x|$ is continuous for $x\ne 0$, for which $x^2>0$.
But there is ``wiggle room'' at $x=0$ as well.  
In fact it is not hard to see $|x|$ is both left- and right-continuous
at $x=0$, and must therefore be continuous there.
To emphasize this we will write this fact as a theorem.
\begin{theorem}
The function $f(x)=|x|$ is continuous for all $x\in\Re$.
\label{|x|IsContinuousEverywhere}\end{theorem}

By our theorem on compositions,
Theorem~\ref{CompositionOfContinuousFunctionsIsContinuous},
we have that the absolute value of a continuous function
is also continuous.


\bex
$f(x)=\sqrt{x^2-2x+1}$ is continuous on $\Re$ since
$f(x)=\sqrt{(x-1)^2}=|x-1|$ is the absolute value of 
a continuous function and is therefore continuous.
\eex










\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\bigskip
\begin{multicols}{2}
\begin{enumerate}
\item Find all $x$ for which the following functions are
continuous:
\begin{enumerate}
\item $\ds{f(x)=\frac{x^2-4}{x^2+4}}$.
\item $\ds{f(x)=\frac{1+x}{1-x^2}}$.
\item $\ds{f(x)=\sqrt{3x-7}}$.
\item $\ds{f(x)=\sqrt{9-3x}}$.
\item $\ds{f(x)=\sqrt{16-x^2}}$.
\item $\ds{f(x)=\sqrt{16+x^2}}$.
\item $\ds{f(x)=\sqrt{x^2+6x+9}}$.
\item $\ds{f(x)=\frac1{\sqrt{x^2+6x+9}}}$.
\item $\ds{f(x)=\sqrt[3]{25-x^2}}$.
\item $\ds{f(x)=\frac{x^2-1}{\sqrt[3]{25-x^2}}}$.
\item $\ds{f(x)=\left|x^2-7x+12\right|}$.
\item $\ds{f(x)=\sqrt{|x|}}$.
\item $\ds{f(x)=\sqrt{\frac{1-x}{1+x^2}}}$.
\item $\ds{f(x)=\sqrt[4]{\frac{1-x}{1+x^2}}}$.
\item $\ds{f(x)=\sqrt[5]{\frac{1-x}{1+x^2}}}$.
\item $\ds{f(x)=\frac1{\sqrt[3]{x^2-1}}}$.

\end{enumerate}
\item Using $\epsilon$-$\delta$ and the definition of 
      right-continuity, show that $f(x)=\sqrt{x}$ is right-continuous
      at $x=0$.

\item  Prove Theorem~\ref{MultiplicativeConstantsPreserveContinuity}.
       Here is the general strategy:
     \begin{enumerate}
     \item For $C=0$, refer to Exercise~\ref{HWConstAreCont}, 
           page~\pageref{HWConstAreCont}.
     \item If $C\ne0$, let $\epsilon_1=\frac{\epsilon}{|C|}$, and
           find the $\delta_1$ corresponding to this $\epsilon_1$
           satisfying the definition of continuity for $f(x)$.  Then
           take $\delta=\delta_1$.
      \end{enumerate}
\item Prove Equation (\ref{1/xContinuousExceptAtZero}).
\item Prove Theorem~\ref{NeedLeftAndRightContinuityForContinuityTheorem}.
      \underline{Hint}: Let $\delta=\min\{\delta_1,\delta_2\}$ where
      $\delta_1$ and $\delta_2$ come from the one-sided continuity
      conditions when proving the ``if,'' and let
      $\delta_1,\delta_2=\delta$ for the ``only if.''
\end{enumerate}
\end{multicols}



















\newpage
\section{Continuity on Intervals\label{ContinuityOnIntervalsSection}}
\bigskip

\begin{quote}{\it
``A function $\phi(x)$ is said to be {\it continuous} between any
limiting values of $x$, such as $a$ and $b$, when to each value
of $x$ between those limits there corresponds a finite value of 
the function, and when an indefinitely small change in the
value of $x$ produces only an indefinitely small change in the
function.  In such cases the function in its passage from 
any one value to any other between the limits
receives every intermediate value, and does not become infinite.
This continuity can be readily illustrated by 
taking $\phi(x)$ as the ordinate of a curve, whose equation
may then be written $y=\phi(x)$.''}

\qquad---{\it Encyclop{\ae}dia Britannica:
A Dictionary of Arts, Sciences, and General Literature},
Volume XIII, Ninth Edition, 1881, p.\ 13 in the
article ``Infinitesimal Calculus,'' pp.\ 5--72.
\label{BritQuote}\end{quote}



\bigskip

\subsection{Continuity on Intervals: Main Definitions and Theorems}

The significance of continuity is perhaps best understood
when applied to whole intervals $(a,b)$, or $[a,b]$, etc., rather
than single points.  Below we will define what it means for
$f(x)$ to be continuous on $(a,b)$, and continuous on $[a,b]$.
(Other cases like $[a,b)$ would be defined in ways which
would be obvious extensions once we have the $(a,b)$ and $[a,b]$ cases.)
Continuity on open intervals is rather trivial to define, 
but nonetheless has interesting
consequences.  In practice we will focus more on 
continuity on  finite closed intervals $[a,b]$, with $a<b$.
But first we look at the open intervals:

\begin{definition}
A function $f(x)$ is said to be continuous on the open
interval $(a,b)$ if and only if $f(x)$ is continuous
at each value $x_0\in(a,b)$.\footnotemark
\end{definition}
%%%%%%%%%%%%%%%  FOOTNOTE TEXT  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext{Of course each $x_0$ may require a different $\delta$ for
a given $\epsilon$ in the original definition of continuity given 
in Section~\ref{FirstContinuitySection}, 
but the above definition only requires
that each individual $x_0\in(a,b)$ is a point at which
$f(x)$ satisfies the $\epsilon$-$\delta$.  To summarize,
$(\forall x_0\in(a,b))(\forall\epsilon>0)(\exists\delta>0)
(\forall x)(|x-x_0|<\delta\longrightarrow|f(x)-f(x_0)|<\epsilon)$.
}
%%%%%%%%%%%%%%   End FOOTNOTE TEXT  %%%%%%%%%%%%%%%%%%%%%%%%%
What is interesting about continuity on $(a,b)$ is that
it implies $f((a,b))$ is an interval of some kind
(possibly infinite, or even a single point),
and that the curve $y=f(x)$ is a {\it connected} graph
for $a<x<b$:

\begin{theorem}
If $f(x)$ is continuous on $(a,b)$, then
$f((a,b))$ is an interval and the graph of $y=f(x)$,
$a<x<b$ is a connected curve.\footnote{%
%%% FOOTNOTE
Recall $f((a,b))=\left\{y\ |\ (\exists x\in(a,b))(y=f(x))\right\}$
is the {\it image} of $(a,b)$ under the function $f$.  That is, 
$f((a,b))$ is the range of $f$, if the domain is restricted to $x\in(a,b)$.
%%% END FOOTNOTE
}
\label{FirstConnectivityTheorem}\end{theorem}


 Unfortunately the proof is just
beyond the scope of this textbook 
and is left, for the interested reader, to a course in 
advanced calculus, real analysis or topology.\footnote{%
%%%%%%%%  FOOTNOTE
The preliminaries required to prove these are not
terribly difficult, but would require a distracting
amount of effort here.}  
%%%%%%%%  END FOOTNOTE
%\hphantom{. }
Still,
with the previous continuity sections
behind us we should at least hear the ring of truth
in the notion that the graph of $f(x)$,
with domain restricted to $x\in(a,b)$, would be connected
if $f$ is continuous on $(a,b)$.
Put another way, we could draw the graph without lifting
our  pen from the paper.  
 This is consistent with the elegant quote given 
at the top of this section, particularly the words,
``\dots{}when an indefinitely small change in the value of 
$x$ produces only an indefinitely small change in the function'';
our pens would not ``jump'' off the page to a radically different height
as we move slowly along the curve by increasing $x$
through the interval $(a,b)$. As a consequence it is then reasonable that
the range will be a (connected) interval as the theorem also states.
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%  FIGURE  %%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\begin{center}
\begin{pspicture}(0,-1)(12,4.25)
%%%Bounding Box \psline(0,-1)(12,-1)(12,4.25)(0,4.25)(0,-1)

%%%%%%% First Graph

\psline[linewidth=.08cm](1.5,1)(3.3,1)
\pscircle[fillstyle=solid,fillcolor=white](1.5,1){.1}
\pscircle[fillstyle=solid,fillcolor=white](3.3,1){.1}

\rput(1.5,.5){$a$}
\rput(3.3,.5){$b$}
\pscurve{oo-oo}(1.5,1.5)(2,2)(2.5,3.4)(3,3)(3.3,3.8)
\psline[linewidth=.08cm](.75,1.5)(.75,3.8)
\pscircle[fillstyle=solid,fillcolor=white](.75,1.5){.1}
\pscircle[fillstyle=solid,fillcolor=white](.75,3.8){.1}
%\psline(.55,1.5)(.95,1.5)
%\psline(.55,3.8)(.95,3.8)
\psline[linestyle=dotted](.75,1.5)(1.5,1.5)
\psline[linestyle=dotted](.75,3.8)(3.3,3.8)
%%%Draw Axes Last
\psline{->}(.5,1)(4,1)
\psline{->}(.75,.75)(.75,4.25)
\psline(1.5,.8)(1.5,1.2)
\psline(3.3,.8)(3.3,1.2)
\rput(2,0){$f((a,b))$ a finite,}
\rput(2,-.5){open interval}

%%%%%%% Second Graph


\rput(5.5,.5){$a$}
\rput(7.3,.5){$b$}
\psline[linewidth=0.08cm](5.5,1)(7.3,1)
\pscircle[fillstyle=solid,fillcolor=white](5.5,1){.1}
\pscircle[fillstyle=solid,fillcolor=white](7.3,1){.1}

%\pscurve{oo-oo}(5.5,2)(6,1.5)(6.3,2)(7,3)(7.3,2.2)
%\psbezier(5.5,2)(5.6,1.75)(5.7,1.5)(6,1.5)
%\psbezier(6,1.5)(6.2,1.5)(6.4,1.75)(6.6,2)

\pscurve{oo-oo}(5.5,2)(5.95,1.5)(6.4,2.25)(6.4,2.25)(6.85,3)(7.3,2.5)

\psline[linestyle=dotted](4.75,3)(6.85,3)
\psline[linestyle=dotted](4.75,1.5)(6,1.5)
\psline[linewidth=0.08cm](4.75,1.5)(4.75,3)
\pscircle[fillstyle=solid,fillcolor=black](4.75,1.5){.1}
\pscircle[fillstyle=solid,fillcolor=black](4.75,3){.1}

%%%Draw Axes Last
\psline{->}(4.5,1)(8,1)
\psline{->}(4.75,.75)(4.75,4.25)
\psline(5.5,.8)(5.5,1.2)
\psline(7.3,.8)(7.3,1.2)
\rput(6,0){$f((a,b))$ a finite,}
\rput(6,-.5){closed interval.}

%%%%%%% Third Graph

\rput(9.5,.5){$a$}
\rput(11.3,.5){$b$}
\pscurve{oo-}(9.5,1)(10.4,1.7)(11.2,4.25)
\psline[linewidth=0.08cm](9.5,1)(11.3,1)
\pscircle[fillstyle=solid,fillcolor=white](9.5,1){.1}
\pscircle[fillstyle=solid,fillcolor=white](11.3,1){.1}
\psline[linestyle=dashed,linewidth=.01cm](11.3,1)(11.3,4.25)
\psline[linewidth=0.08cm]{->}(8.75,1)(8.75,4.25)
\pscircle[fillstyle=solid,fillcolor=white](8.75,1){.1}
%%%Draw Axes Last
\psline{->}(8.5,1)(12,1)
\psline{->}(8.75,.75)(8.75,4.25)
\psline(9.5,.8)(9.5,1.2)
\psline(11.3,.8)(11.3,1.2)
\rput(10,0){$f((a,b))=(0,\infty)$, an}
\rput(10,-.5){infinite, open interval.}
\end{pspicture}
\end{center}
\caption{Some examples of functions continuous on open
intervals $(a,b)$, with images $f((a,b))$ drawn
on the vertical axis.  The image will always
be an interval of some kind---finite, infinite, open,
closed, half-open or a
``single-point'' interval $[c,c]$ if $f$ is a constant
function.
}
\label{ContinuousImageOfAnOpenIntervalFigure}\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






Figure~\ref{ContinuousImageOfAnOpenIntervalFigure} shows
sample cases for continuity on open intervals, illustrating
that the image is always an interval.
Now we turn our attention to continuity on  closed intervals $[a,b]$:
\begin{definition} A function $f:[a,b]\longrightarrow\Re$, with $a<b$ is 
called continuous on the closed interval $[a,b]$
 if and only if
\begin{enumerate}
\item $f(x)$ is continuous on the open interval $(a,b)$;
\item $f(x)$ is right-continuous at $x=a$; and
\item $f(x)$ is left-continuous at $x=b$.
\end{enumerate}
\end{definition}
In other words, if we are on the {\it interior} of $[a,b]$, i.e., 
on $(a,b)$, then we expect good old-fashioned continuity at every point, 
but then we require only right-continuity at $a$, and left-continuity
at $b$.  In this way we ignore the behavior of $f$, if any,
outside of $[a,b]$.

Two very important results which follow from continuity on $[a,b]$ are the
Intermediate Value Theorem (IVT) and the Extreme Value Theorem (EVT).
Both are wrapped up nicely in the following analog to
Theorem~\ref{FirstConnectivityTheorem}, the difference being
that the previous theorem required continuity on $(a,b)$, while
this theorem requires continuity on $[a,b]$.  That minor 
difference gives us a much stronger theorem
(though again we omit the proof):

\begin{theorem} If $f(x)$ is continuous on $[a,b]$, $a<b$, then
$f([a,b])$ is a closed interval of the form $[c,d]$ (possibly
with $c=d$).
\label{SecondConnectivityTheorem}\end{theorem}
In other words, the continuous image of a closed and bounded
interval is also a closed and bounded interval.  If we again
think about graphing such a function we can see that this 
is also believable.  After all, we would have to ``pin down''
the first point $(a,f(a))$, draw continuously until we
end by ``pinning down'' the last point $(b,f(b))$.  In doing
so we would somewhere draw the highest and lowest points
of our curve, and these heights would be $d$ and $c$, respectively,
from our theorem.  Albeit we may hit those high and low
vertical levels repeatedly, and maybe not at $x=a$ or $x=b$,
but they will be achieved nonetheless.

The proof of Theorem~\ref{SecondConnectivityTheorem} is also
beyond the scope of this text, but the EVT and IVT follow
very quickly from the theorem.  We list these very
important facts as corollaries.

\begin{corollary}{\bf (Extreme Value Theorem)} If $f:[a,b]\longrightarrow\Re$
is continuous on $[a,b]$, then $f(x)$ achieves its maximum and
minimum heights at some $x_{\text{\rm max}},x_{\text{\rm min}}\in[a,b]$.
In other words, 
$$\left(
\vphantom{\frac11}
\ \exists x_{\text{\rm min}},x_{\text{\rm max}}\in[a,b]\ \right)
\left(\vphantom{\frac11}
\ f([a,b])=[f(x_{\text{\rm min}}),f(x_{\text{\rm max}})]\ \right).$$
\label{ExtremeValueTheorem}\end{corollary}

\begin{corollary}{\bf(Intermediate Value Theorem)}
 If $f(x)$ is continuous on $[a,b]$, then
$f(x)$ achieves every value between $f(a)$ and $f(b)$.
In other words, if $y_0$ is between $f(a),f(b)$, then
there exists $x_0\in[a,b]$ such that $f(x_0)=y_0$.
\label{IntermediateValueTheorem}\end{corollary}
(Note that the statement of IVT is contained in the second sentence 
of the quote from {\it Britannica}
(page~\pageref{BritQuote}), and the EVT is hinted in the
quote.)
A sample function which demonstrates the theorem and two
corollaries is given in Figure~\ref{ContinuousImageOfClosedIntervalGraph}.

{
%%%%%%%%%%%%%%%%%%%%%%%      FIGURE      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}

\begin{center}
\begin{pspicture}(-2,-2)(7,4)
\psline{->}(-2,0)(7,0)
\psline{->}(0,-2)(0,4)
\psbezier(1,1)(1.3,1.5)(1.5,2)(2,2)
\psbezier(2,2)(2.5,2)(2.5,.5)(3,.5)
\psbezier(3,.5)(4,.5)(4,3.5)(5,3.5)
\psbezier(5,3.5)(5.5,3.5)(5.5,3)(5.9,2.5)
\pscircle[fillstyle=solid,fillcolor=black](1,1){.05}
%\pscircle[fillstyle=solid,fillcolor=black](2,2){.05}
\pscircle[fillstyle=solid,fillcolor=black](3,.5){.05}
\pscircle[fillstyle=solid,fillcolor=black](5,3.5){.05}
\pscircle[fillstyle=solid,fillcolor=black](5.9,2.5){.05}
\psline(1,-.2)(1,.2)
\rput(1,-.5){$a$}
\psline(3,-.2)(3,.2)
\rput(3,-.5){$x_{\text{\rm min}}$}
\psline(5,-.2)(5,.2)
\rput(5,-.5){$x_{\text{\rm max}}$}
\psline(5.9,-.2)(5.9,.2)
\rput(5.9,-.5){$b$}
\psline(-.2,.5)(.2,.5)
\rput(-1,.5){$f(x_{\text{\rm min}})$}
\psline(-.2,3.5)(.2,3.5)
\rput(-1,3.5){$f(x_{\text{\rm max}})$}
%
\psline(-.2,1)(.2,1)
\rput(-1,1){$f(a)$}
\psline(-.2,2.5)(.2,2.5)
\rput(-1,2.5){$f(b)$}
%
\psline[linestyle=dotted](0,2.5)(5.9,2.5)
\psline[linestyle=dotted](0,1)(1,1)
\psline[linestyle=dotted](0,.5)(3,.5)
\psline[linestyle=dotted](0,3.5)(5,3.5)
\pscircle[fillstyle=solid,fillcolor=black](0,3.5){.1}
\pscircle[fillstyle=solid,fillcolor=black](0,.5){.1}
\psline[linewidth=.08cm](0,.5)(0,3.5)
\pscircle[fillstyle=solid,fillcolor=black](1,0){.1}
\pscircle[fillstyle=solid,fillcolor=black](5.9,0){.1}
\psline[linewidth=.08cm](1,0)(5.9,0)
\end{pspicture}
\end{center}
\caption{A typical graph of a function which is continuous on a 
finite, closed interval $[a,b]$.
The image $f([a,b])$ is also a finite, closed interval
(Theorem~\ref{SecondConnectivityTheorem}), containing a maximum 
value $f\left(x_\text{\rm max}\right)$ and a minimum
value $f\left(x_{\text{\rm min}}\right)$, 
which are achieved
at some $x_{\text{\rm max}},x_{\text{\rm min}}\in[a,b]$
(Extreme Value Theorem, Corollary~\ref{ExtremeValueTheorem}).
Also note that all values between $f(a)$ and $f(b)$ (and more, for 
this particular graph) are in the image $f([a,b])$, and thus achieved for
some $x$-values between $a$ and $b$
(Intermediate Value Theorem, Corollary~\ref{IntermediateValueTheorem}).  
}\label{ContinuousImageOfClosedIntervalGraph}
\end{figure}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
It is crucial that the function in question be continuous, and
that the domain in question be closed and bounded, i.e., of the form $[a,b]$
to guarantee that the image is another closed, bounded interval.
The closed criterion is clear from the first and third graphs in 
Figure~\ref{ContinuousImageOfAnOpenIntervalFigure},
page~\pageref{ContinuousImageOfAnOpenIntervalFigure}:
in the first graph, the image is an open interval and so
there is no maximum or minimum is actually achieved;  in the 
third graph, the image is unbounded from above so no maximum
is achieved, and no
minimum is  achieved either.  It may happen that $f((a,b))$ is
a closed and bounded interval, as in the second graph
in that figure, but it clearly (from the other two graphs in that figure) 
is not guaranteed.
Continuity is also required, as we see in 
Figure~\ref{WhyNeedContinuityForIVTandEVT}.

\begin{figure}
\begin{center}
\begin{pspicture}(-1.5,-4)(3.5,2.5)
\psaxes{<->}(0,0)(-1.5,-2.5)(3.5,2.5)
\psplot{-1}{.6}{1 x 1 sub div}
\psplot{1.4}{3}{1 x 1 sub div}
\psline[linestyle=dashed](1,-2.5)(1,2.5)
\rput(1,-3){$\ds{f(x)=\frac1{x-1}}$}
\rput(1,-3.8){$x\in[-1,3]-\{1\}$}
\pscircle[fillstyle=solid,fillcolor=black](-1,-.5){.08}
\pscircle[fillstyle=solid,fillcolor=black](3,.5){.08}
\end{pspicture}\qquad\qquad
\begin{pspicture}(-1.5,-4)(3.5,2.5)
\psaxes{<->}(0,0)(-1.5,-2.5)(3.5,2.5)
\psplot{-1}{1}{x dup mul}
\psplot{1}{3.5}{x .2 mul 1.8 add}
\pscircle[fillstyle=solid,fillcolor=black](-1,1){.08}
\pscircle[fillstyle=solid,fillcolor=white](1,1){.08}
\pscircle[fillstyle=solid,fillcolor=black](1,2){.08}
\pscircle[fillstyle=solid,fillcolor=black](3.5,2.5){.08}
\rput(1,-3.4){$\ds{f(x)=\left\{\begin{array}{rl}x^2,&
             -1\le x<1\\ 2+0.2(x-1),&1\le x\le 3.5\end{array}\right.}$}
\end{pspicture}
\end{center}
\caption{Theorems \ref{FirstConnectivityTheorem}
and \ref{SecondConnectivityTheorem}---and therefore EVT and IVT---require
continuity of $f$, without which the image can be disconnected
or unbounded.
In the first graph, there is a vertical asymptote at $x=1$,
which is a point of discontinuity.  The image is disconnected
(so no IVT) and unbounded (so no EVT).  In the second, there is
a ``jump'' discontinuity at $x=1$, and the image is also
disconnected (no IVT), even though it is bounded.
These do not violate the corollaries since they are of the
form $P\implies Q$, but in both cases we have $\sim P$.
}\label{WhyNeedContinuityForIVTandEVT}\end{figure}

\subsection{Simple Applications of the Intermediate Value Theorem}
We will return to the extreme value theorem and its applications
later in the text.  Here we will instead look at the IVP and 
its usefulness in algebra.  The following simple theorem 
will be useful in what we do next.

\begin{theorem} If $I$ and $J$ are intervals of any
kind except for single points,  with 
$I\subseteq J$, and $f:J\longrightarrow
\Re$ continuous on $J$, then $f:I\longrightarrow\Re$ is continuous
on $I$.\label{DumbContinuityOnSubintervalsTheorem}
\end{theorem}
In other words when a function is  known to be
continuous on an interval, its restriction to a subinterval
is also continuous on that subinterval.
The proof is a matter of chasing down the
definitions of continuity on the various intervals,
and checking each of the cases.  
The following example shows a quick application.
\bex Show that the equation $x^5+7=x^2$ has a solution in $\Re$.
\nopagebreak

\underline{Solution}: First notice that
$$x^5+7=x^2\iff x^5-x^2+7=0.$$
Next define $f(x)=x^5-x^2+7$, which is a polynomial and thus
continuous on all of $\Re$ (think of $\Re$ as the open
interval $(-\infty,\infty)$).  Now
$$x^5+7=x^2\iff x^5-x^2+7=0\iff f(x)=0,$$
so solving the original equation is equivalent to 
finding $x$ so that $f(x)=0$.
Next notice that 
\begin{align*}f(-2)&=(-2)^5-(-2)^2+7=-29,\qquad\text{and}\\
              f(1)&=1-1+7=7.\end{align*}
Because $f$ is continuous in $\Re$, it is also
on $[-2,1]\subseteq\Re$.  Since $f(-2)=-29$ while
$f(1)=7$, there  exists some $x_0$ between $-2$ and $1$
such that $f(x_0)=0$ (by IVT), and this $x_0$ therefore solves the
original equation, q.e.d.
\label{FirstSimpleIVTExample}\eex

The technique in Example~\ref{FirstSimpleIVTExample} is 
standard.  It is similar to the usual algebraic trick
where we try to solve an equation of the form
$g(x)=h(x)$ by instead determining where $g(x)-h(x)=0$.
It is often convenient to define $f(x)=g(x)-h(x)$
and solve the logically equivalent equation $f(x)=0$.
As we saw in the algebra sections earlier, solving $f(x)=0$ is usually
simpler than finding where $g(x)=h(x)$. 

We can apply the IVT 
more than once to a single function, as in the following example:
\bex Show that the equation $x^3-8x^2+15x=-1$ has 
at least three solutions.
\nopagebreak

\underline{Solution}: This is equivalent to the
equation $x^3-8x^2+15x+1=0$ having at least three solutions.
Defining $f(x)=x^3-8x^2+15x+1$, we thus want to prove
that $f(x)=0$ occurs at least three times.

First we notice that $f(x)$ is a polynomial, and therefore
continuous on  $\Re$.  Next we see that
\begin{align*}
f(-1)&=-23,\\
f(0)&=1,\\
f(4)&=-3,\\
f(5)&=1.
\end{align*}
We see that $f(x)$ must be zero for some $x\in(-1,0)$,
another $x\in(0,4)$, and yet another $x\in(4,5)$, q.e.d.
\eex

\subsection{Polynomial Inequalities}
A very important consequence of the Intermediate Value
Theorem is that, for a continuous function to change sign
(positive to negative or vice versa) on an interval,
its values must pass through zero.
We can exploit this to solve polynomial
and rational inequalities.  The application of the IVT
to polynomial inequalities is particularly straightforward,
as the next two examples illustrate.

\bex Solve the inequality $x^3-9x^2+20x\le0$.
\nopagebreak

\underline{Solution}: Define $f(x)=x^3-9x^2+20x$, which
is a polynomial and therefore continuous on all of $\Re$.  We wish
to see where $f(x)\le0$.  First we will see where $f(x)=0$,
to detect the possible points at which $f(x)$ changes signs.
\begin{alignat*}{2}
&&f(x)&=0\\
\iff&&x^3-9x^2+20x&=0\\
\iff&&x(x^2-9x+20)&=0\\
\iff&&x(x-4)(x-5)&=0\\
\iff&&x=0,4,5.\end{alignat*}
These are the only places where $f(x)$ can change 
sign, so $f(x)$ will not change signs within
the intervals $(-\infty,0)$, $(0,4)$, $(4,5)$ or $(5,\infty)$.
For example if we know the sign of $f(x)$ at $x=-10$, then
we know it for the whole interval $x\in(-\infty,0)$.
Furthermore, if we would like to find the sign of $f(x)$
on the interval $(-\infty,0)$, it is enough to know
the signs of all the factors of $f(x)=x(x-4)(x-5)$, since
 if an odd number of the factors are negative then $f$
is negative there, whereas if an even number of factors
are negative then they ``cancel'' to give $f$ a positive 
sign.

A nice visual  device for determining where $f(x)$ is
positive, and where it is negative, is a {\it sign chart}
with the points $x=0,4,5$ as boundary points.  One
style of sign chart is given below (with \boplus\  representing
a positive quantity, and \bominus\  a negative quantity):


\begin{center}
\begin{pspicture}(-0.2,-1)(12,2)
\psline{<->}(2,0)(12,0)
   \psline(4.5,-.2)(4.5,.2)
      \rput(4.5,-.5){$0$}
   \psline(7,-.2)(7,.2)
      \rput(7,-.5){$4$} 
   \psline(9.5,-.2)(9.5,.2)
      \rput(9.5,-.5){$5$}
\rput[l](-0.2,1.5){Function:}
\rput(7,1.5){$f(x)=x(x-4)(x-5)$}

\rput[l](-0.2,.5){Sign Factors:}
\rput[l](-0.2,1.){Test $x=$}
  \rput(3.25,1){$-10$}
\rput(3.25,.5){\bominus\bominus\bominus}
  \rput(5.75,1){$2$}
\rput(5.75,.5){\boplus\bominus\bominus}
  \rput(8.25,1){$4.5$}
\rput(8.25,.5){\boplus\boplus\bominus}
  \rput(10.75,1){$10$}
\rput(10.75,.5){\boplus\boplus\boplus}

\rput[l](-0.2,-.5){Sign $f(x)$:}
\rput(3.25,-.5){\bominus}
\rput(5.75,-.5){\boplus}
\rput(8.25,-.5){\bominus}
\rput(10.75,-.5){\boplus}

\end{pspicture}
\end{center}

\noindent From the chart we see that $f(x)<0$ on the first
and third intervals, i.e., for $x\in(-\infty,0)\cup(4,5)$.
Since $f(x)<0$ is equivalent to our original inequality,
this is also the solution of that inequality.

The information at hand will not give us a complete picture
of the graph of $f(x)$, but it is instructive to see
what the graph looks like, and how an accurate enough
(for our purposes here) picture can be easily imagined
from the sign chart.  For this reason the graph is given
in Figure~\ref{Graph:FunctIneqGraph1}.
\label{Example:FunctIneqGraph1}\eex

\begin{figure}\begin{center}
\begin{pspicture}(-2,-4)(6,4)
\psset{yunit=.2cm}
\psaxes[Dy=5]{<->}(0,0)(-2,-20)(6,20)
\psplot{-.75}{6}{x x 4 sub mul x 5 sub mul}
\end{pspicture}\end{center}
\caption{Actual graph of $f(x)=x(x-4)(x-5)$, showing
where $f(x)>0$, where $f(x)<0$, and how the transitions 
between these occur:
in this case by the function's height passing through zero.  
Compare to the sign chart in Example~\ref{Example:FunctIneqGraph1}.}
\label{Graph:FunctIneqGraph1}\end{figure}

The logic which was used in constructing the sign chart 
bears repeating.  Since $f$ is continuous, the only
way it can change sign is to pass through zero (by IVT,
see also Figure~\ref{Graph:FunctIneqGraph1}), so 
we chart all the $x$-values for which $f(x)=0$.
These mark boundaries of  subintervals of $\Re$
on which $f$ does not change
sign.  For each such interval, knowing the sign of $f(x)$
at any value in the interval gives us the sign for the whole interval
(since, again, it cannot change sign without there
being another zero in the interval, and all such points
are accounted for).  If $f(x)$ happens to be factored,
we only need to check the signs of each factor to see
if the negative factors ``cancel'' completely to leave a
positive function, or if we have an odd number of negatives
to make $f$ negative on the interval in question.

Example~\ref{Example:FunctIneqGraph1} was relatively straightforward.
There can be complications, and we have to be careful to answer
the given question.  For instance, we do not always have
{\it strict inequalities} $<$, $>$, but may have 
{\it inclusive inequalities} $\le$, $\ge$.  


\bex Solve $x^2\ge x+1$.

\underline{Solution}: First we subtract, and then define $f(x)=x^2-x-1$,
so that 
$$x^2\ge x+1\iff x^2-x-1\ge 0\iff f(x)\ge0.$$
Now solving $f(x)=0$ requires the quadratic formula
or completing the square.  We will opt for the former.
Recall first that $f(x)=0\iff x^2-x-1=0$.
$$f(x)=0\iff x=\frac{-(-1)\pm\sqrt{(-1)^2-4(1)(-1)}}{2(1)}
=\frac12\pm\frac12\sqrt{5}\approx-0.61803,\ 1.61803.$$
We will always use the exact values, but the approximate ones
are also useful since we need to know where to find
our test points.\footnotemark
\footnotetext{We could factor $f(x)$ based upon the solutions
to $f(x)=0$, namely $\frac12\pm\frac12\sqrt5$:
$$f(x)=\left(x-\frac{1+\sqrt5}2\right)\left(x-\frac{1-\sqrt5}2\right).$$
Such an approach is perhaps  more sophisticated than our method
in Example~\ref{Example:Second?PolyIneq}, where we did not
bother to factor $f(x)$, but is often unwieldy and 
requires more subtlety than necessary to solve the inequality.}

\begin{center}
\begin{pspicture}(-0.2,-1)(12,2)
\psline{<->}(2,0)(11,0)
   \psline(5,-.2)(5,.2)
      \rput(5,-.5){$\frac{1-\sqrt5}2$}
   \psline(8,-.2)(8,.2)
      \rput(8,-.5){$\frac{1+\sqrt5}2$} 
   \rput[l](-0.2,1.5){Function:}
\rput(7,1.5){$f(x)=x^2-x-1$}
\rput[l](-0.2,1){Test $\hphantom{f(}x\hphantom{)}=$}
\rput[l](-.2,.5){Test $f(x)=$}
\rput[l](-0.2,-.5){Sign $f(x)$:}
\rput(3.5,1){$-10$}
  \rput(3.5,.5){$109$}
  \rput(3.5,-.5){\boplus}
\rput(6.5,1){$0$}
  \rput(6.5,.5){$-1$}
  \rput(6.5,-.5){\bominus}
\rput(9.5,1){$10$}
  \rput(9.5,.5){$89$}
  \rput(9.5,-.5){\boplus}
\end{pspicture}
\end{center}

Recall that we are searching for all points for which $f(x)\ge0$.
These include the cases where $f(x)=0$ as well as where $f(x)>0$.
Therefore we include the endpoints when we report the solution:
$x\in\left.\left(-\infty,\frac{1-\sqrt5}2\right.\right]
\cup\left.\left[\frac{1+\sqrt5}2,\infty\right.\right)$.

The function $f(x)=x^2-x-1$ is graphed in Figure~\ref{Graph:PolyIneq2},
page~\pageref{Graph:PolyIneq2}.
Compare the graph with the sign chart above.
\label{Example:Second?PolyIneq}

\begin{figure}[t]
\begin{center}
\begin{pspicture}(-6,-1)(6,3)
\psset{yunit=.2cm}
\psaxes[Dy=5]{<->}(0,0)(-6,-5)(6,15)
\psplot{-3.38}{4.38}{x dup mul x sub 1 sub}
\end{pspicture}\end{center}
\caption{Actual graph of $f(x)=x^2-x-1$.
The function is zero at $\frac12\pm\frac12\sqrt5
\approx -0.61803,\ 1.61803$.
Compare to the sign chart in Example~\ref{Example:Second?PolyIneq}.}
\label{Graph:PolyIneq2}\end{figure}
\eex

In the first two examples, we had the function $f(x)$
switch signs at every point where $f(x)=0$.  This is not
always the case.  It is possible for the graph to 
touch the axis, and retreat back to the same side.
Consider the following example.

\bex Solve the inequality $x^3-6x^2+9x>0$.

\underline{Solution}: This is already a question about sign,
so we will simply take $f(x)=x^3-6x^2+9x$ and solve $f(x)>0$.
Now 
$$f(x)=x^3-6x^2+9x=x(x^2-6x+9)=x(x-3)^2.$$
We see that $f(x)=0$ at $x=0,3$.  This gives us the
following sign chart:

\begin{center}
\begin{pspicture}(-0.2,-1)(12,2)
\psline{<->}(2,0)(11,0)
   \psline(5,-.2)(5,.2)
      \rput(5,-.5){$0$}
   \psline(8,-.2)(8,.2)
      \rput(8,-.5){$3$} 
   \rput[l](-0.2,1.5){Function:}
\rput(7,1.5){$f(x)=x(x-3)^2$}
\rput[l](-0.2,1){Test $\hphantom{f(}x\hphantom{)}=$}

\rput(3.5,1){$-1$}
\rput(6.5,1){2}
\rput(9.5,1){4}



\rput[l](-.2,.5){Sign Factors:}
\rput[l](-0.2,-.5){Sign $f(x)$:}
\rput(3.5,.5){\bominus\bominus${\vphantom{2}}^2$}
   \rput(3.5,-.5){\bominus}
\rput(6.5,.5){\boplus\bominus${\vphantom{2}}^2$}
  \rput(6.5,-.5){\boplus}
\rput(9.5,.5){\boplus\boplus${\vphantom{2}}^2$}
  \rput(9.5,-.5){\boplus}
\end{pspicture}
\end{center}

We see from the sign chart  that $f(x)>0$ for $x\in(0,3)\cup(3,\infty)$.
\label{Example:ThirdPolyIneq}\eex
We can get an idea how a function might look given a sign
chart as in Example~\ref{Example:ThirdPolyIneq}, and indeed
we see the expected behavior in the graph of the
function, given in Figure~\ref{Figure:ThirdPolyIneq}.

\begin{figure}[h]
\begin{center}

\begin{pspicture}(-2,-3)(5,3)
\psset{yunit=.2cm}
\psaxes[Dy=5]{<->}(0,0)(-2,-15)(5,15)
\psplot{-1}{4.5}{x x 3 sub dup mul mul}
\end{pspicture}\end{center}

\caption{Graph of $f(x)=x(x-3)^2$ as in Example~\ref{Example:ThirdPolyIneq},
illustrating that a function's height can be zero without the
function changing signs there.}
\label{Figure:ThirdPolyIneq}
\end{figure}

It is sometimes the case that, even when $f(x)$ is factored,
some of the factors might never be zero.  In such a case
that factor will never change signs either.  
One common such type of factor is of the form
$x^{2k}+a$, where $k\in\mathbb{N}$ and $a>0$.  Such
a factor is always positive regardless of $x\in\Re$.
Other type factors are not as obvious, but if we
determine a factor has no real zeros, we know it will
not change signs.  The following examples illustrates one case.


\bex Solve the inequality $x^5\le25x$.

\underline{Solution}: As before, we construct $f(x)=x^5-25x$,
so that
$$x^5\le25x\iff x^5-25x\le0\iff f(x)\le 0.$$
Next we factor\footnotemark \ $f(x)=x(x^4-25)=x(x^2+5)(x^2-5)$.
%%%%%%%%%%   FOOTNOTE  %%%%%%%%%%%%%%%%%%%
\footnotetext{For this example we could continue factoring 
$$f(x)=x(x^2+5)(x^2-5)=x(x^2+5)(x-\sqrt5)(x+\sqrt5).$$
However here we will work with the partially factored form,
as this will be sufficient.  It is really a matter of 
personal taste.}
Now the first factor is zero for $x=0$, the second factor
is never zero, and the third is zero for $x=\pm\sqrt5
\approx\pm2.2360679775$.  Hence we get the following sign chart:


\begin{center}
\begin{pspicture}(-0.2,-1)(12,2)
\psline{<->}(2,0)(12,0)
   \psline(4.5,-.2)(4.5,.2)
      \rput(4.5,-.5){$-\sqrt5$}
   \psline(7,-.2)(7,.2)
      \rput(7,-.5){$0$} 
   \psline(9.5,-.2)(9.5,.2)
      \rput(9.5,-.5){$\sqrt5$}
\rput[l](-0.2,1.5){Function:}
\rput(7,1.5){$f(x)=x(x^2+5)(x^2-5)$}

\rput[l](-0.2,.5){Sign Factors:}
\rput[l](-0.2,1.){Test $x=$}
  \rput(3.25,1){$-4$}
\rput(3.25,.5){\bominus\boplus\boplus}
  \rput(5.75,1){$-1$}
\rput(5.75,.5){\bominus\boplus\bominus}
  \rput(8.25,1){$1$}
\rput(8.25,.5){\boplus\boplus\bominus}
  \rput(10.75,1){$4$}
\rput(10.75,.5){\boplus\boplus\boplus}

\rput[l](-0.2,-.5){Sign $f(x)$:}
\rput(3.25,-.5){\bominus}
\rput(5.75,-.5){\boplus}
\rput(8.25,-.5){\bominus}
\rput(10.75,-.5){\boplus}

\end{pspicture}
\end{center}
We see that $f(x)\le0$ for 
$x\in\left(\left.\infty,\vphantom{X_X^X}-\sqrt5\,\right]\right.\cup
\left[0,\vphantom{X_X^X}\sqrt5\,\right]$.




\eex







\subsection{Rational Inequalities}












When applying IVT we have to be careful that we actually
do have continuity.  For instance, if we define $f(x)=1/(x-1)$,
we see that $f(-1)=-1/2$, while $f(3)=1/2$.  However, there
are no points between $-1$ and $3$ at which $f(x)=0$.
The reason the IVT did not apply is that $f(x)=1/(x-1)$ is not
continuous in $[-1,3]$, since it is discontinuous at $x=1$.
If we allow for discontinuities, then a function's output can 
``jump'' past a particular value, and the image be disconnected
(i.e., not an interval).  See the first graph in 
Figure~\ref{WhyNeedContinuityForIVTandEVT},
page~\pageref{WhyNeedContinuityForIVTandEVT} for an illustration of 
this phenomenon with this particular function.  (The second graph
also shows how discontinuity allows ``jumping.'')

Now We can still use the IVT to solve rational inequalities.
We simply need to analyze them and the IVT further. For instance, we
can use the following corollary to that theorem:

\begin{corollary} Suppose that $f(a)=A$ and $f(b)=B$, where
$a<b$, and suppose further that $C$ is between $A$ and $B$.
Then at least one of the following must hold:
\begin{description}
\item[(i)] there exists $c$ between $a$ and $b$ so that $f(c)=C$; or
\item[(ii)] $f(x)$ has at least one discontinuity on $[a,b]$.
\end{description}
\end{corollary}
In other words, for a function to pass from the height
$A$ to the height $B$, it must either pass through every
height in between, or must be discontinuous.

\begin{proof} We can use some symbolic logic to prove this.
The idea is that 
$$f\ \text{continuous on }[a,b]\implies \text{(IVT)}\implies 
{\text{(i)}}.$$
Thus $f$ continuous on $[a,b] \implies $ (i), meaning that
$f$ continuous on $[a,b] \longrightarrow $ (i) is a tautology.  
Finally,  this is 
equivalent to the statement of the corollary:
$$\sim (f \ \text{continuous on }[a,b])\ \vee\ \text{(i),
\qquad q.e.d.}$$
\end{proof}

This proof is, of course, true and precise, but the corollary should
also be intuitive:  as we move $x$  along the
interval $[a,b]$, to pass continuously from one height
to another we pass through all intermediate heights;
if we are not going to pass through all intermediate
heights, we have to somehow ``jump'' over them, requiring a
discontinuity.

The implications for rational, or any other functions
is immediate.  {\it For a function's output
to change signs as we vary its input, that output must
pass through zero or be discontinuous}.  Thus, when we
produce a sign chart for a function $f$, we include
as boundary points all those points where $f$ is zero or discontinuous.  
For rational functions this means we look at where the numerator is
zero, and where the denominator is zero,  respectively.

\bex Solve $\ds{\frac{x}{x^2-1}\le 0}$.


\underline{Solution}: Defining
$\ds{f(x)=\frac{x}{x^2-1}=\frac{x}{(x+1)(x-1)}}$, we see
that $f$ is zero at $x=0$, and discontinuous at $x=\pm1$.
We now use all three of these points to construct the
sign chart.


\begin{center}
\begin{pspicture}(-0.2,-1)(12,3)
\psline{<->}(2,0)(12,0)
   \psline(4.5,-.2)(4.5,.2)
      \rput(4.5,-.5){$-1$}
   \psline(7,-.2)(7,.2)
      \rput(7,-.5){$0$} 
   \psline(9.5,-.2)(9.5,.2)
      \rput(9.5,-.5){$1$}
\rput[l](-0.2,2.5){Function:}
\rput(7,2.5){$\ds{f(x)=\frac{x}{(x+1)(x-1)}}$}

\rput[l](-0.2,.5){Sign Factors:}
\rput[l](-0.2,1.5){Test $x=$}
  \rput(3.25,1.5){$-2$}
\rput(3.25,.5){$\ds{\frac{\text{\bominus}}{\text{\bominus\bominus}}}$}
  \rput(5.75,1.5){$-0.5$}
\rput(5.75,.5){$\ds{\frac{\text{\bominus}}{\text{\boplus\bominus}}}$}
  \rput(8.25,1.5){$0.5$}
\rput(8.25,.5){$\ds{\frac{\text{\boplus}}{\text{\boplus\bominus}}}$}
  \rput(10.75,1.5){$2$}
\rput(10.75,.5){$\ds{\frac{\text{\boplus}}{\text{\boplus\boplus}}}$}

\rput[l](-0.2,-.5){Sign $f(x)$:}
\rput(3.25,-.5){\bominus}
\rput(5.75,-.5){\boplus}
\rput(8.25,-.5){\bominus}
\rput(10.75,-.5){\boplus}

\end{pspicture}
\end{center}
Since we are interested in the points where $f(x)\le0$, we
need the open intervals on which $f(x)<0$, i.e., the first
and third intervals, and all
points where $f(x)=0$, i.e., $x=0$.  Collecting all these
we get 
$x\in(-\infty,-1)\cup[0,1)$.
\label{Example:FirstRationalInequality}\eex

We include a graph of $f(x)=\frac{x}{(x+1)(x-1)}$ 
in Figure~\ref{Graph:FirstRationalInequality} to
illustrate how $f$ changes signs by passing through,
or leaping over zero.  There are other types of 
discontinuities besides vertical asymptotes, but for
rational functions $f$ in which the numerator and
denominator have no common factors, vertical asymptotes
are the only type of discontinuity which can occur.
Notice from the graph why we include $x=0$ but not
$x=\pm 1$, when we solve $f(x)\le 0$.  

\begin{figure}[h]

\begin{center}

\begin{pspicture}(-5,-3)(5,3)
\psset{yunit=.2cm}
\psaxes[Dy=5]{<->}(0,0)(-5,-15)(5,15)
\psplot[plotpoints=300]{-5}{-1.0335}{x x x mul 1 sub div}
\psplot[plotpoints=300]{-.967}{.9667}{x x x mul 1 sub div}
\psplot[plotpoints=300]{1.0335}{5}{x x x mul 1 sub div}

\psline[linestyle=dashed](-1,-15)(-1,15)
\psline[linestyle=dashed](1,-15)(1,15)

\end{pspicture}\end{center}


\caption{Graph of $\ds{f(x)=\frac{x}{(x+1)(x-1)}}$. 
See Example~\ref{Example:FirstRationalInequality}.
Dashed lines are vertical asymptotes at $x=\pm1$, which
are those values of $x$ outside the domain of $f(x)$.
Vertical asymptotes will be properly developed later in 
the text.}
\label{Graph:FirstRationalInequality}
\end{figure}

For another perspective justifying the technique for sign
charts for rational functions, consider that a ratio of functions
can only change signs if the numerator or denominator
changes signs.  Since both numerator and denominator
are polynomials and hence continuous,
they can only change signs by passing through zero.
Summarizing, we conclude that a ratio of polynomials 
can only change signs if the
numerator passes through zero or the denominator passes through
zero.  However, for more general functions we have to consider
all possible types of discontinuities.

The method above can generalize for solving any rational inequality
the same way we generalized for the polynomial case:
we rewrite any inequality into an equivalent statement
about signs ($+/-$).

\bex Solve the inequality $\ds{\frac{x}{x^2-7}\le\frac{2x}{x^2-9}}$.

\underline{Solution}: First we do as before---make this into a question
about signs---by subtracting the right-hand side from the inequality,
and define the difference to be $f(x)$.  Hence we have
$$f(x)=\frac{x}{x^2-7}-\frac{2x}{x^2-9}
=\frac{x(x^2-9)-2x(x^2-7)}{(x^2-7)(x^2-9)}
=\frac{-x^3+5x}{(x^2-7)(x^2-9)}=\frac{-x(x^2-5)}{(x^2-7)(x^2-9)},$$
and we are trying to find where $f(x)\le0$.
We see that $f(x)=0$ for $x=0$ and $x=\pm\sqrt5\approx\pm2.23607$, 
and is discontinuous at $x=\pm3$ and $x=\pm\sqrt7\approx\pm2.64575$.  
The sign chart follows:
%For simplicity we will not factor $f(x)$ any further.
%Instead we will leave it in the form $f(x)=[(-x)(x^2-7)]/[(x^2-1)(x^2-9)]$.

\begin{center}
\begin{pspicture}(-0.2,-1)(14,3.5)
\psline{<->}(2,0)(14,0)
  \psline(3.5,-.2)(3.5,.2)
    \rput(3.5,-.5){$-3$}
  \psline(5,-.2)(5,.2)
    \rput(5,-.5){$-\sqrt7$}
  \psline(6.5,-.2)(6.5,.2)
    \rput(6.5,-.5){$-\sqrt5$}
  \psline(8,-.2)(8,.2)
    \rput(8,-.5){$0$}
  \psline(9.5,-.2)(9.5,.2)
    \rput(9.5,-.5){$\sqrt5$}
  \psline(11,-.2)(11,.2)
    \rput(11,-.5){$\sqrt7$}
  \psline(12.5,-.2)(12.5,.2)
    \rput(12.5,-.5){$3$}
\rput[l](-0.2,3){Function:}
\rput(7,3){$\ds{f(x)=\frac{(-x)(x^2-5)}{(x^2-7)(x^2-9)}}$}

\rput[l](-0.2,.75){Sign Factors:}
\rput[l](-0.2,1.5){Test $x=$}
\rput[l](-0.2,-1){Sign $f(x)$:}
  \rput(2.75,1.5){$-10$}
   \rput(2.75,.75){$\ds{\frac{\text{\boplus\boplus}}{\text{\boplus\boplus}}}$}
         \rput(2.75,-1){\boplus}
  \rput(4.25,1.5){$-2.9$}
    \rput(4.25,.75){$\ds{\frac{\text{\boplus\boplus}}
                                   {\text{\boplus\bominus}}}$}
          \rput(4.25,-1){\bominus}
  \rput(5.75,1.5){$-2.5$}
    \rput(5.75,.75){$\ds{\frac{\text{\boplus\boplus}}
                                   {\text{\bominus\bominus}}}$}
           \rput(5.75,-1){\boplus}
  \rput(7.25,1.5){$-1$}
    \rput(7.25,.75){$\ds{\frac{\text{\boplus\bominus}}
                                   {\text{\bominus\bominus}}}$}
            \rput(7.25,-1){\bominus}
  \rput(8.75,1.5){$1$}
    \rput(8.75,.75){$\ds{\frac{\text{\bominus\bominus}}
                                   {\text{\bominus\bominus}}}$}
            \rput(8.75,-1){\boplus}
  \rput(10.25,1.5){$2.5$}
    \rput(10.25,.75){$\ds{\frac{\text{\bominus\boplus}}
                                   {\text{\bominus\bominus}}}$}
            \rput(10.25,-1){\bominus}  
  \rput(11.75,1.5){$2.9$}
    \rput(11.75,.75){$\ds{\frac{\text{\bominus\boplus}}
                                   {\text{\boplus\bominus}}}$}
            \rput(11.75,-1){\boplus}
  \rput(13.25,1.5){$10$}
    \rput(13.25,.75){$\ds{\frac{\text{\bominus\boplus}}
                                   {\text{\boplus\boplus}}}$}
            \rput(13.25,-1){\bominus}
\end{pspicture}
\end{center}
It is important to note that the sign chart gives us the signs
on the various {\bf open} intervals.  The endpoints of the interval
are either where the function is zero, or undefined
(the latter implying discontinuity).
Since for this case we want our solution to be 
those points where $f(x)\le0$, we have to include those endpoints
where $f(x)=0$.
Putting all this together, we see that
$$x\in\left(-3,-\sqrt7\right)
 \cup\left.\left[-\sqrt5,0\right.\right]\cup\left[\left.-\sqrt5,\sqrt7\right)
\right.\cup(3,\infty).$$
%The the graph of the function $f$ is given in 
%Figure~\ref{Graph:SecondRational}.  
Note where $f$ changes
signs continuously (i.e., passing through zero height)
at $0,\pm\sqrt5$ and discontinuously (in fact, via vertical asymptotes) 
at $x=\pm\sqrt7,\pm3$.  We do not include a graph of $f(x)$ here,
but much of its behavior is evident by the sign chart and
the way $f$ changes signs by passing through height zero
at $x=0, \pm\sqrt5$, and  by discontinuity (in fact, via
vertical asymptotes) at $x=\pm3, \pm\sqrt7$.

%\begin{figure}
%\begin{center}
%\begin{pspicture}(-6,-5)(6,5)
%\psset{xunit=1.5cm}
%\psset{yunit=.5cm}
%\psaxes{<->}(0,0)(-4,-10)(4,10)
%\psplot[plotpoints=300]{-4}{-3.17}{0 x sub x dup mul 5 sub mul %
%                     x dup mul 7 sub x dup mul 9 sub mul div}
%\psplot[plotpoints=300]{-2.83}{-2.66}{0 x sub x dup mul 5 sub mul %
%                     x dup mul 7 sub x dup mul 9 sub mul div}
%\psplot[plotpoints=300]{-.9257}{.9257}{0 x sub x dup mul 5 sub mul %
%                     x dup mul 7 sub x dup mul 9 sub mul div}
%\psplot[plotpoints=300]{1.08}{2.9762}{0 x sub x dup mul 5 sub mul %
%                     x dup mul 7 sub x dup mul 9 sub mul div}
%\psplot[plotpoints=300]{3.17}{4}{0 x sub x dup mul 5 sub mul %
%                     x dup mul 7 sub x dup mul 9 sub mul div}
%\psline[linestyle=dashed](-3,-5)(-3,5)
%\psline[linestyle=dashed](-2.645751311,-5)(-2.645751311,5)
%\psline[linestyle=dashed](2.645751311,-5)(2.645751311,5)
%\psline[linestyle=dashed](3,-5)(3,5)
%\end{pspicture}
%\end{center}
%\caption{Graph of $f(x)=\ds{\frac{(-x)(x^2-7)}{(x^2-1)(x^2-9)}}$
%to accompany Example~\ref{Example:SecondRational}.}
%\label{Graph:SecondRational}
%\end{figure}
%
\label{Example:SecondRational}
\eex

Fortunately, most standard calculus problems require only that
we know where certain functions (or more precisely, derivatives
of functions) are positive ($>0$), and where they are negative ($<$).
For completeness here we also discussed the inclusive
inequalities ($\ge,\le$).  We will round out this section with 
the following final example.

\bex Solve the inequality $\ds{\frac{x^2+x+1}{x^2-7x+12}>0}$.

\underline{Solution}: As usual, we first check to see where 
the numerator is zero (where $f(x)=0$, if $f(x)$ is the
function on the left) and where
the denominator is zero (where $f(x)$ does not exist).
For the numerator we need the quadratic formula:
$$x=\frac{-1\pm\sqrt{1^2-4(1)(1)}}{2(1)}=\frac{1-\sqrt{-3}}{2}
\not\in\Re.$$
We see that the numerator is never zero for $x\in\Re$, and
so the numerator does not contribute any points to include in
making the sign chart.  For the denominator we have
$$x^2-7x+12=0\iff(x-3)(x-4)=0\iff (x=3)\vee(x=4).$$
We use these two points to bound the regions of the sign 
chart:



\begin{center}
\begin{pspicture}(-0.2,-1)(12,2.5)
\psline{<->}(2,0)(11,0)
   \psline(5,-.2)(5,.2)
      \rput(5,-.5){$3$}
   \psline(8,-.2)(8,.2)
      \rput(8,-.5){$4$} 
   \rput[l](-0.2,2){Function:}
\rput(7,2){$\ds{f(x)=\frac{x^2+x+1}{(x-3)(x-4)}}$}
\rput[l](-0.2,1){Test $\hphantom{f(}x\hphantom{)}=$}

\rput(3.5,1){$0$}
\rput(6.5,1){$3.5$}
\rput(9.5,1){$5$}



\rput[l](-.2,.5){Sign Factors:}
\rput[l](-0.2,-.5){Sign $f(x)$:}
\rput(3.5,.5){\rm\boplus/(\bominus\bominus)}
   \rput(3.5,-.5){\boplus}
\rput(6.5,.5){\rm\boplus/(\boplus\bominus)}
  \rput(6.5,-.5){\bominus}
\rput(9.5,.5){\rm\boplus/(\boplus\boplus)}
  \rput(9.5,-.5){\boplus}
\end{pspicture}
\end{center}

\noindent From the sign chart we see the solution is
$x\in(-\infty,3)\cup(4,\infty)$. 

\eex
\newpage
\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\bigskip
\begin{multicols}{2}
\begin{enumerate}
\item For each of the following, draw a continuous
      function $f(x)$ whose domain is $x\in(2,5)$, 
      and whose image of that set (i.e., whose range)
      is given.
  \begin{multicols}{2}
  \begin{enumerate}
    \item $(1,4)$
    \item $\{3\}$
    \item $\Re$
    \item $[1,4]$
    \item $(1,4]$
    \item $(-\infty,1)$
    \item $(-\infty,1]$ \\
    
  \end{enumerate}
  \end{multicols}


\item Solve the inequalities.
  \begin{enumerate}
  \item $(x+1)(x-3)\ge0$.
  \item $\ds{\frac{2x+1}{x^2-16}\le0}$.
  \item $x^2+18>11x$.
  \item $\ds{\frac{x}{x+5}>\frac{1}{x-7}}$.
  \item $x^3+2x^2\le15x$.
  \item $x^2+3x\ge2$
  \item $\ds{\frac{x^2-1}{x^4-3x^2-10}\le0}$.
  \end{enumerate}
\item Use a sign chart to graph the following functions, to the
      extent that continuity and sign of $f$ are illustrated.
  \begin{enumerate}
  \item $f(x)=x(x-1)^2(x^2-4)$.
  \item $f(x)=x^3-x^2-2x$.
  \item $\ds{f(x)=\frac{x-1}{x^2-9x+8}}$.
  \end{enumerate}
\item Draw the graph of a function $y=f(x)$ where
      $f:[2,5]\longrightarrow\Re$, and 
      $f(x)$ is continuous on $(2,5)$ but not on $[2,5]$.
\end{enumerate}





\end{multicols}



\newpage
\section{Finite Limits at Points\label{FirstLimitsSection}}
\begin{figure}
\begin{center}
\begin{pspicture}(-2,-4)(6,4)
%\psset{xunit=.5cm,yunit=.5cm}
\psaxes{<->}(0,0)(-2,-4)(6,4)
\psline(-2,-4)(6,4)
\pscircle[fillstyle=solid,fillcolor=white](3,1){.1}

\rput(4.5,1){$\ds{\lim_{x\to3}f(x)=1}$}


\end{pspicture}
\end{center}
\caption{Graph of the function $f(x)=(x^2-5x+6)/(x-3)
=(x-3)(x-2)/(x-3)$.
Except at $x=3$, this simplifies to $f(x)=x-2$.
Thus the graph of $y=f(x)$ is the same as the line $y=x-2$,
except for a ``hole'' at $(3,1)$.  Though $f(x)$ is
undefined at $x=3$, we can at least say $\ds{\lim_{x\to3}f(x)=1}$.}
\label{IntroductoryLimitExample1}
\end{figure}
The concept of limit is fundamental to calculus.
Before it was developed, mathematicians were able to 
observe many of the apparent truths of calculus, but were unable
to actually {\it prove} them.
The development of a theory of limits, together with the rigorous
definition of $\Re$, bridged the
gaps in calculus  between what they could observe and what they could
actually prove.\footnote{In fact Archimedes (287--212 B.C.)
used many arguments which are considered calculus today.
Without the foundations of calculus his arguments were
very convincing, but fell short of proofs.}

At first limits are just a small step away from continuity;
we can compute many limits quickly based upon our knowledge
of continuous functions.  However, the concept of limit
has been greatly expanded from there
to have meaning in many other contexts.  This section is
devoted to the simplest case---closest to continuity---which
is the case of a finite limit at a point.

As with continuity, we will have many theorems which should
be remembered and understood, but which are intuitive on their 
faces while their proofs are very technical. 
Because of this we leave the proofs until the 
end of the section.\footnote{To be sure, the proofs are
always worth reading and understanding and the techniques involved
are accessible and relevant to our reading here, 
but for now it is more important to
be able to understand and apply the principles enunciated by the theorems
and to understand the definition and examples.}


\subsection{Definition, Theorems and Examples}

A typical example of where we might use a limit 
is the function illustrated in Figure~\ref{IntroductoryLimitExample1},
namely
$$f(x)=\frac{x^2-5x+6}{x-3}.$$
We see that this function is not defined at $x=3$.
If we look at any point other than $x=3$---though what is crucial is to
look at those points near, but not at, $x=3$---we can
simplify $f(x)$ as follows:
$$
f(x)=\frac{x^2-5x+6}{x-3}
=\frac{(x-3)(x-2)}{x-3}=x-2,\qquad x\ne3.$$
Thus $f(x)=x-2$ as long as $x\ne3$. A legitimate 
question to ask is, as $x$ gets near the forbidden value at $3$,
does $f(x)$ get near a particular value?
As we see from figure~\ref{IntroductoryLimitExample1}, 
$f(x)$ {\it does} approach
the value $1$ as $x$ approaches $3$.  The notation we
use to signify this is:
$$\lim_{x\to3}f(x)=1,$$
read, ``the limit, as $x$ approaches 3, of $f(x)$, equals 1.''

Of course, one example does not define a concept,
but before we give the definition we will 
sharpen the idea further by considering
the function $g(x)$ graphed in  
Figure~\ref{IntroductoryLimitExample2}.

\begin{figure}
\begin{center}
\begin{pspicture}(-5.5,-1.1)(5.5,6.6)
\psset{xunit=1.1cm,yunit=1.1cm}
\psaxes{<->}(0,0)(-5,-1)(5,6)
\psbezier(-5,.25)(-4,1)(-4,3)(-3,3)
\pscircle[fillstyle=solid,fillcolor=black](-3,3){.1}
\pscircle[fillstyle=solid,fillcolor=white](-3,2){.1}
\psbezier(-3,2)(-2.5,2)(-2.5,4)(-2,5)
\pscircle[fillstyle=solid,fillcolor=black](-2,1){.1}
\pscircle[fillstyle=solid,fillcolor=white](-2,5){.1}
\psbezier(-2,5)(-1.5,6)(-1.5,3)(-1,2)
\psbezier(-1,2)(-.75,1.5)(-.5,1.5)(0,1)
\pscircle[fillstyle=solid,fillcolor=black](-1,2){.1}
\pscircle[fillstyle=solid,fillcolor=white](-2,5){.1}
\pscircle[fillstyle=solid,fillcolor=white](-3,2){.1}
\psbezier(0,1)(0.5,.5)(2,-1)(4,3)

\rput[Bl](1,5.5){$\ds{\lim_{x\to-3}g(x)}$ does not exist}
\rput[Bl](1,4.5){$\ds{\lim_{x\to-2}g(x)=5}$}
\rput[Bl](1,3.5){$\ds{\lim_{x\to-1}g(x)=2}$}
\rput[Bl](1,2.5){$\ds{\lim_{x\to0}g(x)=1}$}



\end{pspicture}
\end{center}
\caption{A function $g(x)$ to illustrate the concept of limit.  See text.}
\label{IntroductoryLimitExample2}
\end{figure}

\begin{itemize}
\item $\ds{\lim_{x\to 0}g(x)=1}$.  That should be clear
from the graph; as $x$ nears zero, the height indeed
approaches the value $1$.   (We will note later how 
continuity, as at $x=0$, has implications for the
limit.) Similarly $\ds{\lim_{x\to-1}g(x)=2}$.
\item $\ds{\lim_{x\to-2}g(x)=5}$.  Such a limit is oblivious
to what occurs {\it at} $x=-2$, but is instead concerned with what occurs
as we {\it approach} $x=-2$, from both sides. In fact $g(-2)=1$.
\item $\ds{\lim_{x\to-3}g(x)}$ {\it does not exist. }As we
approach from the left of $x=-3$ the function's value nears $3$,
but as we approach from the right the function's value
nears $2$.  For such an ambiguous case we simply
decline to assign a value to the limit, instead declaring 
that it does not exist.  Though not actually 
relevant, we note that $g(-3)=3$. 

\end{itemize}

Now we will give the technical definition of a finite
limit at (or ``about'') a point.

\begin{definition} Given a function $f(x)$ defined on the set
$0<|x-a|<d$, for some $d>0$ ($f(x)$  possibly defined at the point $x=a$ as
well), and some $L\in\Re$, we define
\begin{equation}
\lim_{x\to a}f(x)=L\iff
(\forall\epsilon>0)(\exists\delta>0)(\forall x)(
0<|x-a|<\delta\longrightarrow |f(x)-L|<\epsilon).
\label{FiniteLimitAtAPointDefinition}
\end{equation}
If there is no such $L$ satisfying
{\rm (\ref{FiniteLimitAtAPointDefinition})}, we say
that $\ds{\lim_{x\to a}f(x)}$ {\rm\bf does not exist}.\footnotemark
\end{definition}
%%% FOOTNOTE
\footnotetext{
Note that we will use arrows such as  ``$\to$'' and ``$\longrightarrow$''
for both implication and ``approaches.'' The meanings should be
clear from the contexts.  The valid implication ``$\implies$'' will keep
its earlier meaning throughout.}
%%% END FOOTNOTE
This is sometimes called the epsilon-delta ($\epsilon$-$\delta$)
definition of limit.  It differs from the definition of
continuity in the implication:
\begin{alignat}{2}
\text{\bf continuity:}&
              \qquad&|x-a|<\delta&\longrightarrow|f(x)-f(a)|<\epsilon;
               \label{ContinuityImplication}\\
\text{\bf limit:}&&0<|x-a|<\delta&\longrightarrow|f(x)-L|<\epsilon.
               \label{LimitImplication}
\end{alignat}
A simplistic interpretation would see that the part of $f(a)$ is
played by $L$ in the limit, so $L$ is, in some sense, where
$f(a)$ seems it should be, at least if the function is to be
continuous (which it may or may not be) at $x=a$.
A more important point to note is that the implication
in (\ref{LimitImplication}) is silent on the behavior 
at $x=a$, i.e., when $0=|x-a|$.  Indeed, neither
$x=a$ nor $f(a)$ play a role in the limit implication
(\ref{LimitImplication}),
while both are crucial in (\ref{ContinuityImplication}).
(See again Figure~\ref{IntroductoryLimitExample2}.)



%It was already introduced in Example 
%\ref{notlimit}.   
%Before we begin stating theorems and computing examples, 
%we will somewhat pick apart the definition to see that it
%is consistent with our two earlier examples.
%\begin{enumerate}
%\item The number $\epsilon$ is a precision,
%or tolerance, measuring how accurately $f(x)$ approximates $L$. 
%\begin{itemize}\item $\forall\epsilon>0$:  We are allowed to
%pick any positive tolerance for the variable $f(x)$.  This is
%especially important because we can pick $\epsilon$ to be as
%small as we like, as long as it is positive.  
%\item $|f(x)-L|<\epsilon$:  This is exactly the statement that
%$f(x)$ is within $\epsilon$ of $L$, i.e., $f(x)\in(L-\epsilon,
%%%L+\epsilon).$ This is an interval of
%length $2\epsilon$ with midpoint $L$.\end{itemize}  
%\item The number $\delta$ represents a precision, or tolerance,
%in $x$ which guarantees the $\epsilon$ tolerance in $f(x)$
%{\bf with one crucial exception: 
%we do not consider the case $x=a$.}
%\begin{itemize}
%\item  $\exists\delta>0$:  For the definition to hold true,
%once $\epsilon>0$ is chosen, we can find $\delta>0$ tolerance
%for $x$ as an approximator of (but never equal to $a$), 
%which then implies the $\epsilon$
%tolerance in $f(x)$ as an approximator for $L$.  It is important
%that the existence of positive $\delta$ holds, so that there
%is a region around $x=a$ in which the function $f$ is always
%$\epsilon$-close to $L$.  Thus the function is not allowed to
%vary too violently near $x=a$. 
%\item $0<|x-a|<\delta$: The first statement shows that we are
%not at all interested in the case $|x-a|=0$, i.e., where
%$x=a$.  We have a blind spot for what occurs at the point
%$a$.  We are only interested in what value the function tends
%towards as $x$ tends towards, but never quite attains, the value $a$. 
%The second inequality means that we want to be within $\delta$ of
%$a$ in the variable $x$.  Thus $x$ is allowed to vary within
%the {\it punctured} open interval $(a-\delta,a)\cup(a,a+\delta)
%=(a-\delta,a+\delta)-\{a\}$.
%\end{itemize}\item 

%We can also rephrase the right-hand side
%of (\ref{FiniteLimitAtAPointDefinition}) in terms
%of tolerances as we did with continuity: 
%\begin{quote}{\it for any positive tolerance $\epsilon$ in the
%variable $f(x)$, there exists a positive tolerance $\delta$ in $x$
%such that, if $x$ is within $\delta$ of $a$ {\bf but not equal to } $a$,
%then $f(x)$ is within $\epsilon$ of $L$.}\end{quote} 
%\end{enumerate}

This definition of limit is nontrivial and justifies periodic
revisiting. With all the cases we will study in this section it will
become more and more clear that (\ref{FiniteLimitAtAPointDefinition})
is exactly what we need.
However it would be unwieldy indeed to use this definition to prove
every limit computation, particularly since such computations
are ubiquitous in the rest of this text.
Fortunately we know something about continuous functions,
and indeed  will be able to 
bootstrap much of our knowledge of continuity to
make nearly all of our
limit calculations without working with the $\epsilon$-$\delta$
definition directly.  The limit-specific theorems of this section will
also assist in developing intuition and computational methods.

Our first theorem is on the uniqueness of the limit,
if it exists.  

\begin{theorem}
If $\ds{\lim_{x\to a}f(x)}$ exists, it is unique. In other words,
$$\left(\lim_{x\to a}f(x)=L\right)
\wedge\left(\lim_{x\to a}f(x)=M\right)
\implies L=M.$$
\label{Can'tHaveTwoLimits}\end{theorem}


Theorem~\ref{Can'tHaveTwoLimits} really says the obvious (though
the proof is not so transparent): that a function cannot
simultaneously be within arbitrarily small $\epsilon$ tolerance of two
values and still conform to the limit definition.  Eventually the function
has to ``choose'' between approaching $L$ and $M$
(or other values, or no values), or the
limit definition is violated.  (Recall the discussion
of Figure~\ref{IntroductoryLimitExample2}, particularly 
as $x\to\,-3$.)  The proof is given at the end of the section.

The following theorem is very important for computing limits.\footnotemark
%%% FOOTNOTE
\footnotetext{Many calculus texts  define limits first, using
$\epsilon$-$\delta$ and then use
the second statement of Theorem~\ref{ContinuityImpliesLimit=Function},
$\ds{\lim_{x\to a}f(x)=f(a)}$
as the {\it definition} of continuity of $f(x)$ at $x=a$.  
This is valid since the definition
of limit stands alone without reference to continuity, and (as the proof 
of the theorem shows) their limit definition of continuity is
equivalent to our 
earlier $\epsilon$-$\delta$ definition.  

Recall that our approach  was instead
to first define continuity with $\epsilon$-$\delta$, explore
continuity theorems, and then define the limit.  With our approach
we avoid $\epsilon$-$\delta$ in limit calculations since those 
technicalities are built into the  theorems (specifically in the proofs).  
Ours is the approach
of many analysis texts, and seems to the author less convoluted
and (hopefully) more intuitive than the usual calculus textbook approach.

Eventually (Section~\ref{MoreLimitTheoremsSection}) we do state the
limit theorems which other authors build upon, but only after
we exhaust the problems we can do without those methods, and
after we build a strong, foundational understanding of limits
in a context which is closest to continuity.
\label{FootnoteForWhyWeDoContinuityAndThenLimits}}
%%% END FOOTNOTE


\begin{theorem} \label{ContinuityImpliesLimit=Function}
$f(x)$ is continuous at $x=a$
if and only if $\ds{\lim_{x\to a}f(x)=f(a)}$.
\end{theorem}

 A glance back
at Figure~\ref{IntroductoryLimitExample2} (and also
Figure~\ref{IntroductoryLimitExample1}) makes a good
case for the validity of this theorem.  
The proof is given at the end of the section.
A paraphrasing of the theorem could be: if what the
function approaches is where the function ``ends up,''
then we have continuity; if these are different then we do not.
With this theorem we can compute many limits 
by just evaluating the
functions at the limit points, {\it if the functions
are continuous there}.  (To help decide continuity we had
several theorems in Section~\ref{ContinuityTheoremsSection}.) 

\bex Consider the following limits:
\begin{itemize}
\item $\ds{\lim_{x\to5}\left(x^2+6x\right)=5^2+6(5)=25+30=55,}$
\item $\ds{\lim_{x\to4}\sqrt{26-x^2}=\sqrt{26-4^2}=\sqrt{10}}$,
\item $\ds{\lim_{x\to9}\frac1{x-5}=\frac1{9-5}=\frac14}$,
\item $\ds{\lim_{x\to\,-3}\frac{x}{x^2+1}=\frac{-3}{(-3)^2+1}=\frac{-3}{10}
          }$.
\end{itemize}\eex

\noindent These we could quickly calculate by simple evaluation
because the functions were continuous at the points in question.
However we do need to be careful not to draw the wrong conclusion
from the above example; {\it evaluating a limit by evaluating the 
function at the limit point is only valid if the 
function is continuous there.}  This is illustrated in the next
example.

\bex $\ds{\lim_{x\to3}\sqrt{9-x^2}}$ does not exist
because we cannot approach from the  right side of $3$;
if $x>3$, then $\sqrt{9-x^2}$ is undefined. This does
not contradict Theorem~\ref{ContinuityImpliesLimit=Function},
since the function is not continuous (only left-continuous)
at $x=3$. (This function, along with its additive inverse, is graphed in
{\rm Figure~\ref{SemicirclesFigure}a}, page~\pageref{SemicirclesFigure}.)
\eex

Continuity at $x=a$ is a stronger condition than 
the limit existing at $x=a$: with continuity the
limit must exist {\it and} equal the function value there.
Where limits are truly useful then is with functions which
might not be continuous at a given point, but might
nonetheless have a limit there. Often the function in
question is equivalent to a continuous function {\it near},
but perhaps not {\it at}, the limit point.
We will make repeated use of this fact through
the validity of the following theorem:

\begin{theorem} If $f(x)=g(x)$ on a set $0<|x-a|<d$,
where $d>0$, then
$$\lim_{x\to a}f(x)=\lim_{x\to a}g(x),$$
or both limits do not exist.
\label{f=gLimitTheorem}\end{theorem}

This follows quickly from the definition of limit,
in which we can replace $f$ with $g$, assuming
$\delta\le d$, which is the sort of thing we did in
proving several continuity theorems.

Besides having several applications, this theorem also 
illustrates much of the nature of limits.  First of
all it reflects the fact that the limit has a built-in 
blind spot (by definition) at the point $x=a$.
Next is the local nature of limits:
the fact that $f$ and $g$ could be wildly different
farther away from $x=a$, i.e., for $|x-a|\ge d$,
is of no importance to the limit. 

The most common place where we use Theorem~\ref{f=gLimitTheorem}
is when we calculate limits by simplifying the given function
to one which is the same near $x=a$ and has a more obvious
limit there.  We will consider several examples below.
For our first example we revisit the limit which began this section.
(See Figure~\ref{IntroductoryLimitExample1}, 
page~\pageref{IntroductoryLimitExample1}.)
\bex Compute the limit $\ds{\lim_{x\to3}\frac{x^2-5x+6}{x-3}}$.

\underline{Solution}: Assuming $\ds{f(x)=\frac{x^2-5x+6}{x-3}}$,
we see that
\begin{equation}
f(x)=\frac{(x-3)(x-2)}{x-3}=x-2,\qquad x\ne3.\label{Rut!()}\end{equation}
In other words, for $0<|x-3|<\infty$
(thus $0<|x-3|<d$ for any positive number $d$ as in the theorem), we have
$f(x)=g(x)$, where $g(x)=x-2$, a function continuous at $x=3$.
Now 
$$\lim_{x\to3}g(x)=\lim_{x\to3}(x-2)=3-2=1,$$
and since $f$ and $g$ agree except at $x=3$, we conclude that
$\ds{\lim_{x\to 3}f(x)=1}$ as well.
\eex

The explanation in the example above is complete and correct,
but rather pedantic.  Since it is one of the simpler limit problems
we will come across, a less verbose explanation---but one still
faithful to the spirit of the theorems used---can suffice.
In this text we will write a summary version
which will read as follows:
$$\lim_{x\to3}\frac{x^2-5x+6}{x-3}
\zzalg
%\overset{0/0}{\underset{\text{\rm ALG}}{\longeq}}
\lim_{x\to3}\frac{(x-3)(x-2)}{x-3}
%\overset{0/0}{\underset{\text{\rm ALG}}{\longeq}}
\zzalg
\lim_{x\to3}(x-2)=3-2=1.$$
The ``$0/0$'' over the equal signs signify that the 
limit is of {\it 0/0~form}, which we will discuss
in the next paragraph.
The ``ALG'' underneath the second equal sign signifies that
an algebraic rewriting was carried out which was legitimate
near, but not necessarily at, the limit point
(see again (\ref{Rut!()})).   That 
particular step is where we used Theorem~\ref{f=gLimitTheorem}
(page~\pageref{f=gLimitTheorem}), with 
the original function playing the part of $f$ and
the function $x\longmapsto (x-2)$ playing the part
of $g$. The ``ALG''
under the first equal sign just signifies we algebraically rewrote
the function, so we will use ``ALG'' in both contexts.
We will have other comments to write in the convenient spaces
above and below 
the equal signs for bookkeeping purposes, so we can concisely
organize and later check our work.\footnote{%
%%%%%%  FOOTNOTE 
The comment system we use here was
developed by the author (who doubts that it is unique). 
It has been very useful 
to calculus students for following the instructor's thinking and
clarifying their own. One would usually omit such comments
for  professional publication, where readers are expected
to fully understand each step without explanation.
%%%%%%%%%% END FOOTNOTE
}


The previous example is a limit of a certain {\it form},
which is called the ``0/0~form,'' meaning that the 
function is a fraction in which the numerator and denominator both
approach zero as $x$ approaches the limit point.  
This is one of many {\it indeterminate
forms; }knowing we have $0/0$ form tells
us nothing about the value of the limit itself, or even if
it exists.  The reason is that
a shrinking numerator by itself tends to shrink a
fraction, while a shrinking denominator alone makes a fraction
grow in absolute size.  Knowing these are happening simultaneously does
not tell us the relative rates at which the two influences are
operating.  In other words, which competing 
influence (numerator shrinking or
denominator shrinking) dominates?  Or is there a compromise, as
in the previous example?

There will be many other indeterminate forms, and even
more {\it determinate} forms later in the text.
Most of the interesting limits we will find here are
of the indeterminate forms.  Fortunately we can often
simplify an indeterminate form to one which is not.
We did so in the previous example, finding an
equivalent polynomial limit.  


For now it is important to note that when we have $0/0$ form,
we are not ready to ``plug in the limit point,'' but have
some more work to do, often algebraic. 
The next examples illustrate some 
other such algebraic techniques.

\bex Compute $\ds{\lim_{x\to9}\frac{\sqrt{x}-3}{x-9}}$.

\underline{Solution}: Note that $x=9$ is outside of 
the domain of the function, but the actual domain is
$x\in[0,9)\cup(9,\infty)$ so we can certainly approach
$x=9$ from both directions.  The usual technique here
is to multiply by $(\sqrt{x}+3)/(\sqrt{x}+3)$:
\begin{align*}\lim_{x\to9}\frac{\sqrt{x}-3}{x-9}
&\zzalg 
\lim_{x\to9}\frac{\sqrt{x}-3}{x-9}\cdot\frac{\sqrt{x}+3}{\sqrt{x}+3}
\zzalg
\lim_{x\to9}\frac{x-9}{(x-9)(\sqrt{x}+3)}
\\ &\zzalg\lim_{x\to9}\frac1{\sqrt{x}+3}
=\frac1{\sqrt9+3}=\frac16.
\end{align*}
\eex
As in previous examples, we took a 0/0 form and algebraically
manipulated it until we found a function which was continuous
at $x=9$, and could then evaluate the new function at that point.
A quick alternative method to computing the above limit is 
to use some slightly clever factoring:
$$\lim_{x\to9}\frac{\sqrt{x}-3}{x-9}\zzalg
\lim_{x\to9}\frac{\sqrt{x}-3}{(\sqrt{x}-3)(\sqrt{x}+3)}
\zzalg\lim_{x\to9}\frac1{\sqrt{x}+3}=\frac16.$$

\bex Compute $\ds{\lim_{x\to4}\frac{\frac1x-\frac14}{x-4}}$.

\underline{Solution}: This is of form 0/0 as well.  We need
to simplify the fraction and see how things might cancel.
To be rid of ``fractions in the numerator'' we will 
multiply by $\frac{4x}{4x}$.
\begin{align*} \lim_{x\to4}\frac{\frac1x-\frac14}{x-4}
&\zzalg
\lim_{x\to4}\frac{\frac1x-\frac14}{x-4}\cdot\frac{4x}{4x}
\zzalg\lim_{x\to4}\frac{4-x}{(x-4)(4x)}\\
&\zzalg
\lim_{x\to4}\frac{(-1)(x-4)}{(x-4)(4x)}
\zzalg\lim_{x\to4}\frac{-1}{4x}=\frac{-1}{16}.
\end{align*}
\eex
In the above example, the domain of the original function
was $x\ne0,4$, so we could approach $x=4$ locally inside the
domain.  Such technicalities are important, but one usually
does not make mention of them while working a problem unless
a quick inspection shows they need to be dealt with.
An alternative algebraic method of simplifying
the expression in this limit is to combine the fractions in the
numerator: $1/x-1/4=(4-x)/(4x)$, so the function simplifies
$$\frac{\frac{1}x-\frac14}{x-4}=\frac{\frac{4-x}{4x}}{x-4}
=\frac{4-x}{4x(x-4)}.$$
The first method gives the same simplification
a step (or two) sooner.
Next consider the following rational limit.
\bex Compute $\ds{\lim_{x\to3}\frac{x^2-9}{x^6-243x}}$.

\underline{Solution}: This time we will factor both
numerator and denominator, using $243=3^5$ along the way.
\begin{align*}\lim_{x\to3}\frac{x^2-9}{x^6-243x}
&\zzalg
\lim_{x\to3}\frac{(x+3)(x-3)}{x(x^5-3^5)}
\zzalg
\lim_{x\to3}\frac{(x+3)(x-3)}{x(x-3)(x^4+3x^3+9x^2+27x+81)}\\
&\zzalg
\lim_{x\to3}\frac{x+3}{x(x^4+3x^3+9x^2+27x+81)}\\
&=\frac{6}{3(81+81+81+81+81)}
=\frac{2}{5\cdot81}
=\frac2{405}.
\end{align*}
\eex
In the above example we used the factoring
$a^5-b^5=(a-b)(a^4+a^3b+a^2b^2+ab^3+b^4)$.
Recall earlier we used a version of $a^2-b^2=(a-b)(a+b)$
in the form of $x-9=(\sqrt{x}-3)(\sqrt{x}+3)$.
Similarly, in the following we use 
$a^3-b^3=(a-b)(a^2+ab+b^2)$.
Related techniques often work with limits containing radicals.
\bex Compute $\ds{\lim_{x\to\,-8}\frac{\sqrt[3]x+2}{x+8}}$.

\underline{Solution}:
\begin{align*}
\lim_{x\to\,-8}\frac{\sqrt[3]x+2}{x+8}
&\zzalg
\lim_{x\to\,-8}\frac{x^{1/3}+2}{x+8}\cdot
  \frac{x^{2/3}-2x^{1/3}+4}{x^{2/3}-2x^{1/3}+4}\\
&\zzalg
\lim_{x\to\,-8}\frac{x+8}{(x+8)(x^{2/3}-2x^{1/3}+4)}
\zzalg
\lim_{x\to\,-8}\frac1{x^{2/3}-2x^{1/3}+4}\\
&=\frac1{(-8)^{2/3}-2(-8)^{1/3}+4}=\frac1{4-2(-2)+4}=\frac1{12}.
\end{align*}
The last equality comes from the fact that the new
function is continuous at $x=-8$.
An algebraic alternative is to factor:
$$\lim_{x\to\,-8}\frac{\sqrt[3]x+2}{x+8}
\zzalg
\lim_{x\to\,-8}\frac{\sqrt[3]x+2}{(\sqrt[3]x+2)(x^{2/3}-2x^{1/3}+4)}
\zzalg
\lim_{x\to\,-8}\frac1{x^{2/3}-2x^{1/3}+4}=\frac1{12}  $$
as before.
\eex

We do have to be careful that the limit exists, and there
are many instances in which it will not.  We will discuss
a few below, and add more instances in the next section.

\bex Consider the limit $\ds{\lim_{x\to5}\sqrt{x^2-25}}$.
This limit does not exist, because the function is
not defined for $x\in(-5,5)$, and we need to be able to
approach $x=5$ from the immediate left as well as the right.
\eex

The previous example shows again that we can not compute a limit
by  inputting the limit point just because the function
is defined there.  Recall we can do so if and only if
the function is continuous at that point.  This function
was only right continuous there.

\bex Consider the limit $\ds{\lim_{x\to0}\frac{\sqrt{x^2}}x}$.
This limit is of $0/0$ form, but ultimately
does not exist.  For the sake of argument, 
if it did we would have
$$ \lim_{x\to0}\frac{\sqrt{x^2}}x=\lim_{x\to0}\frac{|x|}{x}.$$
Although $f(x)$ is undefined at $x=0$, we can use the
piecewise definition of the absolute value function to 
rewrite the function for $x\ne0$:
$$f(x)=\frac{x}{|x|}=\begin{cases}
x/(x)&\text{for }x>0\\ x/(-x)&\text{for }x<0\end{cases}
=\begin{cases} 1&\text{for }x>0\\ -1&\text{for }x<0.\end{cases}$$
Now that function has height $-1$ for $x<0$ and height
$1$ for $x>0$, so we get different heights when we approach from
different sides.  Thus the limit does not exist.
This function is graphed in Figure~\ref{x/|x|Graph}.
\label{LimitWithSqrt(x^2)}\eex

\begin{figure}\begin{center}
\begin{pspicture}(-3,-2.1)(3,2.1)
\psset{xunit=.7cm,yunit=.7cm}
\psaxes[labels=none]{<->}(0,0)(-4,-3)(4,3)
\psline(0,-1)(-4,-1)
\psline(0,1)(4,1)
\pscircle[fillstyle=solid,fillcolor=white](0,-1){.08}
\pscircle[fillstyle=solid,fillcolor=white](0,1){.08}
\rput(.7,-1){$-1$}
\rput(-.5,1){$1$}
\rput(-2,-.5){$-2$}

\end{pspicture}
\end{center}
\caption{Partial graph of $f(x)=x/|x|$.}
\label{x/|x|Graph}
\end{figure}

\bex Next consider $\ds{\lim_{x\to-2}\frac{\sqrt{x^2}}x=
                        \lim_{x\to-2}\frac{|x|}{x}}$.

Here we look at two methods of computing this.  First we note
that the function is continuous at $x=-2$, so we can simply
evaluate the function there:
$$\lim_{x\to-2}\frac{\sqrt{x^2}}x=\lim_{x\to-2}\frac{|x|}{x}
         =\frac{|-2|}{-2}=\frac{2}{-2}=-1.$$
Another method is to replace the function by another which is 
equal to the original near $x=-2$:
$$\lim_{x\to-2}\frac{\sqrt{x^2}}x=\lim_{x\to-2}\frac{|x|}{x}
  =\lim_{x\to-2}\frac{-x}{x}=\lim_{x\to-1}(-1)=-1.$$
Note that in the second method, which we will see more of, 
we replaced the function by
$g(x)=(-x)/x$ because $|x|=-x$ for $x\in(-\infty,0)$ and $2\in(-\infty,0)$.
Furthermore, that function could be then be replaced by the {\bf constant}
function $h(x)=-1$---which is trivially continuous---near $x=-2$.\footnotemark
\eex


%%% FOOTNOTE
\footnotetext{The key fact that {\it constant} functions are
continuous is often overlooked at first by students as they compute
limits.  Many calculus textbooks emphasize this fact in the limit
context by enshrining it in a theorem, the gist of which is
\begin{equation}\lim_{x\to a}K=K.\label{LimitOfAConstantFirstStated}
\end{equation}
This is obvious when its meaning is understood:
that if we define $f(x)=K$, where $K\in\Re$ is a constant,
then $\ds{\lim_{x\to a}f(x)=K}$
as well.  A quick glance at such a function---whose graph is a horizontal
line at height $K$---shows that such a function is obviously continuous,
so we can evaluate the limit by evaluating the (constant) function.}
%%% END FOOTNOTE

In the next section we will deal more with piecewise-defined functions,
and how better to deal with limit points that are on the boundaries
of the ``pieces.'' We list one more example here which avoids that
issue, but shows the second method of the previous example in action
again.


\bex Consider the function $\ds{f(x)=\frac{x^2-9}{|x+3|(x-3)}}$.
Then
\begin{align*}
\lim_{x\to3}f(x)&=\lim_{x\to3}\frac{(x+3)(x-3)}{(x+3)(x-3)}
                     \zzalg\lim_{x\to3}1=1;\\
\lim_{x\to-5}f(x)&=\lim_{x\to-5}\frac{(x+3)(x-3)}{-(x+3)(x-3)}
                     \underset{\text{\rm ALG}}{\longeq}\lim_{x\to-5}(-1)=-1.
\end{align*}
We used the fact that $|x+3|=x+3$ for $x$ near $3$, while 
$|x+3|=-(x+3)$ for $x$ near $-5$.  A quick check shows this
limit does not exist for $x\to-3$ (as with Example~\ref{LimitWithSqrt(x^2)}
above).
\eex

\bex Consider the limit $\ds{\lim_{x\to0}\frac1x}$.
This limit does not exist as a finite number. 
The graph is given first in Figure~\ref{ReciprocalGraph}
(and later in Figure~\ref{1/xGraphII}),
but even without referring to that graph, we can see
that the function ``blows up'' as $x$ gets nearer to
zero:  $1/x$ is unbounded and negative as $x$ approaches
zero from the left, and unbounded and positive as
$x$ approaches zero from the right.  When we have
vertical asymptotes at our limit points, 
we do not have finite limits.\footnotemark
\eex
%%% FOOTNOTE
\footnotetext{
In subsequent sections we will define infinite limits, and
left- and right-side limits.  For this section we only concern
ourselves with finite limits at (or ``about,'' i.e., from both
the left and the right) a point. Nothing we do here contradicts
subsequent sections.} 
%%% END FOOTNOTE

Before we end this section we will introduce some convenient
notation.  Unfortunately it resembles some notation
from logic, but it is usually obvious how to distinguish
the two from the context.  The notation is defined
as follows:
\begin{equation}
\lim_{x\to a}f(x)=L
\iff \left[\vphantom{X^X_X}(x\longto a)\longrightarrow (f(x)\longto L)\right].
\end{equation}
For reasons of style, it is often less awkward to write,
``$x^2\longto 9$ as $x\longto 3$,'' than to write $\ds{\lim_{x\to3}x^2=9}$.
We might also write, ``as $x\longto3$, $x^2\longto 9$.'' 
It is important, but usually obvious, where the expressions
would be placed in our original limit notation.
The usefulness of this notation will become more apparent
in the next section.  One nice use we can put it to here
is with the following, perhaps more elegant restatement 
of Theorem~\ref{ContinuityImpliesLimit=Function}:
\begin{equation}
f(x)\text{ continuous at }x=a \iff 
(x\longto a)\longrightarrow( f(x)\longto f(a)).
\end{equation}
\subsection{Proofs of Limit Theorems}
Now we prove Theorem~\ref{ContinuityImpliesLimit=Function},
which states that 
$f(x)$ is continuous at $x=a$
if and only if $\ds{\lim_{x\to a}f(x)=f(a)}$.


\begin{proof}
We prove this in two parts.  First we show the ``only if'' part ($\implies$):

Suppose that $f(x)$ is continuous at $x=a$.  Then
by definition,
$$(\forall \epsilon>0)(\exists\delta>0)(\forall x)
\left(|x-a|<\delta\longrightarrow|f(x)-f(a)|<\epsilon\right).$$
Now for a pair $\epsilon,\delta$ from continuity, we get
$$0<|x-a|<\delta\longrightarrow|x-a|<\delta
\longrightarrow|f(x)-f(a)|<\epsilon,$$
and so the definition of limit works here with the 
$\epsilon,\delta$ from (assumed) continuity, and $f(a)$ for $L$.



For the ``if'' part ($\Longleftarrow$),
 suppose $\ds{\lim_{x\to a}f(x)=f(a)}$.  
Thus 
$$(\forall\epsilon>0)(\exists\delta>0)(\forall x)
(0<|x-a|<\delta\longrightarrow|f(x)-f(a)|<\epsilon).$$
We only need to show that 
$$0=|x-a|\longrightarrow|f(x)-f(a)|<\epsilon.$$
But that is obvious from the definition of a function,
since 
$$|x-a|=0\implies (x=a)\implies f(x)=f(a)\implies
|f(x)-f(a)|=0<\epsilon.$$  Thus the case $0<|x-a|<\delta$
is taken care of by the limit assumption, and the
$0=|x-a|$ by the definition of function, giving us
the full case $|x-a|<\delta$, as required by the continuity
definition, q.e.d.
\end{proof}

Now we prove Theorem~\ref{Can'tHaveTwoLimits}, that
if $\ds{\left(\lim_{x\to a}f(x)=L\right)
\wedge\left(\lim_{x\to a}f(x)=M\right)\implies L=M}$.

\begin{proof} We will prove this by contradiction.  Suppose
that the theorem is false, i.e., that there are two numbers,
$L,M\in\Re$, different, which satisfy the definition
of the limit at $x=a$ (if necessary see (\ref{not(P->Q)})).  
In other words,
\begin{align}
&(\forall \epsilon>0)(\exists \delta_1>0)(\forall x)
\left(0<|x-a|<\delta_1\longrightarrow|f(x)-L|<\epsilon\right),
\label{Can'tHaveTwoLimits1}\\
&(\forall \epsilon>0)(\exists \delta_2>0)(\forall x)
\left(0<|x-a|<\delta_2\longrightarrow|f(x)-M|<\epsilon\right).
\label{Can'tHaveTwoLimits2}\end{align}
Assuming $L\ne M$, then of course $|L-M|>0$.
Choose
\begin{equation}\epsilon=\frac13|L-M|.
  \label{EpsilonChoiceForUniquenssOfLimitProof}\end{equation}
Now pick $\delta_1>0$ which satisfies the implication
in (\ref{Can'tHaveTwoLimits1}) for this particular $\epsilon$,
and $\delta_2>0$ which satisfies the implication in 
(\ref{Can'tHaveTwoLimits2}) for this particular $\epsilon$.
Now define
\begin{equation}\delta=\min\{\delta_1,\delta_2\}.
\label{Can'tHaveTwoLimits3}\end{equation}
Now choose any $x$ satisfying 
$0<|x-a|<\delta$.  This also gives $0<|x-a|<\delta_1$
and $0<|x-a|<\delta_2$ by (\ref{Can'tHaveTwoLimits3}).
This ultimately implies 
\begin{align*}|L-M|&=|L-f(x)+f(x)-M|\\
&\le|L-f(x)|+|f(x)-M|\\
&=|f(x)-L|+|f(x)-M|\\
&< \epsilon+\epsilon=2\epsilon=\frac23|L-M|<|L-M|\implies\F.\end{align*}
The reason that this is a contradiction is the we
proved $L\ne M\implies |L-M|<|L-M|$, which is impossible.\footnotemark
\footnotetext{%
%%%%%%%  FOOTNOTE
We need to be careful about the last step.  It is because
$|L-M|>0$ that we can say $\frac23|L-M|<|L-M|$.  Clearly this
is false if $L=M$.  If 
we do not know that $L\ne M$ (and thus $|L-M|>0$), then we
can only say $\frac23|L-M|\le|L-M|$, as it is always
true that $0\le\frac23|L-M|\le |L-M|$ regardless of
whether $L=M$ or $L\ne M$.
%%%%%%%  END FOOTNOTE
}
This completes the proof of Theorem~\ref{Can'tHaveTwoLimits}.
\end{proof}
\newpage
\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\bigskip
\begin{figure}
\begin{center}
\begin{picture}(300,275)(-100,-100)
\thicklines
\put(-100,0){\vector(1,0){300}}
\put(0,-100){\vector(0,1){275}}
\multiput(-100,-5)(25,0){12}{\line(0,1){10}}
\multiput(-5,-100)(0,25){11}{\line(1,0){10}}
\put(-100,0){\vector(-1,0){10}}

\put(23,-14){$1$}
\put(48,-14){$2$}
\put(73,-14){$3$}
\put(98,-14){$4$}
\put(123,-14){$5$}
\put(148,-14){$6$}
\put(173,-14){$7$}

\put(-36,-14){$-1$}
\put(-61,-14){$-2$}
\put(-86,-14){$-3$}
\put(-111,-14){$-4$}

\put(-20,-102){$-4$}
\put(-20,-77){$-3$}
\put(-20,-52){$-2$}
\put(-20,-27){$-1$}
\put(-12,23){$1$}
\put(-12,48){$2$}
\put(-12,73){$3$}
\put(-12,98){$4$}
\put(-12,123){$5$}
\put(-12,148){$6$}
%\put(-12,173){$7$}

\qbezier(-100,-100)(-75,-25)(-52.5,-25)
\put(-50,-25){\circle{4}}
\qbezier(-47.5,-25)(-25,-25)(0,-75)
\put(-50,25){\circle*{4}}

\qbezier(0,-75)(25,-125)(75,-25)
\put(75,-25){\circle*{4}}
\put(75,125){\circle{4}}
\qbezier(75.5,123)(125,-25)(150,25)
\qbezier(150,25)(175,75)(200,25)
\put(150,25){\circle*{4}}
\put(25,150){$y=f(x)$}
\end{picture}
\end{center}
\caption{Figure for Exercise~\ref{lsdkjf}.}
\label{lsdkjfFigure}
\end{figure}

\begin{multicols}{2}
\begin{enumerate}
\item  \label{lsdkjf}
Consider the graph given above in Figure~\ref{lsdkjfFigure}.

\begin{enumerate}

 \item For each limit, see if it exists.  If not,
          state so.  If so, evaluate it. 
  \begin{enumerate}[(i)]
  \item $\ds{\lim_{x\to-2}f(x)}$.
  \item $\ds{\lim_{x\to0}f(x)}$.
  \item $\ds{\lim_{x\to3}f(x)}$.
  \item $\ds{\lim_{x\to6}f(x)}$.
  \end{enumerate}
 \item Find $f(-2)$, $f(0)$, $f(3)$ and $f(6)$.
 \item Decide if $f(x)$ is continuous at the given
          point.  Explain why or why not, in light of  
          Theorem~\ref{ContinuityImpliesLimit=Function}.
  \begin{enumerate}[(i)]
  \item $x=-2$.
  \item $x=0$.
  \item $x=3$.
  \item $x=6$.
  \end{enumerate}
 \end{enumerate}


\item  Compute the following limits, if they exist, using
Theorem~\ref{ContinuityImpliesLimit=Function}.  If the 
limit does not exist, explain why.
 \begin{enumerate}
 \item $\ds{\lim_{x\to0}\frac{x+2}{x-5}}$.
 \item $\ds{\lim_{x\to5}\sqrt{x^2-16}}$.%(b)
 \item $\ds{\lim_{x\to4}\sqrt{x^2-16}}$.%(c)
 \item $\ds{\lim_{x\to3}\sqrt{x^2-16}}$.%(d)
 \item $\ds{\lim_{x\to81}\sqrt[4]{x}}$.
 \item $\ds{\lim_{x\to-1}\left(x^{100}-x^2+3\right)}$.
 \item $\ds{\lim_{x\to0}\sqrt{x^2+1}}$.
 \item $\ds{\lim_{x\to0}\sqrt[3]{x}}$.
 \item $\ds{\lim_{x\to7}\left((x^2-9)(x+4)\right)}$.
 \end{enumerate}

\item Here we consider why the 0/0-form is indeterminate, 
      i.e., why knowing the numerator and denominator both
      approach zero does not tell us immediately what the 
      limit is.  Compute each of the following limits.
  \begin{enumerate}
  \item $\ds{\lim_{x\to0}\frac{x}{2x}}$.
  \item $\ds{\lim_{x\to0}\frac{x}{3x}}$.
  \item $\ds{\lim_{x\to0}\frac{x^2}{x}}$.
  \item $\ds{\lim_{x\to0}\frac{x}{x^2}}$.
  \item $\ds{\lim_{x\to0}\frac{x}{|x|}}$.
  \item $\ds{\lim_{x\to0}\frac{x^2}{|x|}}$.
  \item Explain why the above computations show that the $0/0$-form 
        is indeed indeterminate.
  \end{enumerate}


\item For each of the following, compute the given
limit if it exists. Be sure to indicate any $0/0$ forms
and any algebraic steps.  If the limit does not
exist, state so and explain why.
 \begin{enumerate}
 \item $\ds{\lim_{x\to3}\frac{x^2+x-12}{2x^2-5x-3}}$.
 \item $\ds{\lim_{x\to25}\frac{x-25}{\sqrt{x}-5}}$.
 \item $\ds{\lim_{x\to\sqrt3}\frac{x^4-9}{x^2-3}}$.
 \item $\ds{\lim_{x\to0}{\frac{\frac{1}{x+3}-\frac13}x}}$.
 \item $\ds{\lim_{x\to0}{\frac{\sqrt{x+1}-1}{x}}}$.
 \item $\ds{\lim_{x\to1}\frac{x^8-1}{x^2-1}}$.
 \item $\ds{\lim_{x\to4}\frac{\frac1{\sqrt x}-\frac12}{x-4}}$.
 \item $\ds{\lim_{x\to16}\frac{\sqrt[4]x-2}{x-16}}$.
 \item $\ds{\lim_{x\to-3}\frac{x^2-9}{x^3+27}}$.

 \end{enumerate}


\item  Let $\ds{f(x)=\frac{(x-2)|2x-5|}{(x-1)(2x-5)}}$.
Compute the following where possible.
 \begin{enumerate}
 \item $\ds{\lim_{x\to2}f(x)}$.
% \item $\ds{\lim_{x\to1}f(x)}$.
 \item $\ds{\lim_{x\to0}f(x)}$.
 \item $\ds{\lim_{x\to3}f(x)}$.
 \item $\ds{\lim_{x\to5/2}f(x)}$.
 \end{enumerate}
\item For each of the following, compute the given
limit if it exists.  Otherwise state and explain why it does not.
 \begin{enumerate}
 \item $\ds{\lim_{x\to3}\sqrt{x^2-4}}$.
 \item $\ds{\lim_{x\to-2}\sqrt{x^2-4}}$.

 \end{enumerate}



\item Compute the limit
$$\lim_{x\to0}\frac{\sqrt{1+x}+\sqrt{1-x}-2}{x^2}.$$
It can help to rewrite the limit
$$\lim_{x\to0}\frac1x\left[\frac{\sqrt{1+x}-1}x+
      \frac{\sqrt{1-x}-1}x\right].$$

%\bhw Compute the following limits if they exist.
%\begin{enumerate}
%\item $\ds{\lim_{x\to0}\frac{x}{|x|}}$.
%\item $\ds{\lim_{x\to0}\frac{x^2}{|x|}}$.
%\end{enumerate}
%\ehw
\item Retrace the proof of Theorem~\ref{Can'tHaveTwoLimits} and
show that the proof still works if we take 
$\ds{\epsilon=\frac12|L-M|}$ in 
(\ref{EpsilonChoiceForUniquenssOfLimitProof}).
(You should be able to then observe why the factor
$1/2$ is the largest factor which works in the proof
of the theorem.)
\end{enumerate}
\end{multicols}


\newpage
\section{One-Sided Finite Limits}


Just as we found a use for one-sided continuity, so we
also have use for so-called left-side (or left-hand side)
and right-side (or right-hand side) limits.  
For instance, consider the function $f(x)=(3x^2+x)/|x|$.
Now $|x|$ can be defined piecewise to be $-x$ for $x\le0$,
and $x$ for $x>0$, for instance.\footnote{%
%%% FOOTNOTE
Of course we can let $|x|$ be $x$ or $-x$ for the case $x=0$,
but that will not come to play in our discussion here.}
%%%% END FOOTNOTE
Although $f(x)$ is undefined at $x=0$, for $x\ne0$ we can write 
$$f(x)=\frac{3x^2+x}{|x|}=\begin{cases}
(3x^2+x)/(x)&\text{for }x>0\\ (3x^2+x)/(-x)&\text{for }x<0\end{cases}\qquad
=\qquad\begin{cases} 3x+1&\text{for }x>0\\ -3x-1&\text{for }x<0.\end{cases}$$
The function is graphed in Figure~\ref{(3x^2+x)/|x|Graph}.
\begin{figure}\begin{center}
\begin{pspicture}(-3,-2.8)(3,2.8)
\psset{xunit=.7cm,yunit=.7cm}
\psaxes[labels=none]{<->}(0,0)(-4,-4)(4,4)
\psline(0,-1)(-1.6666667,4)
\psline(0,1)(1,4)
\pscircle[fillstyle=solid,fillcolor=white](0,-1){.08}
\pscircle[fillstyle=solid,fillcolor=white](0,1){.08}
\end{pspicture}
\end{center}
\caption{Partial graph of $f(x)=(3x^2+x)/|x|$.}
\label{(3x^2+x)/|x|Graph}
\end{figure}
Of course this function is undefined at $x=0$, but we
might be interested in what occurs when we approach zero
from one side or the other.  We see that approaching zero from
the left side
(thus moving right towards zero) we travel along
a line whose height is approaching $-1$, 
while
from the right of zero (moving left) we travel a different line
whose height approaches $1$.
The notation we use to reflect this is the following:
\begin{align*}
\lim_{x\to0^-}f(x)&=-1,\\
\lim_{x\to0^+}f(x)&=1.\end{align*}
We read the notation $x\to0^-$ as ``$x$ approaches zero from the left,''
and $x\to0^+$ as ``$x$ approaches zero from the right.''
To actually work such a problem, in particular without resorting 
to a graph, we could write:
\begin{alignat*}{4}
\lim_{x\to0^-}f(x)&=\lim_{x\to0^-}\frac{3x^2+x}{|x|}
   &&\ {=}\lim_{x\to0^-}\frac{3x^2+x}{-x}&&
  \zzalg\lim_{x\to0^-}(-3x-1)&&=-1,\\
\lim_{x\to0^+}f(x)&=\lim_{x\to0^+}\frac{3x^2+x}{|x|}&&\ {=}
  \lim_{x\to0^+}\frac{3x^2+x}{x}&&
  \zzalg\lim_{x\to0^+}(3x+1)&&=1.
\end{alignat*}
Notice that $\ds{\lim_{x\to0}f(x)}$ does not exist, since 
approaching the limit point (zero) 
from one side gives us one value ($-1$), while
approaching from the other side gives another ($1$).
We next make several clarifications regarding one-sided
limits.
\begin{enumerate}
\item When we analyze a left-side limit, we disregard
      behavior at and right  of the limit point;
      when we analyze a right-side limit, we disregard
      behavior at and left of the limit point.
\item We have analogs (see the theorem below) of 
 Theorem~\ref{NeedLeftAndRightContinuityForContinuityTheorem}
(page~\pageref{NeedLeftAndRightContinuityForContinuityTheorem}),
and 
Theorems~\ref{ContinuityImpliesLimit=Function}
and \ref{f=gLimitTheorem} (page~\pageref{f=gLimitTheorem}) 
except that here it is enough to have
one sided continuity and equality of the replacement function.
We also have the very important theorem in (a) below.
\end{enumerate}
\begin{theorem}The following hold
(where we assume that $d>0$ where it appears):
\begin{enumerate}[\rm\bf(a)]
\item $\ds{\lim_{x\to a}f(x)=L \iff
      \left(\lim_{x\to a^-}f(x)=L\right)\wedge
      \left(\lim_{x\to a^+}f(x)=L\right).}$
\item $\ds{\lim_{x\to a^-}f(x)=f(a)\iff f(x)\text{ is
      left-continuous at }x=a}$.
\item $\ds{\lim_{x\to a^+}f(x)=f(a)\iff f(x)\text{ is
      right-continuous at }x=a}$.
\item $f(x)=g(x)$ on $x\in(a-d,a)$ $\implies$
      $\ds{\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x)}$
      (or both do not exist).
\item $f(x)=g(x)$ on $x\in(a,a+d)$ $\implies$
      $\ds{\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)}$
      (or both do not exist).
\end{enumerate}\label{One-SideLimitTheorem}\end{theorem}
These should become  clear as we
proceed, but are rather technical to prove.\footnote{
%%%% FOOTNOTE
Actually most of these can be proven quickly by 
modifications of the proofs of earlier theorems, but those
proofs each took enough space that to modify them
here would require a rather distracting effort.
We leave them as exercises (but not listed in the
regular exercises) for the interested reader.
%%%% END FOOTNOTE
}
For now we will pursue these ideas in several examples.
\bex If possible find $\ds{\lim_{x\to5^-}\sqrt{x^2-25}}$
and $\ds{\lim_{x\to5^+}\sqrt{x^2-25}}$.

\underline{Solution}:
Note that the domain of $\sqrt{x^2-25}$ is $(-\infty,-5]\cup[5,\infty)$.
Thus we can not approach $x=5$ from the (immediate) left, so
$\ds{\lim_{x\to5^-}\sqrt{x^2-25}}$ does not exist.


On the other hand, the function is right-continuous at $x=5$,
so we can follow the height at $x$-values
on the right of $x=5$, and move left in $x$, and the
height will change  continuously 
to the height at $x=5$ as we move down to that $x$-value.  
$$\lim_{x\to5^+}\sqrt{x^2-25}=\sqrt{5^2-25}=0.$$
\eex
What gave away the fact that we could just ``plug in'' $x=5$
for the right-side limit was that the values inside the
square root were nonnegative for $x$ in that range.
That was not the case as $x\to5^-$; we have ``wiggle room''
to the right, but not to the left, of $x=5$.  For a more 
concise presentation, we could write
\begin{align*}\lim_{x\to5^-}\sqrt{\underbrace{x^2-25}_{<0}}\qquad&\text{does
not exist},\\
\lim_{x\to5^+}\sqrt{\underbrace{x^2-25}_{>0}}\qquad&
=\sqrt{5^2-25}=0.
\end{align*}





Note that the example $f(x)=(3x^2+x)/|x|$ at the beginning
of this section
did not allow us to ``plug in'' $x=0$ for either limit, because
the function is neither left-continuous nor right-continuous
at $x=0$.  But in both cases we replaced the given function
with functions which were: $g(x)=-3x-1$ for the left-side
limit, and $g(x)=3x+1$ for the right-side limit.

\bex Compute if possible
 $\ds{\lim_{x\to3}\frac{(x+2)\sqrt{x^2-6x+9}}{x^2-7x+12}}$.

\underline{Solution}:
First we will do some algebraic simplification:
$$\lim_{x\to3}\frac{(x+2)\sqrt{x^2-6x+9}}{x^2-7x+12}
\zzalg
\lim_{x\to3}\frac{(x+2)\sqrt{(x-3)^2}}{(x-4)(x-3)}
\zzalg
\lim_{x\to3}\frac{(x+2)|x-3|}{(x-4)(x-3)}.
$$
Because we have an absolute value which is zero at our limit point,
the (continuous) function inside the absolute value
 may change sign there and we should check
left and right limits.
\begin{align*}
\lim_{x\to3^-}\frac{(x+2)|\overbrace{x-3}^{<0}|}{(x-4)(x-3)}
&=\lim_{x\to3^-}\frac{(x+2)[-(x-3)]}{(x-4)(x-3)}
=\lim_{x\to3^-}\frac{-(x+2)}{(x-4)}=\frac{-5}{-1}=5,\\
\lim_{x\to3^+}\frac{(x+2)|\overbrace{x-3}^{>0}|}{(x-4)(x-3)}
&=\lim_{x\to3^+}\frac{(x+2)[(x-3)]}{(x-4)(x-3)}
=\lim_{x\to3^-}\frac{(x+2)}{(x-4)}=\frac{5}{-1}=-5.
\end{align*}
Since the left and right limits do not agree, the original
(two-sided) limit does not exist.
\eex
With absolute value problems like the above example,
it is often possible to see quickly if it should be
replaced by the quantity inside, or its opposite
(additive inverse).  One only needs to check if it is
positive or negative just left or just right of the
limit point
(depending upon the side from which we are approaching).
Since $x-3$ is negative just left of $x=3$, we
can use $|x-3|=-(x-3)$ as $x\to3^-$. (Recall the piecewise
definition of $|x|$.)

It is not the case that the two-sided limit will not
exist whenever an absolute value is involved.
Consider the next two examples.

\bex Compute, if possible, $\ds{\lim_{x\to0}\frac{x^2}{|x|}}$.

\underline{Solution}: As before, we will see what limits
we get from both sides.

\begin{alignat*}{3}
\lim_{x\to0^-}\frac{x^2}{|x|}
&\zzalg\lim_{x\to0^-}\frac{x^2}{-x}
&&\zzalg\lim_{x\to0^-}(-x)&&=0,\\
\lim_{x\to0^+}\frac{x^2}{|x|}
&\zzalg\lim_{x\to0^+}\frac{x^2}{x}
&&\zzalg\lim_{x\to0^+}(x)&&=0.
\end{alignat*}
Since both are the same, we conclude\footnote{%%%
%%%% FOOTNOTE
Actually this function simplifies to $|x|$ for $x\ne0$, since
$\ds{\frac{x^2}{|x|}=\frac{|x|^2}{|x|}=|x|,\qquad \text{assuming} \quad
|x|\ne0,}$
i.e., $x\ne0$.
%%% END FOOTNOTE
} 
$\ds{\lim_{x\to0}\frac{x^2}{|x|}=0}$.
\eex

\bex Find $\ds{\lim_{x\to9}\frac{(2x-18)|2x-23|}{x^2-11x+18}}$.

\underline{Solution}: For this function, the expression
inside the absolute value does not change signs at $x=9$
and so we can use older techniques:
$$\lim_{x\to9}\frac{(2x-18)|2x-23|}{x^2-11x+18}
\zzalg\lim_{x\to9}\frac{2(x-9)[-(2x-23)]}%
{(x-9)(x-2)}\zzalg
\lim_{x\to9}\frac{2(23-2x)}{x-2}=\frac{2(23-18)}{9-2}=\frac{10}7.$$
\eex

\bex Suppose $\ds{f(x)=\begin{cases}
      x+1&\text{for }x>3\\
      5x-11&\text{for }x\in[-2,3]\\
      x+3&\text{for }x<-2.\end{cases}}$

\noindent Find all left, right, and two-sided limits, where possible,
at $x=3$, $x=1$ and $x=-2$.

\underline{Solution}:
First we look at $x=3$.
\begin{align*}
\lim_{x\to3^-}f(x)&=\lim_{x\to3^-}(5x-11)=5(3)-11=4,\\
\lim_{x\to3^+}f(x)&=\lim_{x\to3^+}(x+1)=4.
\end{align*}
Therefore $\ds{\lim_{x\to3}f(x)=4}$ also.  (See 
Theorem~\ref{One-SideLimitTheorem}(e), page~\pageref{One-SideLimitTheorem}.)

Next are the limits at $x=1$.  In all cases the computation
is the same, but we will go ahead and write them out here.
(With practice, for such a case only the third would likely be
computed, the other two following.)
\begin{alignat*}{4}
&\lim_{x\to1^-}f(x)&&=\lim_{x\to1^-}(5x-11)&&=5(1)-11&&=-6,\\
&\lim_{x\to1^+}f(x)&&=\lim_{x\to1^+}(5x-11)&&=5(1)-11&&=-6,\\
&\lim_{x\to1}f(x)&&=\lim_{x\to1}(5x-11)&&=5(1)-11&&=-6.
\end{alignat*}
Those were easier because $x=1$ is safely inside the interval
$[-2,3]$, on which $f$ is defined by the (continuous) function
$x\longmapsto5x-12$.
Finally we turn our attention to $x=-2$.
\begin{align*}
\lim_{x\to-2^-}f(x)&=\lim_{x\to-2^-}(x+3)=-2+3=1,\\
\lim_{x\to-2^+}f(x)&=\lim_{x\to-2^+}(5x-11)
  =5(-2)-11=-21.\end{align*}
Since the left and right limits do not agree, we conclude
$\ds{\lim_{x\to-2}f(x)}$ does not exist.
\label{PiecewiseContinuousExample}\eex

If we collect the information in the previous example, along
with the values of $f(x)$ at the limit points, we can 
use Theorem~\ref{One-SideLimitTheorem}, and the
two-sided analogs, to make some 
conclusions regarding various types of  continuity at these points:
\begin{itemize}
\item At $x=3$, we have $\ds{\lim_{x\to3}f(x)=4=f(3)}$, so
      $f(x)$ is continuous at $x=3$.
\item At $x=1$, we have $\ds{\lim_{x\to1}f(x)=-6=f(1)}$, so
      $f(x)$ is continuous at $x=1$.
\item $\ds{\lim_{x\to-2^-}f(x)=1\ne f(-2)=-21}$, so 
      $f(x)$ is not left-continuous at $x=-2$.
\item $\ds{\lim_{x\to-2^+}f(x)=-21=f(-2)}$, so 
      $f(x)$ {\bf is} right-continuous at $x=-2$.
\item $f(x)$ is not continuous at $x=-2$, since it is {\bf not both}
      left- and right-continuous at $x=-2$.  Furthermore,
      since $\ds{\lim_{x\to-2}f(x)}$ does not exist, it cannot
      equal $f(-2)$, so Theorem~\ref{ContinuityImpliesLimit=Function},
      page~\pageref{ContinuityImpliesLimit=Function}
      also gives us a discontinuity at $x=-2$.
\item Since the function is ``piecewise linear,'' it is continuous
      at all other $x$-values.  Thus it is continuous for $x\ne-2$,
      i.e., for all $x\in \Re-\{-2\}=(-\infty,-2)\cup(-2,\infty)$.
\end{itemize}




Just as with continuity and limits, the graph of a function can
often indicate one-sided continuity and the values of one-sided limits.
If we can ``ride along'' the graph towards the limit point from
the prescribed direction, we can visually observe if some height is
approached.  From the graph it is clear that $f(x)$ is continuous
at each $x\ne-2$, and right-continuous there.
The graph of the function
of Example~\ref{PiecewiseContinuousExample}
is given in Figure~\ref{PiecewiseContinuousExampleGraph},
page~\pageref{PiecewiseContinuousExampleGraph}.




\begin{figure}
\begin{center}
\begin{pspicture}(-5,-8)(5,3)
\psset{yunit=.3cm}
\psaxes[Dy=4]{<->}(0,0)(-5,-24)(5,9)
\psline(-5,-2)(-2,1)
\psline(-2,-21)(3,4)
\psline(3,4)(5,6)
\pscircle[fillcolor=white,fillstyle=solid](-2,1){.08}
  \rput(-2,3){$(-2,1)$}
\pscircle[fillcolor=black,fillstyle=solid](-2,-21){.08}
  \rput(-2,-23){$(-2,-21)$}
\pscircle[fillcolor=black,fillstyle=solid](3,4){.08}
  \rput(3,6){$(3,4)$}
\end{pspicture}
\end{center}

\caption{Partial 
graph of function from Example~\ref{PiecewiseContinuousExample},
page~\pageref{PiecewiseContinuousExample}.}
\label{PiecewiseContinuousExampleGraph}
\end{figure}








\newpage
\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\bigskip
\begin{figure}
\begin{center}
\begin{pspicture}(-4.5,-3)(4.5,3.75)
\psset{xunit=.75cm,yunit=.75cm}
\psaxes{<->}(0,0)(-6,-4)(6,5)
\psplot{-5}{-1}{x 3 add 1.5 mul}
\psplot{-1}{1}{-2 x 1 sub mul}
\psplot{1}{5}{x 1 sub}
\pscircle[fillstyle=solid,fillcolor=black](-5,-3){.08}
\pscircle[fillstyle=solid,fillcolor=black](-1,4){.08}
\pscircle[fillstyle=solid,fillcolor=white](-1,3){.08}
\pscircle[fillstyle=solid,fillcolor=black](1,0){.08}
\pscircle[fillstyle=solid,fillcolor=white](5,4){.08}

\end{pspicture}
\end{center}
\caption{Graph of the function $f(x)$ given in Exercises 1 and 2.}
\label{OneSidedLimitsExercisesGraph}
\end{figure}
\begin{enumerate}\begin{multicols}{2}
\item Consider the function graphed in 
Figure~\ref{OneSidedLimitsExercisesGraph}.
{\it From looking at the graph,} answer the following questions.
(It is possible that a requested limit does not exist.)
\begin{enumerate}
 \item $\ds{\lim_{x\to-5^+}f(x)=}$
 \item $\ds{\lim_{x\to-5^-}f(x)=}$
 \item $\ds{\lim_{x\to-5}f(x)=}$
 \item $\ds{\lim_{x\to5^+}f(x)=}$
 \item $\ds{\lim_{x\to5^-}f(x)=}$
 \item $\ds{\lim_{x\to5}f(x)=}$
 \item $\ds{\lim_{x\to-1^-}f(x)=}$
 \item $\ds{\lim_{x\to-1^+}f(x)=}$
 \item $\ds{\lim_{x\to-1}f(x)=}$
 \item $\ds{\lim_{x\to0^-}f(x)=}$
 \item $\ds{\lim_{x\to0^+}f(x)=}$
 \item $\ds{\lim_{x\to0}f(x)=}$
 \item $\ds{\lim_{x\to1}f(x)=}$
 \item $\ds{\lim_{x\to1^-}f(x)=}$
 \item $\ds{\lim_{x\to1^+}f(x)=}$
 \item $\ds{\lim_{x\to-3}f(x)=}$
 \item Is $f(x)$ continuous at $x=-5$? Is $f(x)$
        left-continuous at $x=-5$?
       Is $f(x)$ right-continuous at $x=-5$?
 \item Repeat   for $x=-1$.
 \item Repeat  for $x=1$.
 \item Repeat for  $x=5$.
 \item Repeat for $x=0$.
\end{enumerate}\end{multicols}\newpage
\begin{multicols}{2}
%\begin{enumerate}
\item The function in Figure~\ref{OneSidedLimitsExercisesGraph}
can be defined piecewise as follows:
$$f(x)=\begin{cases}
x-1&\text{for } x\in(1,5)\\
-2(x-1)&\text{for }x\in[-1,1]\\
\frac32(x+3)&\text{for }x\in[-5,-1).
\end{cases}$$
Using this fact (and not referring directly to the graph),
answer (a)--(t) as in the previous exercise.
(For example, $\ds{\lim_{x\to2}f(x)=\lim_{x\to2}(x-1)=2-1=1}$.
For continuity and other questions here, see also
Theorem~\ref{One-SideLimitTheorem} and the previous examples.)
\item Consider the function $f(x)=\ds{\sqrt{x^2-16}}$.
\begin{enumerate}
\item If possible compute $\ds{\lim_{x\to4^-}f(x)=}$
\item If possible compute $\ds{\lim_{x\to4^+}f(x)=}$
\item If possible compute $\ds{\lim_{x\to4}f(x)=}$
\item Do we have continuity, left-continuity, right-continuity
      or neither at $x=4$?
\item If possible compute $\ds{\lim_{x\to-4^-}f(x)=}$
\item If possible compute $\ds{\lim_{x\to-4^+}f(x)=}$
\item If possible compute $\ds{\lim_{x\to-4}f(x)=}$
\item Do we have continuity, left-continuity,  right-continuity
      or neither at $x=-4$?
\item If possible compute $\ds{\lim_{x\to5^-}f(x)=}$
\item If possible compute $\ds{\lim_{x\to5^+}f(x)=}$
\item If possible compute $\ds{\lim_{x\to5}f(x)=}$
\item Do we have continuity, left-continuity,  right-continuity
      or neither at $x=5$?
\end{enumerate}
\item Find $m$ and $b$ so that the following function is
      continuous for all $x\in\Re$:
      $$f(x)=\begin{cases}
            \sqrt{x}&\text{for }x>4\\
            mx+b&\text{for }-4\le x\le4\\
            -3-(x+4)^2&\text{for }x<-4.\end{cases}$$
\underline{Hint}: We need left- and right-continuity at $x=4$,
which has implications for one-sided limits there.  Similarly
at $x=-4$.
\end{multicols}
\end{enumerate}




\newpage
\section{Infinite Limits}
In this section we will extend the notion of limit
so it can describe quantities which are growing without 
bound in many circumstances.  The prototype function
to help define what we mean here will be the familiar
$f(x)=1/x$, which we graph in Figure~\ref{1/xGraphII} above.
%(see also Figure~\ref{ReciprocalGraph}).
\begin{figure}
\begin{center}
\begin{pspicture}(-4,-3.4)(4,3.4)
\psset{xunit=.665,yunit=.665}

\psaxes[labels=none]{<->}(0,0)(-6,-5)(6,5)
\psplot{-6}{-.2}{1 x div}
\psplot{.2}{6}{1 x div}
%  \pscircle[fillstyle=solid,fillcolor=black](2,.5){.05}
%    \rput(2.1,1){$\left(2,\frac12\right)$}
%  \pscircle[fillstyle=solid,fillcolor=black](.5,2){.05}
%    \rput(1.3,2){$\left(\frac12,2\right)$}
%  \pscircle[fillstyle=solid,fillcolor=black](.25,4){.05}
%    \rput(1,4){$\left(\frac14,4\right)$}
%  \pscircle[fillstyle=solid,fillcolor=black](4,.25){.05}
%    \rput(4,.8){$\left(4,\frac14\right)$}
%
%  \pscircle[fillstyle=solid,fillcolor=black](-2,-.5){.05}
%    \rput(-2,-1.3){$\left(-2,-\frac12\right)$}
%  \pscircle[fillstyle=solid,fillcolor=black](-.5,-2){.05}
%    \rput(-1.7,-2.1){$\left(-\frac12,-2\right)$}
%  \pscircle[fillstyle=solid,fillcolor=black](-.25,-4){.05}
%    \rput(-1.4,-4){$\left(-\frac14,-4\right)$}
%  \pscircle[fillstyle=solid,fillcolor=black](-4,-.25){.05}
%    \rput(-4.1,-.75){$\left(-4,-\frac14\right)$}
\end{pspicture}
\end{center}
\caption{Partial graph of $f(x)=1/x$.  We see 
$f(x)\longrightarrow\infty$ as $x\longrightarrow0^+$, while
$f(x)\longrightarrow-\infty$ as $x\longrightarrow0^-$.}
\label{1/xGraphII}
\end{figure}
As we approach zero from the right, we have $1/x$ returning
larger and larger positive numbers, with unbounded growth in $1/x$.
Similarly as we approach zero from the left we
have $1/x$ returning larger and larger negative numbers,
growing without
bound.  For this function we would write
\begin{align}
\lim_{x\to0^+}\frac1x&\,\overset{1/{0^+}}{\longeq}+\infty
  \text{ (or just $\infty$)},
  \label{1/xTo+Infty}\\
\lim_{x\to0^-}\frac1x&\,\overset{1/0^-}{\longeq}-\infty, 
           \label{1/xTo-Infty}\\
\lim_{x\to0}\frac1x&\text{ does not exist }(1/0^{\pm}).
            \label{1/xDNE}
\end{align}
The above is the most important such example.
The first two limits are particular forms, $1/0^+$ and $1/0^-$
 which we will
discuss later in this section.
The third limit does not exist because the left-side and right-side
limits do not agree.
For completeness and future reference we will start by giving definitions of 
what it means for a limit at a point, from the left or right,
to be $\infty$:
\begin{definition} For $a\in\Re$, we say 
\begin{align}\lim_{x\to a}f(x)&=\infty
\iff (\forall M\in\Re)(\exists \delta>0)(\forall x)(0<|x-a|<\delta
\longrightarrow f(x)>M),\label{F(x)->Infty}\\
\lim_{x\to a^+}f(x)&=\infty\iff(\forall M\in\Re)(\exists \delta>0)(\forall x)
    (x\in(a,a+\delta)\longrightarrow f(x)>M),\\
\lim_{x\to a^-}f(x)&=\infty\iff(\forall M\in\Re)(\exists \delta>0)(\forall x)
    (x\in(a-\delta,a)\longrightarrow f(x)>M).
\end{align}
\end{definition}
In other words, to say that a limit is $\infty$ is to say that
we can force $f(x)$ to be greater than any chosen number $M$
by forcing $x$ to be within $\delta$ of $a$ (but not equal to $a$), 
from one or both 
directions depending upon if it is a right, left, or two-sided limit.
A graphical example of (\ref{F(x)->Infty}) is given in
Figure~\ref{FigForF(x)->Infty}.

\begin{figure}[tb]
\begin{center}
\begin{pspicture}(-6.4,-1)(6.4,7.175)
\psset{xunit=1.5cm,yunit=.7cm}
%\psaxes[labels=none]{<->}(0,0)(-3.2,-1)(3.2,10.25)
\psline{<->}(-4.2,-.7)(4.2,-.7)
\psline{<->}(-2,-1.4)(-2,10.25)
\psplot{-4.2}{-.3123}{1 x dup mul div}
\psplot{.3123}{4.2}{1 x dup mul div}
\psline[linestyle=dashed](-3.2,5.7)(3.2,5.7)
  \rput(2.4,6){$y=M$}
\psline[linestyle=dotted,linewidth=0.06cm](-.35,-.7)(-.35,10.25)
\psline[linestyle=dotted,linewidth=0.06cm](.35,-.7)(.35,10.25)
\psline[linestyle=dashed](0,-1)(0,10.25)
\rput(0,-1.4){$a$}
\rput(-1.2,-1.4){$a-\delta$}
 \psline{->}(-.8,-1.4)(-.35,-.7)
\rput(1.2,-1.4){$a+\delta$}
 \psline{->}(.8,-1.4)(.35,-.7)
\rput(-.175,-.4){$\delta$}
\rput(.175,-.4){$\delta$}
\end{pspicture}
\end{center}
\caption{A function $f(x)$ with $\ds{\lim_{x\to a}f(x)=\infty}$.
By (\ref{F(x)->Infty}), 
for any height $M$ we can find $\delta>0$ so
that $0<|x-a|<\delta\implies f(x)>M$.  In other words, we can
choose any height, and then force $f(x)$ to be still higher than
that height by forcing $x$ to be within some $\delta$ of $a$,
but (as always with limits) never actually equal to $a$.
Notice that since $f(x)$ is continuous near $x=a$ (but not at $x=a$),
the limit as $x\to a$ being infinite gives a vertical asymptote there
(given by the dashed vertical line at $x=a$).}
\label{FigForF(x)->Infty}
\end{figure}

Proofs using these definitions are interesting, but
we will have numerous shortcuts based upon general
observations. Again for completeness 
we will first (quickly) list the similar definitions
for the limits being $-\infty$.
\begin{definition} For $a\in\Re$, we say
\begin{align}\lim_{x\to a}f(x)&=-\infty
\iff (\forall N\in\Re)(\exists \delta>0)(\forall x)(0<|x-a|<\delta
\longrightarrow f(x)<N),\label{F(x)->-Infty}\\
\lim_{x\to a^+}f(x)&=-\infty\iff(\forall N\in\Re)(\exists \delta>0)(\forall x)
    (x\in(a,a+\delta)\longrightarrow f(x)<N),\\
\lim_{x\to a^-}f(x)&=-\infty\iff(\forall N\in\Re)(\exists \delta>0)(\forall x)
    (x\in(a-\delta,a)\longrightarrow f(x)<N).
\end{align}
\end{definition}
Thus, to say a limit is $-\infty$ is to say that the function's
height can be forced to be below any given (earlier) fixed level
by forcing $x$ to be within some distance of $a$, ignoring
the case $x=a$ as we always do with limits.

Earlier we had the {\it indeterminate} limit form $0/0$ (meaning that
knowing the numerator and denominator both approach zero does
not tell us the value of the limit).
In many of these next cases we will have  variations of 
forms $1/0^+$, $1/0^-$ and $1/0^{\pm}$, which are {\it not
indeterminate}, i.e., are {\it determinate}
and as such should become intuitive upon reflection.
In the definitions below, we will write the functions
$\NUM$ for the numerator, and $\DEN$ for the denominator.
\begin{definition} For a function $\ds{f(x)=\frac{\NUM(x)}{\DEN(x)}}$,
define the following forms:
\begin{enumerate}
\item $1/0^+$: any limit in which $\NUM(x)\longto1$ and $\DEN(x)\longto0^+$,
               the latter meaning
               the denominator is positive but approaching zero,
               as $x$ approaches the limit point in the prescribed way.
\item $1/0^-$: any limit in which $\NUM(x)\longto1$ and $\DEN(x)\longto0^-$,
               the latter meaning 
               the denominator is negative but approaching zero,
               as $x$ approaches the limit point in the prescribed way.
\item $1/0^{\pm}$: any limit in which $\NUM(x)\longto1$ and
               $\DEN(x)\longto0$, with $\DEN(x)\ne0$ but sometimes
               $\DEN(x)$ is positive, other times negative,
               as $x$ approaches the limit point in the prescribed way.
\end{enumerate}
\end{definition}
\begin{theorem} Any limit of the form $1/0^+$ will return $+\infty$;
any limit of the form $1/0^-$ will return $-\infty$; and
any limit of the form $1/0^\pm$ will not exist. 
\end{theorem}
This is well illustrated in the behavior of $f(x)=1/x$
as zero is approached, as in Figure~\ref{1/xGraphII}
at the opening of this section (page~\pageref{1/xGraphII}), and the
corresponding limits (\ref{1/xTo+Infty}), (\ref{1/xTo-Infty})
and (\ref{1/xDNE}).

\bex Consider the following limits and their methods of computation:
\begin{enumerate}
\item $\ds{\lim_{x\to5^+}\frac1{\sqrt{x^2-25}}
   \overset{1/0^+}\longeq\infty}$.
\item $\ds{\lim_{x\to9^+}\frac{10-x}{9-x}
    \overset{1/0^-}\longeq-\infty}$.
\item $\ds{\lim_{x\to3}\frac{1}{x-3}
    \text{ does not exist }(1/0^\pm)}$.
\item $\ds{\lim_{x\to4}\frac{x}{(x-4)^2}
    \overset{4/0^+}\longeq\infty}$.
\end{enumerate}
\eex
In the last limit, the denominator {\it is} positive for $x\to4$
from both sides, because it is a perfect (polynomial) square.
Notice also that, strictly speaking, it is of the form
$4/0^+$, but that is also {\it determinate} (i.e., not indeterminate).  
In fact, it
is just 4 times a limit which is of the form $1/0^+$
if we factor out the 4 (and accept that $4\cdot\infty=\infty$):
\begin{equation}\lim_{x\to4}\frac{x}{(x-4)^2}
=4\lim_{x\to4}\frac{x/4}{(x-4)^2}
\overset{4(1/0^+)}\llongeq4\cdot\infty=\infty.\label{4CdotInfty}
\end{equation}
Notice that limits allow us to---somewhat---extend
our arithmetic when it is understood that it is 
really a statement about limit forms.   For instance,
we could say that
\begin{equation}
(\forall a>0)[a\cdot\infty=\infty],\qquad\text{and}\qquad
            (\forall a>0)[a\cdot(-\infty)=-\infty].
\end{equation}
These mean that if part of the function approaches $a>0$,
and the other ``approaches'' $\infty$, then so does the 
limit of the product approach $\infty$. Similarly $a\cdot(-\infty)$
gives us $-\infty$. 
For (\ref{4CdotInfty}), we used the fact that  if a function
grows positive without bound as we approach the limit point,
then so will something which is roughly
4 times that function (it will just happen
roughly four times as fast).  On the other hand,
\begin{equation}
(\forall a<0)[a\cdot\infty=-\infty],\qquad\text{and}\qquad
            (\forall a<0)[a\cdot(-\infty)=\infty].
\end{equation}
Multiplying a function, which ``blows up'' as we approach
the limit point, by another function which approaches
a negative number, does not change the fact that the product
will still blow up, but it will occur in the other direction,
i.e., with the other sign.

In terms of division, we can write\footnotemark
\begin{align}
(\forall a>0)&\left[\left(\frac{a}{0^+}=a\cdot\frac1{0^+}=a\cdot\infty=\infty
              \right)\wedge\left(\frac{a}{0^-}
               =a\cdot\frac1{0^-}=a\cdot(-\infty)=-\infty\right)
              \right],\label{(a>0)timesinfty}\\
(\forall a<0)&\left[\left(\frac{a}{0^+}=a\cdot\frac1{0^+}=a\cdot\infty=-\infty
               \right)\wedge\left(\frac{a}{0^-}=
               a\cdot\frac1{0^-}=a\cdot(-\infty)=\infty\right)
               \right].\label{(a<0)timesinfty}
\end{align}
%%%%%%% FOOTNOTE
\footnotetext{Another way to look at these limits is to 
first make note that they are blowing up---for 
instance $\NUM\to a\ne0$ but $\DEN\to0$---and 
then just take note of the sign of the fraction as a whole.
If it is positive and blowing up, the limit must be $\infty$;
if negative and blowing up, the limit must be $-\infty$;
if both signs occur consistently as $x$ approaches the
limit point, {\it and} the fraction is blowing up in
absolute size, then the limit must not exist
(part of the function blows up towards $\infty$, and another
part towards $-\infty$, as $x\to a$).}
%%%%%%% END FOOTNOTE









We take this opportunity to point out that knowing where these infinite
limits occur is useful in sketching a graph of the function.  Consider
for instance the limit from the previous example:
$$\lim_{x\to4}\frac{x}{(x-4)^2}=\infty.$$
If we were to construct a sign chart for this function, and note
the vertical asymptote at $x=4$, we get some idea of what it's graph looks
like near that vertical asymptote.

\begin{center}
\begin{pspicture}(-0.2,-1)(12,2)
\psline{<->}(2,0)(11,0)
   \psline(5,-.2)(5,.2)
 \psline[linestyle=dashed](8,-1)(8,2)     
% \psframe*[linecolor=white](4.5,-1)(5.5,0)
      \rput(5,-.5){$0$}
   \psline(8,-.2)(8,.2)
      \rput(8,-.5){$4$} 
   \rput[l](-0.2,1.5){Function:}
\rput(5,1.5){$f(x)=x/(x-4)^2$}
\rput[l](-0.2,1){Test $\hphantom{f(}x\hphantom{)}=$}
\pscurve(7,1)(7.5,1.2)(7.9,2)
\pscurve(9,1)(8.5,1.2)(8.1,2)


\rput(3.5,1){$-1$}
\rput(6.5,1){2}
\rput(9.5,1){5}

\rput[l](-.2,.5){Sign Factors:}
\rput[l](-0.2,-.5){Sign $f(x)$:}
\rput(3.5,.5){\bominus/\bominus${\vphantom{2}}^2$}
   \rput(3.5,-.5){\bominus}
\rput(6.5,.5){\boplus/\bominus${\vphantom{2}}^2$}
  \rput(6.5,-.5){\boplus}
\rput(9.5,.5){\boplus/\boplus${\vphantom{2}}^2$}
  \rput(9.5,-.5){\boplus}
\end{pspicture}
\end{center}
In fact this function also has horizontal asymptotes, a topic which
will occur in a later section.  A computer-generated graph is given
in Figure~\ref{x/(x-4)^2}, page~\pageref{x/(x-4)^2}, and so
our sign chart at least accurately displays the sign and the
behavior as $x\to4$. 

\begin{figure}
\begin{center}
\begin{pspicture}(-2,-3)(7,4.3)
\psaxes{<->}(0,0)(-2,-3)(7,4)
\psline[linestyle=dashed](4,-3)(4,4)
\psplot[plotpoints=2000]{-2}{3.13}{x x 4 sub dup mul div}
\psplot[plotpoints=2000]{5.095}{7}{x x 4 sub dup mul div}
\psframe*[linecolor=white](2,4)(6,4.3)
\end{pspicture}
\end{center}
\caption{Partial graph of $f(x)=x/(x-4)^2$. Besides the
vertical asymptote at $x=4$, note the sign change at $x=0$,
the latter being not easily discerned due to the scale being true.
(For instance, $f(-1)=-1/25=-0.04$.)}\label{x/(x-4)^2}\end{figure}

Knowing the function ``blows up''
at $x=4$, along with the sign chart, gives us the limits
from {\it both} sides.  For another example, we revisit
the function $f(x)=x/((x+1)(x-1))$ which we encountered in
Example~\ref{Example:FirstRationalInequality},
page~\pageref{Example:FirstRationalInequality}.

\bex The following limits can be found by considering the 
sign chart for the function $f(x)=x/((x+1)(x-1))$:
\begin{alignat*}{2}
\lim_{x\to-1^-}\frac{x}{(x+1)(x-1)}&=-\infty,\qquad\qquad
               &\lim_{x\to1^-}\frac{x}{(x+1)(x-1)}&=-\infty,\\
\lim_{x\to-1^+}\frac{x}{(x+1)(x-1)}&=\infty,\qquad\qquad
               &\lim_{x\to1^+}\frac{x}{(x+1)(x-1)}&=\infty,
\end{alignat*}
All of these are of forms $1/0^+$, $1/0^-$, $-1/0^+$ or $-1/0^-$,
since the numerators are approaching $\pm1$ and the denominators
are approaching zero from left or right.  Thus we have the function
``blowing up'' at $\pm1$, so we just need to know what are its
signs as we approach $\pm1$ from either side.  We repeat the
sign chart from Example~\ref{Example:FirstRationalInequality},
page~\pageref{Example:FirstRationalInequality} for convenience:
\begin{center}
\begin{pspicture}(-0.2,-1)(12,3)
\psline{<->}(2,0)(12,0)
   \psline(4.5,-.2)(4.5,.2)
      \rput(4.5,-.5){$-1$}
   \psline(7,-.2)(7,.2)
      \rput(7,-.5){$0$} 
   \psline(9.5,-.2)(9.5,.2)
      \rput(9.5,-.5){$1$}
\rput[l](-0.2,2.5){Function:}
\rput(7,2.5){$\ds{f(x)=\frac{x}{(x+1)(x-1)}}$}

\rput[l](-0.2,.5){Sign Factors:}
\rput[l](-0.2,1.5){Test $x=$}
  \rput(3.25,1.5){$-2$}
\rput(3.25,.5){$\ds{\frac{\text{\bominus}}{\text{\bominus\bominus}}}$}
  \rput(5.75,1.5){$-0.5$}
\rput(5.75,.5){$\ds{\frac{\text{\bominus}}{\text{\boplus\bominus}}}$}
  \rput(8.25,1.5){$0.5$}
\rput(8.25,.5){$\ds{\frac{\text{\boplus}}{\text{\boplus\bominus}}}$}
  \rput(10.75,1.5){$2$}
\rput(10.75,.5){$\ds{\frac{\text{\boplus}}{\text{\boplus\boplus}}}$}

\rput[l](-0.2,-.5){Sign $f(x)$:}
\rput(3.25,-.5){\bominus}
\rput(5.75,-.5){\boplus}
\rput(8.25,-.5){\bominus}
\rput(10.75,-.5){\boplus}

\end{pspicture}
\end{center}

\begin{figure}
\begin{center}
\begin{pspicture}(-5,-3)(5,3)
\psset{yunit=.2cm}
\psaxes[Dy=5]{<->}(0,0)(-5,-15)(5,15)
\psplot[plotpoints=300]{-5}{-1.0335}{x x x mul 1 sub div}
\psplot[plotpoints=300]{-.967}{.9667}{x x x mul 1 sub div}
\psplot[plotpoints=300]{1.0335}{5}{x x x mul 1 sub div}

\psline[linestyle=dashed](-1,-15)(-1,15)
\psline[linestyle=dashed](1,-15)(1,15)
\end{pspicture}\end{center}
\caption{Graph of $\ds{f(x)=\frac{x}{(x+1)(x-1)}}$. 
See Example~\ref{SignChart->VerticalAsymptoticBehavior}.}
\label{Graph:f(x)=x/((x+1)(x-1))}
\end{figure}

\label{SignChart->VerticalAsymptoticBehavior}

The graph of $f(x)=x/((x+1)(x-1))$ is given in 
Figure~\ref{Graph:f(x)=x/((x+1)(x-1))},
page~\pageref{Graph:f(x)=x/((x+1)(x-1))}.
\eex

While the sign chart can help in computing limits, its construction
is often more work than required.  If we are already building
it for some other reason, we can go ahead and use it to compute our limits
at the vertical asymptotes, but first we need to know that
there is in fact ``blow up'' as we approach those input values,
and so we need an eye to what a computation without a sign chart
would look like.
Thus, more examples of such computations are in order.
\bex Consider the following limits.
\begin{enumerate}
\item$\ds{\lim_{x\to9^+}\frac{x}{3-\sqrt{x}}
  \overset{9/{0^-}}\llongeq-\infty}$.
\item $\ds{\lim_{x\to6^-}\frac{3-2x}{x^2+2x-48}
=\lim_{x\to6^-}\frac{3-2x}{(x+8)(x-6)}
\overset{\frac{-9}{(14)(0^-)}}{\lllongeq} \infty}$
\end{enumerate}
\eex
These are fairly routine, but did use some subtlety to get the
correct signs.  In the first one, it was important to 
notice that the denominator $3-\sqrt{x}$ is negative
for $x>9$.  The second one can be thought of as
a form $\frac{-9}{14}\cdot(-\infty)=\infty$.
(It also helped to have the denominator factored.)  

It is possible that a $0/0$ form can simplify to one of these
determinate forms, as in the following example.
(We will start to use the shorthand ``=D.N.E.'' when a limit
does not exist.) 
\bex Consider the following limits. (The algebra is the same for each
     so we only show details for the first limit.)
\begin{enumerate}
\item $\ds{\lim_{x\to3}\frac{81-x^4}{(x^2-6x+9)^2}
        \zzalg\lim_{x\to3}\frac{(9-x^2)(9+x^2)}{\left[(x-3)^2
           \right]^2} 
        \overset{0/0}\longeq\lim_{x\to3}\frac{(3-x)(3+x)(9+x^2)}
       {(x-3)^4}}$
$$      \zzalg\lim_{x\to3}\frac{-(x-3)(3+x)(9+x^2)}{(x-3)^4}
        \zzalg\lim_{x\to3}\frac{-(3+x)(9+x^2)}{(x-3)^3}
       \overset{\frac{-6\cdot18}{0^\pm}}\llongeq\text{D.N.E.}$$
\item $\ds{\lim_{x\to3^+}\frac{81-x^4}{(x^2-6x+9)^2}\zzalg
        \lim_{x\to3^+}\frac{-(3+x)(9+x^2)}{(x-3)^3}
       \overset{\frac{-6\cdot18}{0^+}}\llongeq-\infty}$.
\item $\ds{\lim_{x\to3^-}\frac{81-x^4}{(x^2-6x+9)^2}\zzalg
        \lim_{x\to3^-}\frac{-(3+x)(9+x^2)}{(x-3)^3}
       \overset{\frac{-6\cdot18}{0^-}}\llongeq\infty}$.
\end{enumerate}
\eex

Considerations also need to be taken for limits involving rational
exponents.  Recall that if $a/b$ is a simplified fraction
(so we do not allow $4/6$ but do allow $2/3$, for example), then
\begin{equation}x^{a/b}=\left(x^a\right)^{1/b}=\left(x^{1/b}\right)^a.
\end{equation}
Also recall that $x^{1/b}=\ds{\sqrt[b]{x}}$. Finally,
$(x^2)^{1/2}=\sqrt{x^2}=|x|$, for instance, while $(x^3)^{1/3}
=\sqrt[3]{x^3}=x$.  As usual, the odd roots are simpler to
deal with then the even roots, at least for abstract computations.
\newpage
\bex Consider the following limits:
\begin{enumerate}
\item $\ds{\lim_{x\to-4}\frac{x}{(x+4)^{4/3}}=\lim_{x\to-4}
        \frac{x}{\left[(x+4)^4\right]^{1/3}}\overset{-4/0^+}\longeq
        -\infty}$.
\item $\ds{\lim_{x\to-4^-}\frac{x}{(x+4)^{1/3}}\overset{-4/0^-}\longeq
        \infty}$.
\item $\ds{\lim_{x\to-4^-}\frac{x}{\left[(x+4)^2\right]^{1/2}}=\lim_{x\to-4^-}
        \frac{x}{|x+4|}\overset{-4/0^+}\longeq
        -\infty}$.
\end{enumerate}
\eex
%\newpage
\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\begin{multicols}{2}
\begin{enumerate}
\item Compute $\ds{\lim_{x\to-5}\frac1{(x+5)^2}=}$
\item Suppose $\ds{f(x)=\frac{x}{x^2-1}}$. Compute:
  \begin{enumerate}
  \item $\ds{\lim_{x\to1^+}f(x)=}$
  \item $\ds{\lim_{x\to1^-}f(x)=}$
  \item $\ds{\lim_{x\to1}f(x)=}$
  \item $\ds{\lim_{x\to-1^+}f(x)=}$
  \item $\ds{\lim_{x\to-1^-}f(x)=}$
  \item $\ds{\lim_{x\to-1}f(x)=}$
  \end{enumerate}
\item Suppose $\ds{f(x)=\frac{x^2-4x+4}{x^2-4}}$. Compute:
  \begin{enumerate}
  \item $\ds{\lim_{x\to2^+}f(x)=}$
  \item $\ds{\lim_{x\to2^-}f(x)=}$
  \item $\ds{\lim_{x\to2}f(x)=}$
  \item $\ds{\lim_{x\to-2^+}f(x)=}$
  \item $\ds{\lim_{x\to-2^-}f(x)=}$
  \item $\ds{\lim_{x\to-2}f(x)=}$
  \end{enumerate}
\item Suppose $\ds{f(x)=\frac{x}{|x-3|}}$. Compute:
  \begin{enumerate}
  \item $\ds{\lim_{x\to-3}f(x)=}$
  \item $\ds{\lim_{x\to3}f(x)=}$
  \end{enumerate}
\item Suppose $\ds{f(x)=\frac{|x-3|}{x^2-9}}$. Compute:
  \begin{enumerate}
  \item $\ds{\lim_{x\to3^+}f(x)=}$
  \item $\ds{\lim_{x\to3^-}f(x)=}$
  \item $\ds{\lim_{x\to3}f(x)=}$
  \item $\ds{\lim_{x\to-3^+}f(x)=}$
  \item $\ds{\lim_{x\to-3^-}f(x)=}$
  \item $\ds{\lim_{x\to-3}f(x)=}$
  \end{enumerate}
\item Suppose $\ds{f(x)=\frac{x}{\sqrt{1-x^2}}}$.
  \begin{enumerate}
  \item Discuss all possible points $a\in\Re$ at which 
  $f(x)$ may have infinite limits as $x$ approaches
  $a$ from one side or both sides.  List all
  such limits and their values.
  \item Draw a sign chart for this function.
  \item Use all the information above to sketch a rough graph of the function.
  \end{enumerate}
\item Suppose $\ds{f(x)=\frac1{x^4-9}}$. 
  \begin{enumerate}
   \item Make a sign chart for $f(x)$.
  \item  Discuss all possible points $a\in\Re$ at which 
  $f(x)$ may have infinite limits as $x$ approaches
  $a$ from one side or both sides.  List all
  such limits and their values, using the sign chart above.
  \item Use all the information above to sketch a rough graph of the function.
  \end{enumerate}
\end{enumerate}

\end{multicols}
\newpage
\section[Sandwich, Composition, Trigonometric Continuity]{Sandwich, Composition and Trigonometric Continuity Theorems
\label{STCT}}
%\markright{\ref{STCT}\ SANDWICH, COMPOSITION, 
%TRIGONOMETRIC CONTINUITY THEOREMS}
In this section we will state the Sandwich Theorem\footnotemark
%%%% FOOTNOTE
\footnotetext{The Sandwich Theorem is also called the
Squeeze Theorem and the Pinching Theorem in other texts.}
%%%% END FOOTNOTE
and use it for computing several limits, including those
which prove that the trigonometric functions are continuous
where defined. 
% We will also state a useful basic trigonometric
%limit and use it to derive several others.  We will not
%yet prove the aforementioned trigonometric limit, leaving the actual
%proof for a later chapter when we have more calculus tools
%at our disposal (L'H\^opital's Rule, to be specific),
%but we will illustrate why it is believable geometrically.


\subsection{Sandwich Theorem}
\begin{theorem}(Sandwich Theorem) Suppose that there exists some $d>0$
such that for every $x\in(a-d,a)\cup(a,a+d)$ we have
\begin{equation}
f(x)\le g(x)\le h(x).\label{SandwichTheoremFunctionBounds}
\end{equation}
Then
$$\left(\lim_{x\to a}f(x)=L\right)\wedge
\left(\lim_{x\to a}h(x)=L\right)
\implies \lim_{x\to a}g(x)=L.$$
\label{SandwichTheoremStatement}\end{theorem}
The idea is that $f$ and $h$ ``sandwich'' $g$ between them, and so if
$f$ and $h$ both approach $L$, then $g$ has nowhere to go
but $L$.  This is graphed for two cases in 
Figure~\ref{SandwichTheoremFigure},  where $L$ first is
a finite real number,  and then where $L=\infty$.
\begin{figure}
\begin{center}
\begin{pspicture}(-1,-1)(4.4,5)
\psaxes[labels=none,ticks=none]{<->}(0,0)(-1,-1)(4,5)
\psplot{1}{4}{x 2.5 sub dup mul .6 mul 3 add}
\psplot{1}{2.5}{x 2.5 sub 1.4 mul 3 add}
\psplot{2.5}{4}{x 2.5 sub -1.4 mul 3 add}
\psplot[linecolor=gray]{1}{2.5}{x 2.5 sub .5 mul 3 exp 3 mul  3 add} 
\psplot[linecolor=gray]{2.5}{4}{x 2.5 sub .5 mul 3 exp   3 add} 
\pscircle[fillstyle=solid,fillcolor=white](2.5,3){.1}
\psline(-.2,3)(.2,3)
  \rput(-.4,3){$L$}
\psline(2.5,-.2)(2.5,.2)
  \rput(2.5,-.4){$a$}
\rput[Bl](4.2,1){$f(x)$}
\rput[Bl](4.2,3.3){$g(x)$}
\rput[Bl](4.2,4.4){$h(x)$}
\end{pspicture}\qquad\qquad
\begin{pspicture}(-1,-1)(4.5,5)
\psaxes[labels=none,ticks=none]{<->}(0,0)(-1,-1)(4,5)
\psline[linestyle=dashed](2.5,0)(2.5,5)
\psplot{1}{2.25}{-1 x 2.5 sub  div 1 add}
\psplot{2.75}{4}{1 x 2.5 sub div 1 add}

\psplot{1}{2.46}{1 x 2.5 sub -1 mul .5 exp div}
\psplot{2.54}{4}{1 x 2.5 sub .5 exp div}

\psplot[linecolor=gray]{1}{2.3654}{1 x 2.5 sub -1 mul .75 exp div .5 add}
 \psplot[linecolor=gray]{2.6346}{4}{1 x 2.5 sub  .75 exp div .5 add}
\psline(2.5,-.2)(2.5,.2)
  \rput(2.5,-.4){$a$}
\rput[Bl](4.2,.7){$f(x)$}
\rput[Bl](4.2,1.15){$g(x)$}
\rput[Bl](4.2,1.6){$h(x)$}
\end{pspicture}
\end{center}
\caption{Examples illustrating the Sandwich Theorem.  In both
cases,  $f(x)\le g(x)\le h(x)$ near $x=a$, i.e., 
for some set $0<|x-a|<\delta$, some $\delta>0$.  Since the
limits, as $x\to a$, of $f(x)$ and $h(x)$ are the same
($L$ and $+\infty$ for the respective graphs), 
the function  $g(x)$ must also have the same limit as $x\to a$.}
\label{SandwichTheoremFigure}
\end{figure}
The functions $f(x)$ and $h(x)$ can be
thought of as variable lower and upper {bounds} for the function $g(x)$ 
in between by  (\ref{SandwichTheoremFunctionBounds}).  Thus the
behavior of $f(x)$ and $h(x)$ can, in some circumstances (as
in the theorem) force behavior upon $g(x)$.
The logic of the argument for the theorem is often graphed in various ways.
We will employ the style of Figure~\ref{FigureForStatementOfSandwichTheorem},
page~\pageref{FigureForStatementOfSandwichTheorem} to illustrate our arguments,
except that we will not include the labels 
``(Hypothesis)'' and ``(Conclusion),'' as they will become apparent in 
context.

\begin{figure}
\begin{center}
\begin{pspicture}(-2,-3)(5,.5)
\rput[r](0,.1){(Hypothesis) As $x\to a$:}
\rput(2.5,0){$\ds{\underbrace{f(x)}\ \le\ g(x)\ \le\ \underbrace{g(x)}}$}
\psline{->}(1.14,-.4)(1.14,-1.7)
\psline{->}(3.87,-.4)(3.87,-1.7)
\rput(1.14,-2){$L$}
\rput(3.87,-2){$L$}
\rput[r](0,-3){(Conclusion):}
\rput(2.5,-3){$\therefore g(x)\longto L$}
\end{pspicture}
\end{center}
\caption{Figure illustrating the argument for the Sandwich Theorem.}
\label{FigureForStatementOfSandwichTheorem}
\end{figure}





There are several variations of the Sandwich Theorem, in which
behavior of one or more {\it bounding functions} $f(x)$ and $h(x)$
can force behavior upon
a (variably) {\it bounded}  function $g(x)$.  These variations
are perhaps most clearly seen by graphing their respective
situations.  For instance,
it is easily seen that we can replace $f(x)\le g(x)\le h(x)$
with $f(x)<g(x)<h(x)$ (see again Figure~\ref{SandwichTheoremFigure} 
at the beginning of this section).\footnotemark
%% FOOTNOTE
\footnotetext{Note that $f(x)<g(x)<h(x)\implies
f(x)\le g(x)\le h(x)$, so the fact that we can 
replace the latter with the former follows quickly from
logic; if we have the strict inequalities, then we
also have the non-strict inequalities and that hypotheses
of the Sandwich Theorem will still hold.}
%% END FOOTNOTE
One-sided versions of the theorem also hold, as in for
instance  the left-sided limit version:
\begin{align*}
\left(\vphantom{\lim_{x\to a^-}}
(\exists d>0)(\forall x)\left[\vphantom{X_X^X}
 x\in(a-d,a)\right.\right.
&\longrightarrow
\left.\vphantom{\lim_{x\to a^-}}
\left.\vphantom{X^X_X} f(x)\le g(x)\le h(x)\right]\right)
\wedge \left(\lim_{x\to a^-}f(x)=L=\lim_{x\to a^-}h(x)\right)
\\
&\implies \lim_{x\to a^-}g(x)=L.\end{align*}


The following limit is a very traditional example
for the original statement of the Sandwich Theorem.
Note that it relies on the fact that $\sin\theta$ is defined
for every $\theta\in\Re$, and that $-1\le\sin\theta\le1$.
\begin{figure}
\begin{center}
\begin{pspicture}(-6,-3)(6,3.5)
\psset{xunit=3cm,yunit=3cm}
\psaxes[labels=none,ticks=none]{<->}(0,0)(-1,-1)(1,1)
\psplot[linewidth=.3pt,plotpoints=1000]%
{-1}{-.05}{x 1 x div 3.14159265 div 180 mul sin mul}
\psplot[linewidth=.3pt,plotpoints=1000]%
{-.05}{-.02}{x 1 x div 3.14159265 div 180 mul sin mul}
\psplot[linewidth=.3pt,plotpoints=1000]%
{-.02}{-.01}{x 1 x div 3.1415926536 div 180 mul 11880 add  sin mul}

\psplot[linewidth=.3pt,plotpoints=1000]%
{.05}{1}{x 1 x div 180 mul 3.14159265 div sin mul}
\psplot[linewidth=.3pt,plotpoints=1000]%
{.01}{.02}{x 1 x div 180 mul 11880 sub 3.14159265 div sin mul}
\psplot[linewidth=.3pt,plotpoints=1000]%
{.02}{.05}{x 1 x div 180 mul 11880 sub 3.14159265 div sin mul}
\psplot{-1}{1}{x}
\psplot{-1}{1}{x  -1 mul}
\rput[Bl](1.1,-1){$f(x)=-|x|$}
\rput[Bl](1.1,1.1){$h(x)=|x|$}
\rput[Bl](1.1,.8){$g(x)=x\sin\frac1x$}
\end{pspicture}
\end{center}
\caption{Partial graph of $\ds{g(x)=x\sin\frac1x}$, which is bounded
from above by $h(x)=|x|$ and from below by $f(x)=-|x|$.
It oscillates wildly, running through infinitely many periods
in the argument $1/x$ of the sine function as $x\to0$, but is
bounded in amplitude by functions which shrink to zero
as $x\to0$.  ($g(x)$ is undefined at $x=0$ but that fact is not
apparent in the graph above.)}
\label{XSin1/X}
\end{figure}
%\newpage




\bex Compute the limit $\ds{\lim_{x\to0}x\sin\frac1x}$.


\underline{Solution}: Note that $x\in\left\{\vphantom{\frac11}
         -|x|,|x|\,\right\}$ while $\sin\frac1x\in[-1,1]$.
         Looking at all four ``extreme-case'' scenarios for
         the outputs of $x\sin\frac1x$ (positive or negative),
         we can conclude that
         $x\sin\frac1x\in\left[\vphantom{\frac11}
         -|x|,|x|\,\right]$, that is,
\begin{equation}{-|x|}\le x\sin\frac1x\le|x|.\footnotemark
%%% FOOTNOTE
\footnotetext{We can make the argument leading to (\ref{BoundsForXSin1/X})  
more precise.  For $x\ne 0$, we can say
\begin{align*}
&\hphantom{\implies}\left|x\sin\frac1x\right|=|x|\cdot\left|\sin\frac1x\right|
                         \le|x|\cdot1=|x|,\\
&\implies\left|x\sin\frac1x\right|\le|x|\\
&\iff -|x|\le x\sin\frac1x\le|x|,\end{align*}
where the ``$\iff$'' comes from the general rule that
$|z|\le K\iff-K\le z\le K$.
}
\label{BoundsForXSin1/X}
\end{equation} 
         By continuity of $|x|$ and $-|x|$, we have
         $$\lim_{x\to0}\left(-|x|\right)=-|0|=0, \qquad 
         \text{and}\qquad\lim_{x\to0}|x|=|0|=0,$$
         so by the Sandwich Theorem we must conclude as well that
         $$\lim_{x\to0}x\sin\frac1x=0.$$
\label{GreatSandwichTheoremExample}\eex
The Sandwich Theorem argument for the limit of 
Example~\ref{GreatSandwichTheoremExample}
above can be summarized graphically as follows:

\begin{center}
\begin{pspicture}(-3,.7)(4.5,4.5)
\rput[l](-3,4.2){As $x\to0$:}
\rput(0,4){$\ds{\underbrace{-|x|}}$}
  \rput(1,4.2){$\le$}
\rput(2,4.2){$x\sin\frac1x$}
  \rput(3,4.2){$\le$}
\rput(4,4){$\ds{\underbrace{|x|}}$}
\psline{->}(0,3.7)(0,2.3)
\psline{->}(4,3.7)(4,2.3)
 \rput(0,2){0}
 \rput(4,2){0}
\rput[l](-3,1.2){$\therefore x\sin\frac1x\longrightarrow0$.}
\end{pspicture}
\end{center}













The function $g(x)=x\sin\frac1x$ is graphed in Figure~\ref{XSin1/X} above,
together with the
bounding functions $-|x|$ and $|x|$.  It  has some interesting features
which make it very valuable for later examples which 
clarify some limit principles.
We note how the 
argument $1/x$ of the sine function here runs through infinitely
many periods of sine as $x\to0$, so the function oscillates
with infinitely increasing rapidity as $x\to0$.  
However the ``amplitude'' $|x|$ is variable and shrinking to
zero. 

One use of the above function is in illustrating a rather general theorem,
based upon the Sandwich Theorem, regarding limits of products
where one factor approaches zero while the other factor,
however else it is ill-behaved, is at least bounded and
defined as we approach the limit point.

\begin{theorem}Suppose that $f(x)$ is defined for $0<|x-a|<d$
for some $d>0$, and that for such $x$, $f(x)$ is of the form
$f(x)=g(x)h(x)$ where $|g(x)|\le M$ and $h(x)\longto0$ as $x\to a$.
Then $\ds{\lim_{x\to a}f(x)=0}$.\end{theorem}
The proof consists of noting that $-M|h(x)|\le f(x)\le M|h(x)|$,
so $\pm M|h(x)|\longto 0$ as $x\to a$ implies $f(x)\longto 0$
as $x\to a$ as well:

\begin{center}
\begin{pspicture}(-3,.7)(4.5,4.5)
\rput[l](-3,4.2){As $x\to a$:}
\rput(0,4.1){$\ds{\underbrace{-M|h(x)|}}$}
  \rput(1,4.2){$\le$}
\rput(2,4.2){$g(x)h(x)$}
  \rput(3,4.2){$\le$}
\rput(4,4.1){$\ds{\underbrace{M|h(x)|}}$}
\psline{->}(0,3.7)(0,2.3)
\psline{->}(4,3.7)(4,2.3)
 \rput(0,2){0}
 \rput(4,2){0}
\rput[l](-3,1.2){$\therefore f(x)=g(x)h(x)\longrightarrow0$.}
\end{pspicture}
\end{center}

This theorem could have been used in the previous
example to compute that limit immediately.
We will have more use for this theorem in the next section.
For instance, there we will use ``$B$'' to refer to a function
which is defined and {\it bounded} as we approach the limit point.
Then we point out that ``$B\cdot0$'' is in fact a {\it determinate} form which
yields zero in the limit.  For the previous example, we would
note the fact that for $x\ne0$ we have $\left|\sin\frac1x\right|\le1$
and so, aside from being defined, $\sin\frac1x$ is bounded as $x\to0$,
and we can write
$$\lim_{x\to0}x\sin\frac1x\overset{0\cdot B}{\longeq}0.$$
While based upon the Sandwich Theorem, the above argument
is somewhat intuitive and certainly more concise.


\subsection{``Approaches'' for Independent Versus Dependent Variables
\label{SubsectionOnIdeaOfApproach}}
This was not such an important issue before (though a reader might
have wondered about this point), so it was deferred until now,
and give this point its own subsection to be sure it is emphasized.

So we just take a moment here
to point out that when we consider the {\it independent}
variable $x$ ``approaching'' some point, say $x\longrightarrow a$, 
we should visualize it 
gradually getting closer to that point $a$---as close as we like and
then even closer---but never actually achieving the value $x=a$.
That is built into, for instance, the definition of limit in the antecedant
$0<|x-a|<\delta$.
On the other hand, we have more flexibility in the consequent
$|f(x)-L|<\epsilon$, though we still write
$f(x)\longrightarrow L$.  For instance, in our latest example,
$x\sin\frac1x\longrightarrow0$, and in fact that function
not only go closer to zero consistently, but also achieved the
value zero (infinitely many times!) as $x\to0$.  So the independent
variable is force to approach {\it and avoid} its limiting
value, but the dependent variable need not actually avoid its
limiting value.

For another, rather trivial
example, consider that $f(x)=0\cdot\sin x\longrightarrow
0$ as $x\to\frac{\pi}2$.  In fact, $f(x)=0$ for all $x\in\Re$,
so the function not only approaches zero, it is never anything but
zero.  Still we use the notaition $f(x)\longrightarrow0$.















\subsection{``Sandwiching'' From One Side}

Occasionally  one only needs one bounding function in an
infinite limit case, to have a valid Sandwich Theorem-type argument
(recalling that $\pm\infty$ can always be considered ``bounds'').
In (\ref{fboundh}) below, $f$ is the bounding function pushing $h$, while in
(\ref{hboundf}) $h$ is the bounding function pushing $f$.
\begin{theorem} Suppose $f(x)\le h(x)$ on $0<|x-a|<d$
for some $d>0$.  Then (separately) we have
\begin{align}
\lim_{x\to a}f(x)=\infty&\implies \lim_{x\to a}h(x)=\infty,\label{fboundh}\\
\lim_{x\to a}h(x)=-\infty&\implies \lim_{x\to a}f(x)=-\infty.\label{hboundf}
\end{align}
\end{theorem}
In other words, if the lesser (lower) function blows up towards $\infty$,
then so must the greater (upper) function, while if the greater function
has blowup towards $-\infty$, then so must the lesser function.
Such arguments can be verified easily by graphing
the situations and seeing how the ``blowup'' of one function
can force a similar behavior of another.  It is also useful to see
graphing style of the {\it arguments} of (\ref{fboundh}) and
(\ref{hboundf}):

%\begin{multicols}{2}
\begin{center}
\begin{pspicture}(0,-3.2)(4,.5)
\rput[l](0,.2){As $x\to a$:}
\rput(3,0){$\ds{\underbrace{g(x)}\ \le\ {h(x)}}$}

\psline{->}(2.31,-.4)(2.31,-1.7)
\rput(2.31,-2.3){$\infty$}
\rput(2,-3){$\therefore h(x)\longrightarrow\infty$}

\end{pspicture}
\qquad\qquad\qquad\qquad
\begin{pspicture}(0,-3.2)(4,.5)
\rput[l](0,.2){As $x\to a$:}
\rput(3,0){$\ds{{f(x)}\ \le\ \underbrace{h(x)}}$}

\psline{->}(3.7,-.4)(3.7,-1.7)
\rput(3.7,-2.3){$-\infty$}
\rput(2,-3){$\therefore f(x)\longrightarrow-\infty$}


\end{pspicture}
\end{center}
%\end{multicols}




  Of course we
always have to be careful.  For instance,
suppose $f(x)\le h(x)$ and $h(x)\longto\infty$.  It is
not necessarily the case that $f(x)\longto\infty$ as
well, since $h(x)$ is above $f(x)$, and thus unable to
``push'' $f(x)$ up with it.

\bex Compute $\ds{\lim_{x\to2^+}\frac{x^2+\sin x}{x-2}}$.

\underline{Solution}: Since $-1\le\sin x\le 1$, and 
for $x>2$ we have $x^2>0$, $x-2>0$ we can write
\begin{equation}
\underbrace{\frac{x^2-1}{x-2}}_{\text{``$f(x)$''}}
\le\underbrace{\frac{x^2+\sin x}{x-2}}_{\text{``$g(x)$''}}
\le\underbrace{\frac{x^2+1}{x-2}}_{\text{``$h(x)$''}}.
\label{SandwichTheoremInfiniteExample}\end{equation}
In other words, the least that $\frac{x^2+\sin x}{x-2}$ can
be as $x\to2^+$ is $\frac{x^2-1}{x-2}$, i.e., where
$\sin x=-1$, and the greatest it
can be is $\frac{x^2+1}{x-2}$, the case where $\sin x=1$.
Next we notice that
$$\lim_{x\to2^+}\frac{x^2-1}{x-2}\overset{3/0^+}{\longeq}\infty,
\qquad\qquad
\lim_{x\to2^+}\frac{x^2+1}{x-2}\overset{5/0^+}{\longeq}\infty,$$
and so $\ds{\lim_{x\to2}\frac{x^2+\sin x}{x-2}=\infty}$ 
as well.\footnotemark
\label{FirstSandwichTheoremExample}\eex
\footnotetext{%
%%% FOOTNOTE
After the next subsection, where we prove trigonometric functions
continuous where defined, the limit in 
Example~\ref{FirstSandwichTheoremExample}
can be done directly:
$$\lim_{x\to2^+}\frac{x^2+\sin x}{x-2}\overset{\frac{4+\sin 2}{0^+}}{\llongeq}
\infty,$$
since $x^2+\sin x\longto 4+\sin2>0$.  Though not necessary here, it 
is perhaps easier to see we have the correct sign if we note
that $\sin2\approx0.909297426$, and thus
$x^2+\sin x\longto4+\sin2\approx4.909297426$.  
(The sign of $x^2+\sin 2$ was going to
be positive as $x\to2$ anyways because $\sin2\in[-1,1]$, while $x^2\longto4$.)
}
%%% END FOOTNOTE
As noted before,  the first inequality in 
(\ref{SandwichTheoremInfiniteExample}) is in fact enough to ``push'' the
desired limit to be $\infty$:
\begin{center}
\begin{pspicture}(-4,-3)(4,.5)
\rput[l](-4,.2){As $x\to 2^+$:}
\rput[r](3,0)%
{$\ds{\underbrace{\frac{x^2-1}{x-2}}\ \le\ \frac{x^2+\sin x}{x-2}}$}

\psline{->}(.25,-.7)(.25,-2)
\rput(.25,-2.3){$\infty$}
\rput[r](4,-3){$\ds{\therefore \frac{x^2+\sin x}{x-2}\longto\infty}$}

\end{pspicture}
\end{center}

In fact the example above will not need this Sandwich Theorem-type
argument if
we note that $\sin2\approx0.909297426>0.9$.  That is because we
could have written
$$\lim_{x\to2^+}\frac{x^2+\sin x}{x-2}
=\lim_{x\to2^+}\left[\frac{x^2}{x-2}+\frac{\sin x}{x-2}\right]
\overset{\frac{4}{0^+}+\frac{\sin 2}{0^+}}{\underset{\infty+\infty}{\lllongeq}}
\infty.$$
This used the fact that, as a form, $\infty+\infty$ yields
limits which are $\infty$, as we will note in later sections
and should be intuitive now.
That does not mean we can avoid using such arguments altogether
(recall our first example, $x\sin\frac1x\longto 0$ as $x\to0$).
A small change makes the case for such a method:
consider a similar limit but where the numerator of the function
is now $x^2-\sin2$.  Then we still have
$$\lim_{x\to2^+}\frac{x^2+\sin x}{x-2}
=\lim_{x\to2^+}\left[\frac{x^2}{x-2}+\frac{\sin x}{x-2}\right]
\overset{\frac{4}{0^+}-\frac{\sin 2}{0^+}}{\underset{\infty-\infty}{\lllongeq}}
?,$$
that is, $\infty-\infty$ form which is indeterminate
(first discussed properly on 
page~\pageref{FirstOfficialInstanceOfInfty-Infty}).
However the earlier Sandwich Theorem-type argument still applies,
since $-\sin x\in[-1,1]$:
\begin{center}
\begin{pspicture}(-4,-3)(4,.5)
\rput[l](-4,.2){As $x\to 2^+$:}
\rput[r](3,0)%
{$\ds{\underbrace{\frac{x^2-1}{x-2}}\ \le\ \frac{x^2-\sin x}{x-2}}$}
\psline{->}(.22,-.7)(.22,-2)

%\psline{->}(.25,-.7)(.25,-2)
\rput(.22,-2.3){$\infty$}
\rput[r](4,-3){$\ds{\therefore \frac{x^2-\sin x}{x-2}\longto\infty}$}
\end{pspicture}
\end{center}
In fact the above limit still does not require the Sandwich Theorem-type
argument if it is noticed that $x^2-\sin x\longrightarrow 4-0.909297426>0$,
but with practice it is a reasonably quick argument leading to the
conclusion that the limit is in fact $\infty$.





\subsection{Limits with Compositions of Functions}

\begin{theorem} Suppose that, for some limiting behavior of $x$, we
have $g(x)\longto L$, and $f(x)$ continuous at $x=L$.  Then
for the same limiting behavior of $x$ we have
$f(g(x))\longto f(L)$.
\label{LimitOfCompositionOfFunctionsTheorem}\end{theorem}
So for instance, if $f(x)$ is continuous at $L$ and
$\ds{\lim_{x\to a}g(x)=L}$, then
$$\lim_{x\to a}f(g(x))=f(L),$$
i.e., 
\begin{equation}
\lim_{x\to a}f(g(x))=f\left(\lim_{x\to a}g(x)\right)=f(L).
\label{BadIdeaForMovingLimitInside}\end{equation}
In other words, if the limit of the ``inside'' function is
a point of continuity of the ``outside'' function, then
we can ``move the limit notation (lim) inside.''

In fact in the interest of avoiding errors 
students are often discouraged from using
(\ref{BadIdeaForMovingLimitInside}) as it is written.
One reason is that it is crucial that $f$ be continuous 
at the limit of $g$, or
the theorem is false, as we will show in the exercises,
while reading (\ref{BadIdeaForMovingLimitInside}) without
context may give
the impression that we can always move the limit inside.
Instead we will concentrate on the theorem itself,
and the limit forms which arise from its proper application.
Still, the theorem is very general in terms of the type of limit
(basic, left, right or the ``at infinity'' variety we will have
in Section~\ref{LimitsAtInfinitySection}).  We will give a 
proof for the most basic case at the end of this section.
That proof will be a simple modification of the proof
of
Theorem~\ref{CompositionOfContinuousFunctionsIsContinuous},
page~\pageref{CompositionOfContinuousFunctionsIsContinuous}.
The theorem can be illustrated graphically as follows:
\begin{center}
\begin{pspicture}(-2,-2.5)(7,.5)
\rput[l](-2,0){As $x\to a$:}
\rput(1,-.1){$\ds{f(\,\underbrace{g(x)}\,)}$}
\psline{->}(2,0)(6,0)
\rput(4,.3){$\therefore$ (by continuity)}
%\rput(4,-.3){(continuity of $f$)}
\rput(7,0){$f(L)$}
\psline{->}(1.1,-.5)(1.1,-1.5)
\rput(1.1,-1.8){$L$}
\end{pspicture}
\end{center}
Again, the diagram above is not necessarily true if $f(x)$ is
not continuous at $x=L$.  When $f$ is, we might not always give
the justification ``(by continuity)'' within the diagram.


\bex Suppose that $\ds{\lim_{x\to a}g(x)=12}$, while 
                  $\ds{\lim_{x\to b}g(x)=0}$.
Then
\begin{itemize}
\item $\ds{\lim_{x\to a}\sqrt[3]{g(x)}\overset{\sqrt[3]{12}}{\llongeq}%
\sqrt[3]{12}}$,
\item $\ds{\lim_{x\to b}\sqrt[3]{g(x)}\overset{\sqrt[3]0}{\longeq}%
\sqrt[3]{0}=0}$,
\item $\ds{\lim_{x\to a}\sqrt{g(x)}\overset{\sqrt{12}}{\llongeq}%
\sqrt{12}=2\sqrt3}$,
\item $\ds{\lim_{x\to b}\sqrt{g(x)}}$ cannot be determined
      by the given information.  It depends upon how
      $g(x)$ approaches $0$ as $x\to b$: 
  \begin{itemize}
      \item If $g(x)\to 0^+$
      then $\ds{\lim_{x\to b}\sqrt{g(x)}=\sqrt0=0}$:
        $\ds{\lim_{x\to b}\sqrt{g(x)}\overset{\sqrt{0^+}}{\llongeq}%
             \sqrt0=0}$.
      \item In fact, if we just have $g(x)\ge 0$ as $x\to b$, we
            have the limit being $\sqrt{0}=0$.
      \item However, if $g(x)\to 0^\pm$, then
      $\ds{\lim_{x\to b}\sqrt{g(x)}\overset{\sqrt{0^{\pm}}}{\llongeq}}$
       does not exist.
  \end{itemize}
\end{itemize}

\eex
In the first two limits above, we have $g(x)\longto12$ or $0$, which
are well-within the set on which  $\sqrt[3]{x}$
is  continuous, namely $\Re$.
For the third limit above, we 
recall that 
$\sqrt{x}$ is continuous for $x>0$, and so 
$g(x)\longto12\implies\sqrt{g(x)}\longto\sqrt{12}$.  
Since $\sqrt{x}$ is defined for
$x\ge0$, and is in fact right-continuous at $x=0$, it is 
possible that if $g(x)\to0$,
then $\lim_{x\to b}\sqrt{g(x)}$ is zero or does not exist.
The right-continuity of $\sqrt{x}$ at $x=0$ guarantees that
$\sqrt{g(x)}\longto0$ if $g(x)\to0^+$, but does not exist if
$g(x)$ is sometimes negative as $x\to b$.






This theorem will prove to be more useful---and in fact will be
crucial---in later sections, but we will make some use of it
in this section as an alternative method for some limit computations
for which earlier methods are not quite as efficient.


\subsection{Continuity of Trigonometric Functions}

Our theorem is as follows:
\begin{theorem}
The six basic trigonometric functions, $\sin x$, $\cos x$, 
$\tan x$, $\cot x$, $\sec x$ and $\csc x$ are continuous
everywhere they are defined.  Thus
\begin{enumerate}
\item $\sin x$ and $\cos x$ are continuous for $x\in\Re$.
\item $\tan x$ and $\sec x$ are continuous {\bf except} where $\cos x=0$,
      and  are thus continuous for all
       $$x\in\Re-\left\{\frac{\pm \pi}2,\frac{\pm3\pi}2,
            \frac{\pm5\pi}{2},\cdots\right\}.$$
\item $\cot x$ and $\csc x$ are continuous {\bf except} where $\sin x=0$,
      and  are thus continuous for all
      $$x\in\Re-\{0,\pm\pi,\pm2\pi,\pm3\pi,\cdots\}.$$
\end{enumerate}
\label{TrigFunctionsContinuousWhereDefinedTheorem}\end{theorem}

Considering the unit circle definitions of $\sin\theta$ and $\cos\theta$,
it is reasonable that these are continuous (as functions of $\theta$).
The continuity of the other trigonometric functions,  where
they are defined, then follows immediately.
Because the result of 
Theorem~\ref{TrigFunctionsContinuousWhereDefinedTheorem}
is intuitive, we will defer the proof until the end of the section.
The proof uses the sandwich theorem and a geometric argument,
and is interesting in its own right, but for now we will 
investigate {\it applications} of the theorem. 






\bex The following limits follow directly from continuity
of the trigonometric functions (where defined):
\begin{itemize}
\item $\ds{\lim_{x\to\pi}\sin x=\sin\pi=0}$.
\item $\ds{\lim_{x\to\pi/4}\tan x=\tan\frac{\pi}4=1}$.
\item $\ds{\lim_{x\to\sqrt{\pi}}\cos x^2=\cos\left(\sqrt\pi\right)^2
         =\cos\pi=-1}$.
\end{itemize}
The last limit above was so computable since $x^2$ is continuous 
on all of $\Re$, and so is $\cos x$, so the composition
$x\longmapsto x^2\longmapsto \cos x^2$ is continuous on all of $\Re$,
including $x=\sqrt\pi$
(see Theorem~\ref{CompositionOfContinuousFunctionsIsContinuous},
page~\pageref{CompositionOfContinuousFunctionsIsContinuous}).
\eex
In the last example above, the cosine function
was the ``outer'' function, but the trigonometric functions can 
be combined with other functions in a variety of ways.
\bex Consider the following limit computations.
\begin{itemize}
\item $\ds{\lim_{x\to\frac{\pi}2}\frac{1-\sin^2x}{\cos x}
\overset{0/0}{\longeq}\lim_{x\to\frac{\pi}2}\frac{\cos^2x}{\cos x}
\overset{0/0}{\longeq}\lim_{x\to\frac{\pi}2}\cos x=\cos\frac{\pi}2=0}$.
\item $\ds{\lim_{x\to0}\sqrt{1-\underbrace{\cos^2x}_{<1}}
\overset{\sqrt{0^+}}{\longeq}\sqrt{1-\cos^20}=\sqrt{1-1^2}
         =\sqrt0=0}$.
\end{itemize}
The first was a standard $0/0$-form simplification using the 
trigonometric identity $\cos^2x+\sin^2x=1$.  The second relied
upon the fact that $\cos^2\theta<1$ as $x\to0$.
In fact it was enough that $\cos x\in[-1,1]$, so $\cos^2x\in[0,1]$
and so, though we are only interested in behavior as we approach
zero, in fact the expression inside the square root, 
$1-\cos^2x$ is never negative (and is everywhere continuous):
$\Re\overset{\cos x}{\longto}[-1,1]\overset{x^2}{\longto}[0,1]
\overset{1-x}{\longto}[0,1]$.
\eex


\bex Consider the following limit computation.
Note that since $0/0$ is indeterminate, so is $\sin\frac00$.
\begin{align*}
\lim_{x\to3}\sin\left(\frac{x^2-9}{x^2-5x+6}\right)
&\overset{\sin\frac00}{\llongeq}
\lim_{x\to3}\sin\left(\frac{(x+3)(x-3)}{(x-2)(x-3)}\right)
\overset{\sin\frac00}{\llongeq}
\lim_{x\to3}\sin\left(\frac{x+3}{x-2}\right)\\
&
=\sin\frac{3+3}{3-2}=\sin6\approx-0.279415498.\end{align*}
Since $0/0$-form is indeterminate, any ``function'' of it 
is also, so we have to deal with the argument (``inside'')
of the sine function.  Of course the {\bf exact} answer
is $\sin6$, but one is naturally curious about what
is the approximate value of this limit so a nine-digit
approximation is also included.
\label{LimitOfSineOfSomethingUgly-I}\eex

In Theorem~\ref{LimitOfCompositionOfFunctionsTheorem},
page~\pageref{LimitOfCompositionOfFunctionsTheorem} we
had an alternative method for analyzing the previous
example's limit:
we could instead exploit the everywhere-continuity of the sine function
to allow manipulations such as
$$\lim_{x\to3}\sin\left(\frac{x^2-9}{x^2-5x+6}\right)
=\sin\left(\lim_{x\to3}\frac{x^2-9}{x^2-5x+6}\right)
=\cdots=\sin6.$$
We will usually opt for the first method---as in 
Example~\ref{LimitOfSineOfSomethingUgly-I} above---where possible
for reasons stated previously.\footnotemark
%%% FOOTNTOE
\footnotetext{Many textbooks prescribe exactly this
second method (not preferred here) for
such a problem.  Instead we solved it by replacing
the original function with one which was continuous at 
$x=3$, and were thus able to call upon 
Theorem~\ref{f=gLimitTheorem}, page~\pageref{f=gLimitTheorem}.
We will require this alternative kind of 
manipulation later, particularly with limits
``at infinity,'' but we will otherwise usually avoid it when possible
because it requires very specific hypotheses.
It is acceptable here since
we know that if the limit inside exists and is finite, then the sine
function is continuous there (since it is continuous everywhere!).
We need more care if the outer function is not continuous on all of $\Re$.}
%%% END FOOTNOTE
% Graphically, this method can be illustrate by the following diagram:
% 
% \begin{center}
% \begin{pspicture}(-6,0)(6,5)
% \rput(-6,4){As $x\to3$,}
% \rput(-3,3){$\ds{\sin\left(\frac{x^2-9}{x^2-5x+6}\right)
%                  =\sin\underbrace{\left(\frac{x+3}{x-2}\right)}}$}
% \psline{->}(0,3.1)(2,3.1)
% \rput(2.8,3.1){$\sin6$}
% \psline{->}(-1.08,2.3)(-1.08,1)
% 
% \rput(-1.08,.7){6}
% \end{pspicture}
% \end{center}
% 
% 
% \bex Consider the following limit computation:
% $$\lim_{x\to\infty}\cos\frac1x\overset{\cos\frac1\infty}{\llongeq}
%       \cos 0=1.$$
% Here, we are not able to replace the
% function $\cos\frac1x$ with one which is defined at the limit point, since
% the limit point is $\infty\not\in\Re$.  However, cosine is
% certainly continuous at $x=0$, which is the limit of
% $1/x$ as $x\to\infty$.\footnote{
% %%%% FOOTNOTE
% In Subsection~\ref{LimitsBySubstitutionSubsection} we will
% make the substitution $\theta=1/x$, so that
% $x\to\infty\iff\theta\to0^+$, and then write
% $$\lim_{x\to\infty}\cos\frac1x
% =\lim_{\theta\to0^+}\cos\theta=\cos0=1.$$
% Such a method will prove to be very attractive, but
% we will have to be very careful to use it correctly.
% %%%% END FOOTNOTE
% }
% \eex







Trigonometric functions can also give rise to infinite-valued limits.
In such cases
it is crucial to determine from within which quadrant the argument of
the function is approaching the limit point, and thus the sign of
the trigonometric functions.
If the argument is $x$, then $x\to0^+$ means the ``angle'' $x$ approaches
zero from within the first quadrant (where $x$ is the 
measure of an angle in standard position).
For $x\to\pi^+$, we have $x$ approaching $\pi$ from
angles with measure slightly greater than $\pi$, i.e., from the
third quadrant.  For $x\to{\frac{\pi}2}^+$, we are in the second
quadrant, and so on. See 
Figure~\ref{CircleForSignsOfTrigFunctionsAsApproachAngles},
page~\pageref{CircleForSignsOfTrigFunctionsAsApproachAngles}
where the part of ``$x$'' is played by the angle
$\theta$.

\begin{figure}
\begin{center}
\begin{pspicture}(-4,-3)(4,3)
\psset{xunit=2cm,yunit=2cm}
\psaxes[ticks=none,labels=none]{<->}(0,0)(-1.3,-1.3)(1.3,1.3)
\rput(0,1.45){$\pi/2$}
\rput(0,-1.45){$3\pi/2$}
%\rput(1.3,.15){0}
%\rput(1.3,-.15){$2\pi$}
\rput(-1.45,0){$\pi$}
\pscircle(0,0){2}
  \psarc[linewidth=2.5pt]{->}(0,0){2}{55}{90}
  \rput{-20}(.5,1.05){$\theta\to{\frac{\pi}{2}}^-$}
  \psarc[linewidth=2.5pt]{<-}(0,0){2}{90}{125}
  \rput{20}(-.45,1.08){$\theta\to{\frac{\pi}{2}}^+$}
  \psarc[linewidth=2.5pt]{->}(0,0){2}{145}{180}
  \rput{70}(-1.08,.4){$\theta\to\pi^-$}
  \psarc[linewidth=2.5pt]{<-}(0,0){2}{180}{215}
  \rput{110}(-1.08,-.4){$\theta\to\pi^+$}
  \psarc[linewidth=2.5pt]{->}(0,0){2}{235}{270}
  \rput{-20}(-.4,-1.1){$\theta\to{\frac{3\pi}{2}}^-$}
  \psarc[linewidth=2.5pt]{<-}(0,0){2}{270}{305}
  \rput{20}(.45,-1.08){$\theta\to{\frac{3\pi}{2}}^+$}
  
  \psarc[linewidth=2.5pt]{<-}(0,0){2}{0}{35}
  \rput{-70}(1.08,.4){$\theta\to0^+$}
  \rput{-70}(1.3,.4){$\theta\to2\pi^+$} 

  \psarc[linewidth=2.5pt]{->}(0,0){2}{325}{360}
  \rput{70}(1.08,-.4){$\theta\to0^-$}
  \rput{70}(1.3,-.4){$\theta\to2\pi^-$}

  \rput(.4,.4){$\sin\theta>0$}
  \rput(.4,.2){$\cos\theta>0$}
  \rput(-.4,.4){$\sin\theta>0$}
  \rput(-.4,.2){$\cos\theta<0$}
  \rput(-.4,-.2){$\sin\theta<0$}
  \rput(-.4,-.4){$\cos\theta<0$}
  \rput(.4,-.2){$\sin\theta<0$}
  \rput(.4,-.4){$\cos\theta>0$}

%\rput(.5,.1){$\sin\theta>0$}
%\rput(-.5,.1){$\sin\theta>0$}
%\rput{-90}(.1,.5){$\cos\theta>0$}
%\rput{-90}(.1,-.5){$\cos\theta>0$}
%\rput{90}(-.1,.5){$\cos\theta<0$}
%\rput{90}(-.1,.5){$\cos\theta<0$}
%\rput{180}(.5,-.1){$\sin\theta<0$}
%\rput{180}(-.5,-.1){$\sin\theta<0$}


\end{pspicture}
\end{center}
\caption{Unit circle graph showing the signs of $\sin \theta$ and 
$\cos \theta$
as $\theta$ approaches various axial from the left and right.
For instance, as $x\to\frac{\pi}2^+$, we have 
$\cos x\longrightarrow 0^-$, since in such a case $x$ is approaching
the angle $\pi/2$ from angles within the second quadrant,
in which the cosine is negative.  As a result,
$\sec x\longrightarrow-\infty$ as $x\to\frac{\pi}2^+$.}
\label{CircleForSignsOfTrigFunctionsAsApproachAngles}
\end{figure}





\bex Consider the following trigonometric limits:
\begin{enumerate}
\item $\ds{\lim_{x\to0^+}\csc x=\lim_{x\to0^+}\frac{1}{\sin x}
      \overset{1/0^+}\longeq\infty}$,
\item $\ds{\lim_{x\to\pi^+}\csc x=\lim_{x\to\pi^+}\frac{1}{\sin x}
       \overset{1/0^-}\longeq-\infty}$,
\item $\ds{\lim_{x\to\frac{\pi}2^-}\tan x
  =\lim_{x\to\frac{\pi}2^-}\frac{\sin x}{\cos x}
  \overset{1/0^+}\longeq+\infty}$,
\item $\ds{\lim_{x\to\frac{\pi}2^+}\tan x
  =\lim_{x\to\frac{\pi}2^+}\frac{\sin x}{\cos x}
  \overset{1/0^-}\longeq-\infty}$.
\item $\ds{\lim_{x\to\frac{\pi}2}\tan x
  =\lim_{x\to\frac{\pi}{2}}\frac{\sin x}{\cos x}
  \text{ does not exist }({1/0^\pm})}$.
\end{enumerate}
\eex

\newpage
\subsection{Proofs}
First we prove Theorem~\ref{LimitOfCompositionOfFunctionsTheorem},
page~\pageref{LimitOfCompositionOfFunctionsTheorem}, which states
that if $g(x)\longto L$, and $f(x)$ is continuous at $x=L$,
then $f(g(x))\longto f(L)$.  Here we will prove the 
basic case where the limiting behavior 
is as  $x\to a\in\Re$ ($a$ not infinite).

\begin{proof}
Here we will prove the basic case where $a\in\Re$ (not infinite):
$$\left(\lim_{x\to a}g(x)=L\right)\wedge
  \left(f(x)\text{ continuous at }x=L\right)
  \implies\left(\lim_{x\to a}f(g(x))=f(L)\right).$$
To show this, we have to show that for any 
$\epsilon>0$, we can find  a $\delta>0$
such that
$$0<|x-a|<\delta\implies|f(g(x))-f(L)|<\epsilon.$$
By our continuity and limit assumptions, we know that
\begin{align}
&(\forall\epsilon_1>0)(\exists\delta_1>0)(\forall x)(|x-L|<\delta_1
  \longrightarrow|f(x)-f(L)|<\epsilon_1),\label{Berford}\\
&(\forall\epsilon_2>0)(\exists\delta_2>0)(\forall x)(0<|x-a|<\delta_2
  \longrightarrow|g(x)-L|<\epsilon_2).\label{Berford2}\end{align}
So for this $\epsilon$, choose $\epsilon_1=\epsilon$,
which gives a $\delta_1>0$ so that
$$|x-L|<\delta_1\implies|f(x)-f(L)|<\epsilon.$$
Next set $\epsilon_2=\delta_1>0$. This gives a $\delta_2>0$
so that 
$$0<|x-a|<\delta_2\implies|g(x)-g(a)|<\epsilon_2=\delta_1.$$
Finally, let $\delta=\delta_2$, corresponding to $\epsilon_2$
in the limit requirement for $g(x)\longto L$. This gives
(with the part of ``$x$'' in (\ref{Berford}) played by
$g(x)$ in the third and fourth lines below):
\begin{align*}
0<|x-a|<\delta&\iff0<|x-a|<\delta_2\\
&\implies|g(x)-L|<\epsilon_2\\
&\iff |g(x)-L|<\delta_1\\
&\implies |f(g(x))-f(L)|<\epsilon_1=\epsilon,\qquad\text{q.e.d.}
\end{align*}\end{proof}

Next we prove that the trigonometric functions
$\sin x$, $\cos x$, $\tan x$, $\cot x$, $\sec x$ and $\csc x$
are continuous  wherever they are defined.

\begin{proof}
Our ``proof'' will be in four parts, and will be
cut somewhat shorter than a proof from ``first principles''
would be by using an observation
about the geometry of the unit circle.
In this abbreviated proof we will see
the sandwich theorem in action, in particular as applied
to a useful inequality, 
(\ref{SineEstimatedByArgument}),  which will be our ``observation.'' 

The order in which we will prove our results is as follows:
1.\ continuity of $\sin x$ at $x=0$, implying 2.\ continuity of $\cos x$ at
$x=0$, together implying 3.\ continuity of $\sin x$ and $\cos x$ at every 
$x\in\Re$, which implies
4.\ continuity of the other trigonometric functions 
wherever they are defined.

\begin{enumerate}
\item $\sin x$ is continuous at $x=0$.

Consider the unit circle graphed in Figure~\ref{CircleForContOfSine}.
\begin{figure}
\begin{center}
\begin{pspicture}(-4,-3)(4,3)
\psset{xunit=2cm,yunit=2cm}
\psaxes[ticks=none,labels=none]{<->}(0,0)(-1.5,-1.5)(1.5,1.55)
\pscircle(0,0){2}
\psline{->}(.5,0)(.5,.866025404)
 \rput{-90}(.625,.4){$\sin x$}
\psline[linestyle=dashed]{->}(0,0)(.721687836,1.25)
\psarc[linewidth=2.5pt]{->}(0,0){2}{0}{60}
\pscircle[fillstyle=solid,fillcolor=black](.5,.866025404){.075}
  \rput(.5,1.05){$P$}
  \rput(1,.5){$x$}
  \rput{60}(.2,.6){1}
\psline(.4,0)(.4,.1)(.5,.1)
\end{pspicture}
\end{center}
\caption{Unit circle graph showing the relative sizes of $\sin x$
and $x$, where $x$ is the angle measure in radians, i.e., the
directed length of the arc. More generally, the distance
from the horizontal axis to $P$ on the terminal side is
$|\sin x|$, and the arc length distance from $(1,0)$ to $P$
is given by $|x|$.  }
\label{CircleForContOfSine}
\end{figure}
Now $|\sin x|$ is the distance from the horizontal 
axis to a point $P$ on the terminal
side of the angle. The arc is another,
but non-straight path of length $|x|$ from the horizontal axis to $P$.
Thus \begin{equation}|\sin x|\le |x|,\label{SineEstimatedByArgument}
\end{equation}
which is the same as $-|x|\le\sin x\le|x|$.
Letting $x\to0$, we get the following:
\begin{center}
\begin{pspicture}(-.5,0)(4.5,2)
  \rput(0,1.9){$\ds{\underbrace{-|x|}}$}
  \rput(1,2){$\le$}
  \rput(2,2){$\sin x$}
  \rput(3,2){$\le$}
  \rput(4,1.9){$\ds{\underbrace{|x|}}$}
\psline{->}(0,1.5)(0,.5)
  \rput(0,0){0}
\psline{->}(4,1.5)(4,.5)
  \rput(4,0){0}
\end{pspicture}
\end{center}
The Sandwich Theorem then gives us $\ds{\lim_{x\to0}\sin x=0}$.
Since $\sin0=0$ as well, we have $\sin x$ is continuous at $x=0$, q.e.d.%
\footnote{
%%%  FOOTNOTE
Recall that $f(x)$ is continuous at $x=a$ 
if and only if $\ds{\lim_{x\to a}f(x)=f(a)}$.  See 
Theorem~\ref{ContinuityImpliesLimit=Function},
page~\pageref{ContinuityImpliesLimit=Function}.
%%%  END FOOTNOTE
}
\item $\cos x$ is continuous at $x=0$.
This follows immediately, since near $x=0$ (so the ``angle'' $x$ terminates
in the first or fourth quadrants) we have $\cos x>0$
and thus (again, near $x=0$) $\cos x=\ds{
\sqrt{1-\sin^2x}}$, and so we can replace
$\cos x$ with that expression (according to Theorem~\ref{f=gLimitTheorem}):
$$\lim_{x\to0}\cos x=\lim_{x\to0}\sqrt{1-\sin^2x}=\sqrt{1-\sin^20}=\sqrt{1}=1
=\cos 0, \text{\ q.e.d.}$$
We will take a moment here to explain why we could 
compute the above limit as we did.
Because $\sin x$ is continuous at $x=0$, so is $1-\sin^2x$, and
since that function approaches $1>0$ as $x\to 0$, its square root
is also continuous at $x=0$.


\item $\sin x$ and $\cos x$ are continuous for all $x\in\Re$.
These follow from the two results above and the 
trigonometric identities (\ref{Sin(Alpha+Beta)}) and
(\ref{Cos(Alpha+Beta)}) as below:
\begin{align*}
\lim_{x\to a}\sin x
&=\lim_{x\to a}\sin(a+(x-a))\\
&=\lim_{x\to a}(\sin a \cos(\underbrace{x-a}_{\begin{array}{c}
\downarrow\\ 0\end{array}})+\cos a\sin(\underbrace{x-a}_{\begin{array}{c}
\downarrow\\ 0\end{array}}))
=\sin a \cos 0 + \cos a\sin 0 
\\&= (\sin a)(1)+(\cos a)(0)=\sin a,\\ \\
\lim_{x\to a}\cos x
&=\lim_{x\to a}\cos(a+(x-a))\\
&=\lim_{x\to a}(\cos a \cos(\underbrace{x-a}_{\begin{array}{c}
\downarrow\\ 0\end{array}})-\sin a\sin(\underbrace{x-a}_{\begin{array}{c}
\downarrow\\ 0\end{array}}))
=\cos a \cos 0 -\sin a\sin 0 \\&= (\cos a)(1)-(\sin a)(0)
=\cos a,\text{ q.e.d.}
\end{align*}
Here we used what we will later call a {\it substitution argument},
which will be introduced properly in 
Section~\ref{MoreLimitTheoremsSection} (though
we could also invoke Theorem~\ref{LimitOfCompositionOfFunctionsTheorem},
page~\pageref{LimitOfCompositionOfFunctionsTheorem}).  The idea is, roughly,
that $x\to a\iff x-a\to 0$ in the sense of limit (where $x$ is
never actually equal to $a$, and $x-a$ is never equal to zero).
\item All six trigonometric functions are continuous where 
they are defined.

Of course $\sin x$ and $\cos x$ were already shown continuous 
for all $x\in\Re$, i.e., where defined, earlier.  
The other functions are defined by quotients
where the numerators are either $\sin x$, $\cos x$ or
$1$, which are continuous everywhere,
while the denominators are either $\sin x$ or
$\cos x$, again continuous everywhere.  
Since a ratio of two functions is 
continuous if both numerator and denominator
are continuous and the denominator is nonzero,
the functions $\tan x$ and $\sec x$ are continuous
except where $\cos x=0$, and $\cot x$ and $\csc x$
are continuous except where $\sin x=0$.  Summarizing,
all trigonometric functions are continuous where defined, q.e.d.
\end{enumerate}
\end{proof}











\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\begin{multicols}{2}
\begin{enumerate}
\item Compute $\ds{\lim_{x\to0^+}\left[\sqrt{x}\sin\left(\frac1x\right)\right]
                   }$.
\item Compute $\ds{\lim_{x\to1^+}\frac{\sin x}{x-1}}$.
(\underline{Hint}: $\sin1\approx0.841470985$.)
\item Compute using a Sandwich Theorem-type argument
$\ds{\lim_{x\to5^+}\frac{x+\cos x}{x^2-25}}$.
\item Compute $\ds{\lim_{x\to2}\cos\left(\frac{x^2-4x+4}{x^2-4}\right)}$.
\item  Compute the following limits.
  \begin{enumerate}
  \item $\ds{\lim_{x\to{\frac{\pi}2}^+}\sec x}$.
  \item $\ds{\lim_{x\to{\frac{\pi}2}^-}\sec x}$.
  \item $\ds{\lim_{x\to{\frac{3\pi}2}^+}\sec x}$.
  \item $\ds{\lim_{x\to{\frac{3\pi}2}^-}\sec x}$.
  \end{enumerate}
\item Compute the following limits.
  \begin{enumerate}
  \item $\ds{\lim_{x\to 0^+}\cot x}$.
  \item $\ds{\lim_{x\to 0^-}\cot x}$.
  \item $\ds{\lim_{x\to\pi^+}\cot x}$.
  \item $\ds{\lim_{x\to \pi^-}\cot x}$.
  \end{enumerate}   
\item Compute $\ds{\lim_{x\to0^+}\left[\sqrt{x}\sin(\csc x)\right]}$.

\item Suppose that $f(x)\le h(x)$ for $0<|x-a|<d$, for some 
      $d>0$, and that $\ds{\lim_{x\to a}h(x)=\infty}$.
      By drawing several graphs, show that $\ds{\lim_{x\to a}f(x)}$
      can be anything: finite, $\infty$, $-\infty$, or nonexistent.
\item Compute the following limits if they exist.
  \begin{enumerate}
  \item $\ds{\lim_{x\to 0}\sqrt[3]{x\sin\frac1x}}$
  \item $\ds{\lim_{x\to 0}\sqrt{x\sin\frac1x}}$
  \item $\ds{\lim_{x\to 0}\sqrt{\left|x\sin\frac1x\right|}}$
  \item $\ds{\lim_{x\to 0}\sqrt{x^2\sin^2\frac1x}}$
  \end{enumerate}

\end{enumerate}
\end{multicols}

\newpage
\section{Limits ``At Infinity''\label{LimitsAtInfinitySection}}
The limits we introduce here differ from previous
limits in that here we are interested in the behavior
of functions $f(x)$ as $x$ grows without bound, rather than as $x$
approaches a finite point.
There are new ``forms'' we will come across
here, such as $1/\infty$, $\infty\cdot\infty$,
 $\infty/\infty$, $0\cdot\infty$ and $\infty-\infty$.
\label{FirstOfficialInstanceOfInfty-Infty}  (Only the
first two {\it determinate.})

The first forms we will look at are $1/\infty$ and 
$1/(-\infty)$.  For these we look again to the function
$f(x)=1/x$.  Due to the importance of this function
we produce it here for the third time, in Figure~\ref{1/xGraphIII}.
\begin{figure}
\begin{center}
\begin{pspicture}(-4,-3.4)(4,3.4)
\psset{xunit=.665cm,yunit=.665cm}

\psaxes[labels=none]{<->}(0,0)(-6,-5)(6,5)
\psplot{-6}{-.2}{1 x div}
\psplot{.2}{6}{1 x div}
\end{pspicture}
\end{center}
\caption{Partial graph of $f(x)=1/x$.  We see here that
$f(x)\longrightarrow0$ as $x\to\infty$ and as $x\to-\infty$.}
\label{1/xGraphIII}
\end{figure}
We see that as $x$ moves to the right through values like
$x=1$, 2, 3, 10, 100, 1000, $10^6$ and so on, the function takes
on respective values $f(x)=1$, 1/2, 1/3, 1/10, 1/100, 1/1000,
$10^{-6}$ and
so on. So as $x$ grows without bound, the function's output
shrinks towards (though is never equal to, for this case)
zero.  A similar phenomenon occurs when we take
$x$-values $x=-1, -2, -3, -10, -100, -1000, -10^6$, etc.,
except the values of $f(x)$ are then 
$f(x)=-1, -1/2, -1/3, -1/10, -1/100, -1/1000, -10^{-6}$
etc.  So as $x$ moves left without bound, the
function values are negative numbers shrinking in absolute size.
The fact that in both cases we can get as close
to zero in the values of $f(x)$ as we could like
(without necessarily {\it achieving} the value zero) by choosing $x$
large enough is reflected in the statements
\begin{align}
\lim_{x\to\infty}\frac1x&\overset{\frac1\infty}{\longeq}0,
  \label{1/x->0AsX->infty}\\
\lim_{x\to-\infty}\frac1x&\overset{\frac1{(-\infty)}}{\llongeq}0.
  \label{1/x->0AsX->-infty}\end{align}
The forms $1/\infty$ and $1/(-\infty)$ are determinate, both yielding
zero limits.
Recall that a growing denominator will produce a shrinking
fraction.\footnote{%
%%%%% FOOTNOTE
Unless there is another effect to counteract the growing
denominator, such as a growing numerator.  We will
soon see that $\infty/\infty$ is indeterminate.}
%%%%% END FOOTNOTE
Furthermore reciprocals of large numbers give small 
numbers.  From earlier discussions of the graph of
$y=1/x$ we can see how, as $x$ gets arbitrarily large, 
$1/x$ gets arbitrarily small (though never quite zero)
in absolute size.

\begin{figure}


\begin{center}
\begin{pspicture}(-.5,-1)(11,4)
\psaxes[labels=none,Dx=15,Dy=15]{<->}(0,0)(-.5,-1)(11,4)
\psplot[plotpoints=550]{.8}{11}{x 180 mul cos 2 mul x div 2 add}
\psline[linestyle=dashed](0,2)(11,2)
\psline(-.2,2)(.2,2)
\rput(-.4,2){$L$}
\psline[linestyle=dashed](7.2,-.2)(7.2,4)
\rput(7.2,-.5){$M$}
\psline[linestyle=dotted](0,2.3)(11,2.3)
\psline[linestyle=dotted](0,1.7)(11,1.7)

  \psline{->}(-.7,2.7)(0,2.3)
  \rput(-1,3.0){$L+\epsilon$}
%\psline[linestyle=dashed](.2,2.5)(10,2.5)
%\psline(-.2,2.1)(.2,2.1)
  \psline{->}(-.7,1.1)(0,1.7)
  \rput(-1,.9){$L-\epsilon$}
\rput(5.5,-1){$(\forall\epsilon>0)(\exists M\in\Re)(\forall x\in\Re)
  (x>M\longrightarrow |f(x)-L|<\epsilon)$}


\end{pspicture}\end{center}

\caption{Illustration of the definition of a finite limit $L$
of a function as $x\to\infty$.  }
\label{FigureForDefOfLimitLAtInfty}\end{figure}





It is common to read the left-hand side of (\ref{1/x->0AsX->infty})
as, ``the limit, as $x$ approaches infinity, of $1/x$.''
Of course $x$ does not ``get close'' to $\infty$,
but the notation means that we are computing what
the behavior of $1/x$ is as $x$ grows positive without
bound.  Similarly for $x\to-\infty$.  To make these 
precise, we give the following definitions.
\begin{definition} For a finite number $L\in\Re$, we say
\begin{align}
\lim_{x\to\infty}f(x)=L\qquad&\iff\qquad
 (\forall\epsilon>0)(\exists M\in\Re)(\forall x\in\Re)
  (x>M\longrightarrow |f(x)-L|<\epsilon),\label{Lim_xToInfty=L}\\
\lim_{x\to-\infty}f(x)=L\qquad&\iff\qquad
  (\forall\epsilon>0)(\exists N\in\Re)(\forall x\in\Re)
  (x<N\longrightarrow |f(x)-L|<\epsilon).\label{Lim_xTo-Infty=L}\end{align}
\end{definition}
In (\ref{Lim_xToInfty=L}), we could also write
$f((M,\infty))\subseteq(L-\epsilon,L+\epsilon)$, while
in (\ref{Lim_xTo-Infty=L}), we could write
$f((-\infty,N))\subseteq(L-\epsilon,L+\epsilon)$.
A case of (\ref{Lim_xToInfty=L}) for a particular $\epsilon$
is illustrated in
Figure~\ref{FigureForDefOfLimitLAtInfty}.
We will leave the illustrations of (\ref{Lim_xTo-Infty=L})
to the reader.

Next we point out that it is natural to have a notion
of an {\it infinite} limit as $x\to\infty$ or $x\to-\infty$.
For instance,
\begin{equation}\lim_{x\to\infty}x=\infty\end{equation}
seems quite reasonable, as does
\begin{equation}\lim_{x\to-\infty}x^2=\infty.\label{LimX->-InftyX^2=Infty}
\end{equation}
There are many common functions which grow without bound
as $x$ grows without bound.  Note that 
(\ref{LimX->-InftyX^2=Infty}) can be thought of as
a form $(-\infty)\cdot(-\infty)$ or $(-\infty)^2$,
which reasonably yields the limit $\infty$.\footnote{%
%%%%%% FOOTNOTE
Of course $(-\infty)\cdot(-\infty)$ is a particular {\it form} 
representing  a product
of two functions which are both negative and growing without bound.
The product is naturally positive and growing without bound, 
the resulting limit then being $\infty$.
%%%%%% FOOTNOTE 
}  On the other hand,
\begin{equation}
\lim_{x\to-\infty}x^3=-\infty,\end{equation}
since $x^3<0$ and $x^3$ grows without bound as 
$x$ grows larger, without bound but negative.
We could think of the above limit as a form
$(-\infty)^3$, giving the limit as $-\infty$ as
we should expect.  In general, all positive 
powers of $x$ will grow to $+\infty$ as $x\to\infty$,
while even powers will grow to $+\infty$ as $x\to-\infty$
and odd powers will grow to $-\infty$ as $x\to-\infty$.\footnotemark
\footnotetext{Noninteger powers of $x$ are more complicated
for $x\to-\infty$.  Some approach $+\infty$, some $-\infty$
and some are undefined as $x\to-\infty$.  Such things will be
discussed as they come up in the text.}
Constant factors behave as before (see (\ref{(a>0)timesinfty})
and (\ref{(a<0)timesinfty}), page~\pageref{(a<0)timesinfty}), as in 
\begin{align*}
\lim_{x\to\infty}5x&\overset{5\cdot\infty}{\longeq}\infty,\\
\lim_{x\to-\infty}(-3x)&\overset{-3\cdot(-\infty)}{\lllongeq}\infty.
\end{align*}
The definition of $\ds{\lim_{x\to\infty}f(x)=\infty}$ is
given below:
\begin{definition}We make the following definition:
\begin{equation}\lim_{x\to\infty}f(x)=\infty
\iff (\forall M)(\exists N)(\forall x)(x>N\longrightarrow f(x)>M).
\label{EqForDefOfLimX->Infty=Infty}\end{equation}
\label{DefineLimAtInfinityToBeInfinity}
\end{definition}
In other words, for any fixed $M$, we can force $f(x)$ to
be greater than $M$ by taking $x>N$, so that
$f((N,\infty))\subseteq(M,\infty)$.
The definition of $f(x)\longto-\infty$ as $x\to\infty$,
and similar definitions, are left as exercises.
To see (\ref{EqForDefOfLimX->Infty=Infty}) in action, consider
proving $\ds{\lim_{x\to\infty}x^2=\infty}$.  For any $M$,
we can take $N=\sqrt{|M|}$
to get
$$x>N=\sqrt{|M|}\implies
f(x)=x^2>N^2=\left(\sqrt{|M|}\right)^2=|M|\ge M.$$
Other forms which can be shown non-indeterminate using
(\ref{EqForDefOfLimX->Infty=Infty})
include the following:
\begin{enumerate}
\item $\infty+a=\infty$ for any fixed $a\in\Re$,
\item $\infty+\infty=\infty$,
\item $a\cdot\infty=\infty$ if $a>0$, but $a\cdot\infty=-\infty$
      if $a<0$.
%\item $\infty-\infty$, $0\cdot\infty$, and $\infty/\infty$ are
%      all indeterminate.
\end{enumerate}
The third one was mentioned
in the previous sections, first on page~\pageref{4CdotInfty}.
Again, these are statements about limit {\it forms,} so
the first one means that if one function ``approaches'' $\infty$,
i.e., grows positive without bound according to infinite
limit definitions, 
and another approaches some fixed real (and therefore finite) 
number $a$, then
the sum will grow without bound and its limit will be $\infty$.
Intuitively, if one term in a sum is
a function approaching $a\in\Re$, it can not, in the limit,
affect the sum if the other term grows without bound.


The above forms are relatively intuitive.  The following are
more subtle, and in fact indeterminate:
$$\infty-\infty,\qquad\qquad 0\cdot\infty,\qquad\qquad \infty/\infty.$$
To see the first is indeterminate, consider for instance the following 
limits of the form $\infty-\infty$:\footnotemark
\bex
\begin{align*}
\lim_{x\to\infty}\left[(x^2+1)-(x^2)\right]&
\underset{\ALG}{\overset{\infty-\infty}{\llongeq}}
\lim_{x\to\infty}(1)=1,\\
\lim_{x\to\infty}\left(x^3-x^2\right)&
\underset{\ALG}{\overset{\infty-\infty}{\llongeq}}
\lim_{x\to\infty}x^2(x-1)
\overset{\infty\cdot\infty}\llongeq\infty,\\
\lim_{x\to\infty}\left(x^4-x^6\right)&
\underset{\ALG}{\overset{\infty-\infty}{\llongeq}}
\lim_{x\to\infty}x^4(1-x^2)
\overset{\infty\cdot(-\infty)}{\llongeq}-\infty.
\end{align*}
\footnotetext{%
%%%%%%  FOOTNOTE
The first limit shows that
it is possible to come up with a limit of the form $\infty-\infty$
which when evaluated gives any predetermined real value we would like
(just replace the number 1 with the desired value).  The second and third
show we can, furthermore, find limits of form $\infty-\infty$ which
return infinite limits as well.}
%%%%%%  END FOOTNOTE 
\label{Infty-InftyExamples}\eex
The question for $\infty-\infty$ form becomes, which ``infinity'' is larger, i.e.,
which function grows faster
when we have a difference $f(x)-g(x)$ of functions
$f$ and $g$ which grow without bound?  Or is there
ultimately a compromise?  Similar 
examples can be found for forms $0\cdot\infty$ (or $\infty\cdot0$)
and $\infty/\infty$.  The former we look at next, with
a few examples to show that it is in fact indeterminate.
\bex Consider the following limits:
\begin{align*}
\lim_{x\to\infty}\left[x\cdot\frac1{x^2}\right]
  &\underset{\ALG}{\overset{\infty\cdot0}{\llongeq}}
  \lim_{x\to\infty}\frac1x=0,\\
\lim_{x\to\infty}\left[x^2\cdot\frac1{x}\right]
  &\underset{\ALG}{\overset{\infty\cdot0}{\llongeq}}
  \lim_{x\to\infty}x=\infty,\\
\lim_{x\to\infty}\left[x\cdot\frac5{x}\right]
  &\underset{\ALG}{\overset{\infty\cdot0}{\llongeq}}
  \lim_{x\to\infty}5=5.\\
\end{align*}
\label{InfinityTimesZeroExample}\eex

Now let us turn to polynomial and rational functions.
Our first theorem is the following:
\begin{theorem}For a polynomial function
$p(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots+a_1x+a_0$,
where $a_n\ne0$ (so the polynomial really is of
degree $n$), we have
\begin{align}
\lim_{x\to\infty}p(x)&=\lim_{x\to\infty}a_nx^n,\\
\lim_{x\to-\infty}p(x)&=\lim_{x\to-\infty}a_nx^n.
\end{align}\label{TheoremOnPolynomialGrowth}
\end{theorem}
In other words, for $x\to\infty$ and $x\to-\infty$,
a polynomial function's growth is ultimately
dictated by its leading (highest degree) term.  Rather than prove this
in general, we can see the essence of a proof
in the following examples and leave the actual proof
as an exercise.
\bex Consider the following limits. (Forms are first given above
the ``=,'' and then simplified below.)
\begin{align*}
\lim_{x\to\infty}\left(3x^2-5x+11\right)
&=\lim_{x\to\infty}x^2\left(3-\frac5x+\frac{11}{x^2}\right)
\overset{\infty\cdot(3-0+0)}{\underset{\infty\cdot3}{\lllongeq}}\infty,\\
\lim_{x\to-\infty}\left(x^3+95x^2-15x+1000\right)
&=\lim_{x\to-\infty}x^3\left(1+\frac{95}{x}-\frac{15}{x^2}
     +\frac{1000}{x^3}\right)
\overset{-\infty(1+0-0)}{\underset{-\infty\cdot1}{\lllongeq}}-\infty.
\end{align*}
\label{ExForHwLimitsXToInfinity}\eex
When we factor out the highest power, the lower-order
terms we are left with negative powers of $x$ which
then shrink to zero, leaving only the coefficient
of the highest-order term as a factor in the limit.
This phenomenon is very useful when we look at rational limits
as $x\to\pm\infty$, which are often of the form
$\infty/\infty$, $(-\infty)/(-\infty)$ and so on.
\bex Consider the following limits.
\begin{align*}
\lim_{x\to\infty}\frac{3x^2+5x-9}{6x+11}
  &\overset{\infty/\infty}{\llongeq}
  \lim_{x\to\infty}\frac{x^2\left(3+\frac5x-\frac9{x^2}\right)}
  {x\left(6+\frac{11}x\right)}
  \underset{\ALG}{\overset{\infty/\infty}{\llongeq}}\lim_{x\to\infty}
  x\cdot\frac{3+\frac5x-\frac9{x^2}}{6+\frac{11}{x}}
  \overset{\infty\cdot\frac36}{\llongeq}\infty,\\
\lim_{x\to\infty}\frac{9x^2+2x+1}{16x^2+3x-100}
  &\overset{\infty/\infty}{\llongeq}
  \lim_{x\to\infty}\frac{x^2\left(9+\frac2x+\frac1{x^2}\right)}
  {x^2\left(16+\frac3x-\frac{100}{x^2}\right)}
  \underset{\ALG}{\overset{\infty/\infty}{\llongeq}}\lim_{x\to\infty}
  \frac{9+\frac2x+\frac1{x^2}}{16+\frac3x-\frac{100}{x^2}}
  \\&=\frac{9+0+0}{16+0-0}=\frac9{16},\\
\lim_{x\to-\infty}\frac{5-3x}{2x^2+x+1}
  &\overset{\infty/\infty}{\llongeq}
  \lim_{x\to-\infty}\frac{x\cdot\left(\frac5x-3\right)}
  {x^2\left(2+\frac1x+\frac1{x^2}\right)}
  \underset{\ALG}{\overset{\infty/\infty}{\llongeq}}
  \lim_{x\to-\infty}\left[
    \frac1x\cdot\frac{\frac5x-3}{2+\frac1x+\frac1{x^2}}\right]\\
  &\overset{\frac1{-\infty}\cdot\frac{-3}2}{\lllongeq}0\cdot\frac{-3}2=0.
  \end{align*}
\label{SomeRationalLimitsExample}\eex
A quick corollary---which we must be careful not to abuse---to 
our theorem is the following:
\begin{theorem} For any rational function
$f(x)=\frac{p(x)}{q(x)}$, where
$p(x)=a_nx^n+\cdots+a_1x+a_0$ and 
$q(x)=b_mx^m+\cdots+b_1x+b_0$, with $a_n,b_m\ne0$, we have
\begin{align}
\lim_{x\to\infty}\frac{p(x)}{q(x)}&=\lim_{x\to\infty}\frac{a_nx^n}{b_mx^m},\\
\lim_{x\to-\infty}\frac{p(x)}{q(x)}&=\lim_{x\to-\infty}\frac{a_nx^n}{b_mx^m}.
\end{align}\label{TheoremOnRationalFunctionsAtInfty}
\end{theorem}
So as we take $x\to\infty$ or $x\to-\infty$, 
the limiting behavior of a rational function is 
governed by the leading terms of the numerator and 
denominator.\footnote{%
%%%%%%%% FOOTNOTE
Note that the ``leading term'' means the term of the highest
degree, not necessarily the first term appearing.
For instance, in the polynomial $6-5x^2$, the leading term
is $-5x^2$.
}
%%%%%%%% END FOOTNOTE
\hphantom{. }%
We will use this theorem for anticipating results, but
will work the actual limits as in 
Example~\ref{SomeRationalLimitsExample}.\footnote{%%
%%%%%%%%  FOOTNOTE
We will continue to compute the limits longhand for
three reasons.  First it is good reinforcement
of the underlying principles.  Second, it is not
entirely standard to write, for instance,
$$\lim_{x\to\infty}\frac{5x^2+3x-11}{7x^2-9x+1,000}
=\lim_{x\to\infty}\frac{5x^2}{7x^2}=\lim_{x\to\infty}
\frac57=5/7.$$
A reader might be confused about the whereabouts of the
terms that were dropped, and generally lose confidence that
the writer's understanding is correct.  Finally, the theorem
requires that $x\to\infty$ or $x\to-\infty$, so
if we reflexively drop terms we may be tempted to do so
for a limit at a finite point, where the theorem does
not hold.
}
%%%%%%%%  END FOOTNOTE

It is common for trigonometric limits, and variations
of the Sandwich Theorem
(originally Theorem~\ref{SandwichTheoremStatement}, page
\pageref{SandwichTheoremStatement})
to appear with limits ``at infinity.'' 
\bex Consider the limit $\ds{\lim_{x\to\infty}\frac{\cos x}{x}}$.
This yields to the Sandwich Theorem quickly:
\bigskip

\begin{center}
\begin{pspicture}(-2.5,0)(8.2,2)
  \rput(-2.2,2){As $x\to\infty$:}
  \rput(0,2){$\ds{\underbrace{\frac{-1}{x}}}$}
  \rput(1,2){$\le$}
  \rput(2,2){$\ds{\frac{\cos x}{x}}$}
  \rput(3,2){$\le$}
  \rput(4,2){$\ds{\underbrace{\frac1x}}$}
\psline{->}(0,1.5)(0,.5)
  \rput(0,0.2){$0$}
\psline{->}(4,1.5)(4,.5)
  \rput(4,0.2){$0$}
\rput(7,0.3){$\ds{\therefore \frac{\cos x}x\longrightarrow 0.}$}
\end{pspicture}
\end{center} 
\eex

One could also look at the previous limit as
one  of a product of two functions,
one which is bounded ($\cos x$), and the other which 
approaches zero ($1/x$), yielding $B\cdot0$ form, which
is a determinate form giving zero in the limit.  
Furthermore we could define
a form, ``$B/\infty$'' which will always yield zero
since the denominator grows without bound (shrinking the
fraction) while the numerator is unable to compensate
(by growing the fraction) since it is bounded.
We could also write $B/\infty=B\cdot\frac1{\infty}=B\cdot0$.
The ``algebra'' of forms is interesting and intuitive, but
one needs to be careful to understand the underlying 
mechanisms to perform such calculations on forms.

\bex Consider the limit $\ds{\lim_{x\to\infty}(x+\sin x)}$.
Here we have a sum of functions, the first growing without
bound and the second being bounded.  Intuitively this sum
should grow without bound since the function $\sin x$ is
unable to check the growth of $x$.  We can again use the
Sandwich Theorem:

\bigskip

\begin{center}
\begin{pspicture}(-2.5,0)(9,2)
  \rput[l](-2.5,2){As $x\to\infty$:}
  \rput(0,1.85){$\ds{\underbrace{x-1}}$}
  \rput(1,2){$\le$}
  \rput(2,2){$x+\sin x$}
  \rput(3,2){$\le$}
  \rput(4,1.85){$\ds{\underbrace{x+1}}$}
\psline{->}(0,1.5)(0,.5)
  \rput(0,0){$\infty$}
\psline{->}(4,1.5)(4,.5)
  \rput(4,0){$\infty$}
\rput[r](9,0){$\therefore(x+\sin x)\longrightarrow\infty$.}
\end{pspicture}
\end{center} 
In fact, recall that in such a case
we only need the first inequality above to form our conclusion.
\eex

We could look at the limit above as an example of a form
we could define as ``$\infty+B$,'' which will always
give us the actual limit being $\infty$.  To see this, note
that for such a case we are 
looking at sums $f(x)+g(x)$ where $g(x)$ is defined
and bounded, i.e., $|g(x)|\le M$ for some finite
fixed $M$, and $f(x)\longto\infty$.  By the
boundedness of $g(x)$, we get
$$f(x)-M\le f(x)+g(x)\le f(x)+M.$$
 Since
$f(x)-M, f(x)+M\longto\infty$, we would conclude $f(x)+g(x)\longto
\infty$ as well.

It should be pointed out that the limits ${\lim_{x\to\infty}\sin x}$
and ${\lim_{x\to\infty}\cos x}$ both do not exist. This is because
these functions oscillate between $-1$ and $1$, and do not approach
any particular value to the exclusion of others
(recall that a limit must be unique).  However the limits above
show that such functions can still be involved in limits ``at infinity,''
especially when their (bounded) oscillations can be 
checked by, or absorbed into, the influences of other functions in
the limits.

The methods of of above two examples are important and should
be mastered, but we can use observations about forms (proved the
same ways) and have more abbreviated computations:
\begin{align*}
\lim_{x\to\infty}\frac{\cos x}{x}&\overset{B/\infty}{%
\llongeq}0,\\
\lim_{x\to\infty}(x+\sin x)&\overset{\infty+B}{\llongeq}\infty.
\end{align*}
Here $B$ stands for any bounded function, including constants.
In both cases, the ``$B$'' can not check the growth of the
other (``$\infty$'') function, and so the other function's
influence ultimately prevails in the limit.  Note that
$B/\infty$ and $\infty+B$ are {\it determinate} forms.
We list these and some others below  Note that the left sides
are {\it forms,} and the right sides are final limit values.
\begin{align}
B/\infty&=0,\label{B/Infinity=0}\\  
B/(-\infty)&=0,\label{B/(-Infinity)=0}\\
B+\infty&=\infty,\label{B+Infinity=Infinity}\\  
B-\infty&=-\infty\label{B-Infinity=-Infinity}.
\end{align}
All these are intuitive and
provable using the Sandwich Theorem and its variations.


However, knowing we have a bounded function
and one which blows up does not always tell us the limit
(unless it is one of the forms above).
For instance we can not really say anything about 
$B\cdot\infty$ without more 
information.  If the first function is $f(x)$ defined by 
$(\forall x)(f(x)=0)$, then we have a zero limit.  If $f(x)\to0$,
we definitely need more information.\footnote{%%%
%%%% FOOTNOTE
For example, consider
$f(x)=K/x$, $g(x)=x$ and $x\to\infty$.  This gives a limit
of $K$, i.e., $f(x)g(x)=(k/x)\cdot x=K\longrightarrow K$,
and we can choose $K$ to be anything real number we like.
%%%% END FOOTNOTE
}
  If we instead know
$1\le f(x)\le 2$,
and $g(x)\longto\infty$ we have 
$g(x)\le f(x)g(x)\le 2g(x)$, and $g(x), 2g(x)\longto\infty$ so
we can say in this case that $f(x)g(x)\longto\infty$.\footnote{  
%%%% FOOTNOTE
For example, this is exactly what occurs with the limit
$\ds{\lim_{x\to\infty}\left[\left(\frac{3+\sin x}2\right)\cdot
x\right]=\infty}$.}
%%%% END FOOTNOTE  
The upshot of all
this is the fact that we sometimes {\it do} need to refer
back to the Sandwich Theorem-type computations for these, unless
the form gives us an obvious answer.


The continuity of the trigonometric functions (where they
are defined) can also come into play with these limits.
\bex Consider $\ds{\lim_{x\to\infty}\sec\left(\frac{x}{x^2+1}\right)}$. 
From what we know of rational functions, the argument of the secant
function here is approaching zero.  Since the secant (=1/cosine) is
continuous at zero, our answer should be $\sec0=1/\cos0=1/1=1$.
For a more computational argument we might write
$$\lim_{x\to\infty}\sec\left(\frac{x}{x^2+1}\right)
\underset{\text{\rm ALG}}{\overset{\sec(\infty/\infty)}{\llongeq}}
\lim_{x\to\infty}\sec\left(\frac{x(1)}{x\left(x+\frac1x\right)}\right)
=\lim_{x\to\infty}\sec\left(\frac1{x+\frac1x}\right)
\overset{\sec\left(\frac1{\infty+0}\right)}{\llongeq}\sec0=1.
$$
(We used the fact that $1/x\longto0$ as $x\to\infty$ in the
denominator of the argument of the secant function.)
Again, the last step utilized the fact that $\sec x$ is continuous
at $x=0$.\eex
For our last example we will return to a form $\infty-\infty$.
It is often useful to rewrite the limit as a quotient.  In the 
case below, we also use a conjugate multiplication step.
\bex Consider the limit $\ds{\lim_{x\to\infty}\left(\sqrt{x^2+x+1}-x\right)}$.
Clearly $x^2+x+1\longto\infty$, and so we are taking square roots of
numbers as large as we like.  In fact, $\sqrt{x^2+x+1}>\sqrt{x^2}=x
\longto\infty$ as $x\to\infty$.\footnote{%
%%%% FOOTNOTE
If we do not know $x\ge0$, then we must write $\ds{\sqrt{x^2}=|x|}$.}
%%%% END FOOTNOTE
We solve this using the following method:
\begin{align*}
\lim_{x\to\infty}\left(\sqrt{x^2+x+1}-x\right)
&\overset{\infty-\infty}{\underset{\text{ALG}}{\llongeq}}
\lim_{x\to\infty}\left[\left(\sqrt{x^2+x+1}-x\right)
\cdot\frac{\sqrt{x^2+x+1}+x}{\sqrt{x^2+x+1}+x}\right]\\
&=\lim_{x\to\infty}\frac{x^2+x+1-x^2}{\sqrt{x^2+x+1}+x}
=\lim_{x\to\infty}\frac{x+1}{\sqrt{x^2+x+1}+x}\\
&=\overset{\infty/\infty}{\underset{\text{ALG}}{\llongeq}}
\lim_{x\to\infty}\frac{x\left(1+\frac1x\right)}
{x\left[\sqrt{1+\frac1x+\frac1{x^2}}+1\right]}\\
&=\lim_{x\to\infty}\frac{1+\frac1x}{\sqrt{1+\frac1x+\frac1{x^2}}+1}
=\frac{1+0}{\sqrt{1+0+0}+1}=1/2.
\end{align*}\eex
The limit above is correct, but probably not at all obvious
from the original form.  Only after finding a useful
fractional form could we use our earlier techniques to compute
its value.  Limits which are writable as ratios are often
easier to solve than other forms.  Here it allowed us
to compare the powers of $x$ in the numerator and denominator.
In our first limit section we had many $0/0$ forms which 
we could easily simplify to get determinate forms.


\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\begin{multicols}{2}
\begin{enumerate}
\item Compute the following limits, showing all steps.
You may wish to use 
Theorem~\ref{TheoremOnPolynomialGrowth} 
(page~\pageref{TheoremOnPolynomialGrowth})
or Theorem~\ref{TheoremOnRationalFunctionsAtInfty}
(page~\pageref{TheoremOnRationalFunctionsAtInfty}) 
to \underline{\bf anticipate}
an answer, but perform all the computations as in 
Examples~\ref{ExForHwLimitsXToInfinity} and \ref{SomeRationalLimitsExample},
starting on page~\pageref{SomeRationalLimitsExample}.
 \begin{enumerate}
 \item $\ds{\lim_{x\to\infty}x^5}$
 \item $\ds{\lim_{x\to-\infty}x^5}$
 \item $\ds{\lim_{x\to-\infty}x^4}$
 \item $\ds{\lim_{x\to\infty}\left(x^4-5x^5\right)}$.
 \item $\ds{\lim_{x\to-\infty}\left(x^4-5x^5\right)}$.
 \item $\ds{\lim_{x\to\infty}\left(x^4-5x^6\right)}$.
 \item $\ds{\lim_{x\to-\infty}\left(x^4-5x^6\right)}$.
 \item $\ds{\lim_{x\to\infty}\frac{1}{x^3}}$.
 \item $\ds{\lim_{x\to-\infty}\frac1{x^3}}$.
 \item $\ds{\lim_{x\to\infty}\frac{x^2}{x^4+1}}$.
 \item $\ds{\lim_{x\to-\infty}\frac{1-2x^2}{x^3+x^2+x+9}}$.
 \item $\ds{\lim_{x\to\infty}\frac{3x^2+5x-11}{2x^2-27x+100}}$.
 \item $\ds{\lim_{x\to-\infty}\frac{3x^2+5x-11}{2x^2-27x+100}}$.
 \item $\ds{\lim_{x\to\infty}\frac{x^2+3x-7}{x+5}}$.
 \item $\ds{\lim_{x\to-\infty}\frac{x^2+3x-7}{x+5}}$.

 \end{enumerate}
\item Compute the limits:
 \begin{enumerate}
  \item $\ds{\lim_{x\to\infty}(x+\cos x)}$.
 \item $\ds{\lim_{x\to\infty}(x-\cos x)}$.
 \item $\ds{\lim_{x\to-\infty}(x+\cos x)}$.
\item $\ds{\lim_{x\to-\infty}\left(x^2+\cos x\right)}$
 \end{enumerate}
\item Compute the limits:
 \begin{enumerate}
 \item $\ds{\lim_{x\to\infty}\frac{\sin x}{x^2}}$.
 \item $\ds{\lim_{x\to\infty}\frac{x+\sin x}{x^2+1}}$.
 \item $\ds{\lim_{x\to\infty}\frac{x^2}{x-\sin x}}$.
 \item $\ds{\lim_{x\to\infty}\frac{x^2+2x+1-\sin x}{3x^2+2x-1}}$.
 \item $\ds{\lim_{x\to\infty}x\sin x}$.

 \end{enumerate}

\item Compute the limit 
$$\lim_{x\to\infty}\left(\sqrt{x^2+3x+9}-x
\right).$$  
\item Compute the limit $$\lim_{x\to-\infty}\left(\sqrt{x^2-5x+9}-x
\right).$$ It is actually simpler than the previous limit (one line!).  

\item Compute the following.
\begin{enumerate}
\item $\ds{\lim_{x\to\infty}\sin\frac1x}$.
\item $\ds{\lim_{x\to\infty}\cos\frac1x}$.
\item $\ds{\lim_{x\to\infty}\sin\left[\frac{x^2+2x+9}{6x^2-11x+45}\right]}$.
\end{enumerate}

\item Write  definitions for the following
(see (\ref{EqForDefOfLimX->Infty=Infty}), 
page~\pageref{EqForDefOfLimX->Infty=Infty}).
It may help to graph situations where these are true.
 \begin{enumerate}
 \item $\ds{\lim_{x\to\infty}f(x)=\infty}$.
 \item $\ds{\lim_{x\to-\infty}f(x)=\infty}$.
 \item $\ds{\lim_{x\to\infty}f(x)=-\infty}$.
 \item $\ds{\lim_{x\to-\infty}f(x)=-\infty}$.
 \end{enumerate}
\item Prove Theorem~\ref{TheoremOnPolynomialGrowth}, 
       page~\pageref{TheoremOnPolynomialGrowth}.
\item Prove Theorem~\ref{TheoremOnRationalFunctionsAtInfty},
       page~\pageref{TheoremOnRationalFunctionsAtInfty}.

\end{enumerate}
\end{multicols}
\newpage


\section{Further Limit Theorems and Trigonometric Limits
\label{MoreLimitTheoremsSection}}
In this section we wrap up our discussion of fundamental
methods for computing limits of functions.
We also look at some very general theorems on limits,
ranging from very intuitive to rather sophisticated. 
Into the mix we introduce and prove an interesting
trigonometric limit, (\ref{SinX/XLimitTheoremEquation})
which will be the basis for another
fundamental trigonometric limit,
(\ref{(1-CosX)/(X)Limit}) and many consequent
trigonometric limits we could not have proved with
previous methods.
Finally we will develop our most sophisticated (so far)
limit method, which is substitution.\footnote{%%%
%%%%%%%%  FOOTNOTE
Actually, we will add other methods after we develop
derivatives.  Still, what we finish in this section
are the {\it foundational} methods for limits of functions.
Even with the methods we will introduce after derivatives,
we can not avoid the requirements of the methods of
this section or this chapter.  Indeed, the later methods
are quite powerful where applicable, but
have very limited scopes and  therefore cannot replace
what we develop here.
%%%%%%%%  END FOOTNOTE
}  The aforementioned trigonometric limits
will give rise to many interesting limits which require
the new methods here, as well as the methods of previous sections.

%In this subsection we prove and apply a very useful trigonometric
%limit.  Then we state some very general limit theorems.
%In fact, much of our previous limit theorem development
%could have been based alternatively upon the theorems
%we will state here.  However, arguably a better use
%of the limit theorems presented here is in the various
%limits we will encounter in this section, for here we will
%have functions which are discontinuous---undefined, really---at
%the limit points, but ``pieces'' will be known limits which we
%can then put together using the theorem stated above.


\subsection{Simple Limit Theorems}
Many of the limit computations that we have already
performed in this textbook were based upon what we knew
from continuity arguments.  We took that approach because
it is more intuitive than the usual treatment found in most
calculus textbooks.  (See 
Footnote~\ref{FootnoteForWhyWeDoContinuityAndThenLimits},
page~\pageref{FootnoteForWhyWeDoContinuityAndThenLimits}.)
In fact, the more  common
treatment is to instead rely upon theorems about
limits independent of possible underlying continuity
(or continuity of replacement functions).
These basic facts we combine below into one theorem,
the different parts of which can be proved
in ways very similar to the proofs of corresponding continuity theorems
(see especially Section~\ref{ContinuityTheoremsSection}).
\begin{theorem}Suppose that, as $x$ approaches some value,
we have $f(x)\longto L\in\Re$ and $g(x)\longto M\in\Re$.
Then
\begin{enumerate}[\rm (i)]
\item $f(x)+g(x)\longto L+M$,
\item $f(x)-g(x)\longto L-M$,
\item $Cf(x)\longto CL$,
\item $f(x)g(x)\longto LM$,
\item and if $M\ne0$, then $f(x)/g(x)\longto L/M$.
\item $\ds{\lim_{x\to a}C=C}$, where $C$ is any fixed constant.
\end{enumerate}
\label{UsualLimitTheorems}
\end{theorem}
The theorem above assumes $L,M\in\Re$, so $L$ and $M$ exist
and are finite.  The theorem can 
be extended to include several (but not all!) cases where
$L$ or $M$ do not exist or are infinite.  Furthermore the theorem
extends in the obvious ways to numerous {\it forms}, so for instance
if $f(x)\overset{\infty}{\longto}\infty$ and 
$g(x)\overset{\infty}{\longto}\infty$, then
$f(x)+g(x)\overset{\infty+\infty}{\llongto}\infty$.  We still
have to be careful: for
such $f$ and $g$ we have
$f(x)-g(x)$ is of form $\infty-\infty$, which is indeterminate,
as demonstrated in Example~\ref{Infty-InftyExamples}, 
page~\pageref{Infty-InftyExamples}.

Textbooks include part (vi) for theoretical reasons we will
consider to momentarily, but also give it special emphasis because
it is so simple it sometimes confuses.  For an example illustrating
how to interpret (vi) properly, 
consider the statement that $\lim_{x\to5}10=10$.
What this means is that a function $h(x)$, where
$h(x)=10$ for all $x\in\Re$,
will give $\lim_{x\to a}h(x)=10$ regardless of $a$ (finite or infinite).
This $h(x)$ is a ``constant''
function, which always returns the value 10 regardless of the
input; its graph is the horizontal line $y=10$.  When graphed it is clear
that $h(x)\longto 10$ as $x\to a$ (regardless of $a$,
chosen in advance).  Rather than explicitly defining such
an $h$, it is customary to simply write, for example,  $\lim_{x\to a}10=10$. 

The usual method---found in most of today's calculus textbooks---for 
obtaining a preliminary theory of finite limits is in fact based upon 
Theorem~\ref{UsualLimitTheorems} above using the following scheme:
\begin{enumerate}
\item First prove (with $\epsilon$-$\delta$
or by graphical demonstration) that 
$\lim_{x\to a}x=a$.
\item Then  use (i), (iii), (iv) and (vi) from the theorem above
repeatedly to show that polynomials $p(x)$ have the property that
$\ds{\lim_{x\to a}p(x)=p(a)}$, using the limit version of
the argument given in the proof of
Theorem~\ref{PolynomialsContinuousEverywhere},
page~\pageref{PolynomialsContinuousEverywhere}
but without reference to continuity (defined later in that approach).
\item From there (v) gives that rational functions $p(x)/q(x)$ (where 
$p$ and $q$ are polynomials) are
continuous where defined.  
\item Then one
looks at rational cases with $0/0$ form,
mentioning Theorem~\ref{f=gLimitTheorem}, page~\pageref{f=gLimitTheorem}
on replacing functions
with other functions that agree near the limit point and are continuous
there.  
\item One then
progresses through the more sophisticated cases
(radicals, infinite limits, limits at infinity,
Sandwich Theorem, etc.).  
\item {\it Define} continuity at $x=a$ by the criterion
that $\ds{\lim_{x\to a}f(x)=f(a)}$. (Our definition of continuity is
logically equivalent.)
\end{enumerate}

This is mentioned here so the reader will be aware of 
this common alternative treatment.  Though we did not follow that
logical scheme (instead opting for the advanced calculus and real analysis
style of continuity before limits), we will 
occasionally have use for Theorem~\ref{UsualLimitTheorems}
above in the rest of the text.  Now we will look at an
(admittedly) abstract example.

\bex Suppose that
$$\lim_{x\to3}f(x)=5,\qquad\text{and}\qquad \lim_{x\to3}g(x)=7.$$
Then
\begin{align*}
\lim_{x\to3}[f(x)+g(x)]&\overset{5+7}{\longeq}5+7=12,\\
\lim_{x\to3}[f(x)-g(x)]&\overset{5-7}{\longeq}5-7=-2,\\
\lim_{x\to3}[4f(x)]&\overset{4\cdot5}{\longeq}4\cdot5=20,\\
\lim_{x\to3}[f(x)g(x)]&\overset{5\cdot7}{\longeq}5\cdot7=35,\\
\lim_{x\to3}\frac{f(x)}{g(x)}&\overset{5/7}{\longeq}\frac57,\\
\lim_{x\to3}191&\ = 191.
\end{align*}
\eex
The last equation above, of course, has nothing to do with the 
functions $f$ or $g$.
For a more concrete example, consider the following:
\bex Compute $\ds{\lim_{x\to\infty}\left[17+
   \frac{x}{x^2+1}+\frac{3x^2+5x+9}{2-x^2}\cdot
             \frac{2x-3}{6x-5}\right]}$.

\underline{Solution}: There are several subexpressions here whose
limits exist.  In this particular example we are lucky that we can
partition the whole expression into such well-behaved subexpressions:

\begin{center}
\begin{pspicture}(-6,-1.5)(6,1.7)
\rput(0,1){$\ds{\lim_{x\to\infty}\left[%
   \underbrace{17\vphantom{\frac{x}{x^2+1}}}+
   \underbrace{\frac{x}{x^2+1}}+\underbrace{\frac{3x^2+5x+9}{2-x^2}}\cdot
             \underbrace{\frac{2x-3}{6x-5}}%
             \right]=17+0-3\cdot\frac13=17-1=16.}$}
\psline{->}(-4.62,.25)(-4.62,-1.)
  \rput(-4.7,-1.3){$17$}
\psline{->}(-3.38,.25)(-3.38,-1.)
  \rput(-3.38,-1.3){$0$}
\psline{->}(-1.45,.25)(-1.45,-1.)
  \rput(-1.45,-1.3){$(-3)$}
\psline{->}(0.3,.25)(0.3,-1.)
  \rput(0.3,-1.3){$1/3$}
\rput(-4.04,-1.3){$+$}
\rput(-2.415,-1.3){$+$}
\rput(-.875,-1.3){$\cdot$}
\end{pspicture}
\end{center}
Note that we relied upon our previous experience with limits at infinity,
as outlined in Section~\ref{LimitsAtInfinitySection},
especially for rational expressions cases, where only the highest 
powers were ultimately relevant, as $x\to\infty$ (or 
$x\to-\infty$).
\eex

The above limit could be computed as it was because all the
limits of subexpressions, as we organized them, existed and so
our omnibus Theorem~\ref{UsualLimitTheorems} lets us so combine them.
Clearly the argument above is easier than combining the
subexpressions into a single, rational expression.
Sometimes recombining can not be avoided, but often the
complete computation can be avoided, as in what follows.
\bex Compute $\ds{\lim_{x\to\infty}\left[
            \frac{x-2}{x^3-9x+5}\cdot\frac{x^4+10x^3-9x^2+11x+5}
{2x^2+x-9}\right]}$.

\underline{Solution}: As it stands, the form of this limit
is $0\cdot\infty$ (by 
Theorem~\ref{TheoremOnRationalFunctionsAtInfty},  
page~\pageref{TheoremOnRationalFunctionsAtInfty}
and the thinking surrounding that result)
which is indeterminate. One brute-force method
of computing this limit is to combine the two fractions into
one, but this requires some lengthy multiplication calculations.
Instead we offer the two methods below, which work well
because it is a limit at infinity.
\begin{enumerate}
\item We can factor the largest power of $x$ which appears in
each term and cancel:
\begin{multline*}
\lim_{x\to\infty}\left[
            \frac{x-2}{x^3-9x+5}\cdot\frac{x^4+10x^3-9x^2+11x+5}
{2x^2+x-9}\right]\\
  =\lim_{x\to\infty}\left[\frac{x\left(1-\frac2x\right)}{x^3
         \left(1-\frac9{x^2}+\frac5{x^3}\right)}\cdot
         \frac{x^4\left(1+\frac{10}x-\frac{9}{x^2}+\frac{11}{x^3}+
                 \frac5{x^4}\right)}{x^2\left(1+\frac1x-\frac{9}{x^2}
                \right)}\right]\\
 =\lim_{x\to\infty}\left[\frac{x^5\left(1-\frac2x\right)
                                  \left(1+\frac{10}x-\frac{9}{x^2}+
                                  \frac{11}{x^3}+\frac5{x^4}\right)}
                     {x^5\left(1-\frac9{x^2}+\frac5{x^3}\right)
                      \left(2+\frac1x-\frac{9}{x^2}\right)}\right]\\
=\lim_{x\to\infty}\left[\frac{\left(1-\frac2x\right)
                                  \left(1+\frac{10}x-\frac{9}{x^2}+
                                  \frac{11}{x^3}+\frac5{x^4}\right)}
                     {\left(1-\frac9{x^2}+\frac5{x^3}\right)
                      \left(2+\frac1x-\frac{9}{x^2}\right)}\right]
=\frac{1\cdot1}{1\cdot2}=\frac12.
\end{multline*}
\item Another method is to observe what the leading terms of the
      numerator and denominator polynomials would be if we were
      to multiply and simplify them.  For a limit at infinity, as
      we know we need only look at the highest-order terms in the
      numerator and denominator:
\begin{multline*}
\lim_{x\to\infty}\left[
            \frac{x-2}{x^3-9x+5}\cdot\frac{x^4+10x^3-9x^2+11x+5}
{2x^2+x-9}\right]
 =\lim_{x\to\infty}\frac{x^5+\cdots-10}{2x^5+\cdots-45}=\frac12.
\end{multline*}
The highest- and lowest-order terms are the easiest to compute for
a polynomial product (whereas---recall---the intermediate-order terms may
be complicated sums).  In fact it is only the highest-order terms which
are relevant, again, {\bf because} the limit is at infinity.
\end{enumerate}

\eex


Next we consider what to do if our partition of the limit's
function yields subexpressions whose limits do not necessarily exist.
It is true that knowing that one of the component limits does not exist 
can sometimes allow us to conclude that the entire limit
does not.  However this is not always the case.  In the
next example we give an argument where the nonexistence of
a component limit can, in that context, imply nonexistence
of the full limit.  We follow that example with
one in which nonexistence of a component limit does not wreck the
full limit.  Both types should become intuitive, but the perennial lesson
that we must be careful not to be too cavalier with our limit 
arguments should be apparent below.
\bex Suppose that $\ds{\lim_{x\to a}f(x)=5}$ and 
$\ds{\lim_{x\to a}g(x)}$ D.N.E.
Then 
$$\lim_{x\to a}[f(x)+g(x)]\overset{5+\text{DNE}}{\llongeq} D.N.E.$$
To see this, we can argue that since $g(x)$ is not approaching a 
well-defined limit value
for whatever reason (perhaps being 
undefined near $x=a$, or oscillating,
or having different left and right limits), then
adding $f(x)$, which {\bf is} approaching a number, will not
compensate for the behavior of $g(x)$, and the final limit can not
exist.
A more rigorous argument is given next.

\begin{proof}
Suppose again $\lim_{x\to a}f(x)=5$ and $\lim_{x\to a}g(x) $ D.N.E.
We will  prove by contradiction that
$\lim_{x\to a}[f(x)+g(x)]$ can not exist, for suppose that it does.
Then according to our Theorem~\ref{UsualLimitTheorems},
since $\lim_{x\to a}[f(x)+g(x)]$ exists (by our assumption to
be contradicted), we have
\begin{alignat*}{3}
f(x)+g(x)\longto L&\implies -f(x)+(f(x)+g(x))\longto-5+L\qquad&&
                  \text{(by (i))}\\
  &\implies (-f(x)+f(x))+g(x)\longto -5+L&&\text{(algebra)}\\
  &\implies (0+g(x))\longto-5+L &&\text{(algebra near limit point)}\\
  &\iff g(x)\longto -5+L\text{ exists}&&\text{(algebra).}
\end{alignat*}
But that contradicts our original information that $\lim_{x\to a}g(x)$
must not exist.  Thus we have to conclude that our assumption
$\lim_{x\to a}[f(x)+g(x)]$ exists---which leads to a 
contradiction---must be false, and so $\lim_{x\to a}[f(x)+g(x)]$  does not 
exist, q.e.d.\footnote{%%%
%%%% FOOTNOTE
Note how we used $P\longrightarrow(\sim P)\implies\sim P$. 
%%%% END FOOTNOTE
}\end{proof}
\eex

In the above example, the fact that the limit of $f(x)$ was
finite meant that it could not---through simple addition---compensate
for ``bad behavior'' of $g(x)$ in the limit.  It is possible,
however, for $f$ to still compensate. $f$ can also simply dominate
if $g(x)$ is bounded and $f(x)$ blows up.  (The reader may wish
to recall
(\ref{B/Infinity=0})--(\ref{B-Infinity=-Infinity}), 
page~\pageref{B/Infinity=0} as we work the
next example.)

\bex
Suppose that $f(x)\longto\infty$ and $|g(x)|\le M$ for
$x$ near $a$, some real $M>0$ (and real, therefore finite).  
Then we employ a Sandwich Theorem
argument, with  $-M+f(x)\le f(x)+g(x)\le M+f(x)$, with 
the first and third terms approaching $\infty$ (though
the first of the three is enough) carrying $f(x)+g(x)$
to an infinite limit as well.  We could write
$$\lim_{x\to a}[f(x)+g(x)]\overset{\infty+B}{\llongeq}\infty.$$
For a specific example, consider:
$\ds{\lim_{x\to\infty}(x+\sin x)\overset{\infty+B}{\llongeq}\infty}$.
\eex
Actually we worked exactly this example during the discussion
of the form $B+\infty$, introduced on page~\pageref{B+Infinity=Infinity}.

The lesson to be gleaned from the above examples is that 
if one part of the function ``inside the limit'' has nonexistent
limit (for the prescribed approach in the independent variable),
sometimes we can conclude the same about the
whole limit and sometimes we can not.  We usually need to dig 
deeper into the behavior of the other parts of the function, and
take into account how their influences combine.  Sometimes the form
is enough to determine the actual limit (or its nonexistence).
With experience, the various cases become 
intuitive. (Recall also Example~\ref{GreatSandwichTheoremExample},
page~\pageref{GreatSandwichTheoremExample}
and its associated Figure~\ref{XSin1/X}.)

\subsection{A Trigonometric Limit}
\begin{figure}
\begin{center}
\begin{pspicture}(-2.25,-2.25)(9,2.7)
\psset{xunit=1.5cm,yunit=1.5cm}
\psaxes[ticks=none,labels=none]{<->}(0,0)(-1.5,-1.5)(1.5,1.55)
\pscircle(0,0){1.5}
\psline{->}(.5,0)(.5,.866025404)
 \rput{-90}(.625,.4){$\sin\theta$}
\psline[linestyle=dashed]{->}(0,0)(1,1.732050808)
\psarc[linewidth=2.5pt]{->}(0,0){1.5}{0}{60}
\pscircle[fillstyle=solid,fillcolor=black](.5,.866025404){.075}
  \rput(.5,1.05){$P$}
  \rput(.8,.8){$\theta$}
  \rput{60}(.2,.6){1}
\psline(.4,0)(.4,.1)(.5,.1)
\psline{->}(1,0)(1,1.732050808)
\rput{-90}(1.125,.85){$\tan \theta$}
%%%
\pspolygon[fillstyle=solid,fillcolor=gray](2.5,.866025404)(2,0)(2.5,0)
  \rput{-90}(2.625,.4){$\sin \theta$}
   %\rput{60}(2.1,.5){1}
   \rput(2.25,-.13){$\cos \theta$}
\pswedge[fillstyle=solid,fillcolor=gray](3,0){1.5}{0}{60}
    \rput{60}(3.1,.5){1}
    \rput(4,.5){$\theta$}
    \rput(3.5,-.13){$1$}
\pspolygon[fillstyle=solid,fillcolor=gray](4.5,0)(5.5,0)%
(5.5,1.732050808)(4.5,0)
  \rput{-90}(5.625,.85){$\tan \theta$}
  \rput(5,-.13){$1$}
\rput(1.9,-1){$\ds{\frac12\cos \theta\sin \theta}$}
  \rput(2.8,-1){$\le$}
\rput(3.5,-1){$\ds{\frac12(1)^2\theta}$}
  \rput(4.2,-1){$\le$}
\rput(5,-1){$\ds{\frac12\tan \theta}$}
\end{pspicture}
\end{center}
\caption{Illustration of relative sizes of $\frac12\cos \theta\sin \theta$,
$\frac12\theta$ and $\frac12\tan \theta$ for
an angle $\theta\in[0,\pi/2)$.  Note that each area is a superset
of any preceding area illustrated above, as most clearly illustrated
in the far-left figure.
Recall also that $\theta=s/r$, where $s$ is the directed arc length and
$r$ the radius, so on the unit circle $\theta=s/1=s$.
Also recall that the area of a circular wedge is given 
by $A=\frac12r^2\theta$.}\label{SinX/X->1FigureI}
\end{figure}
An interesting limit, which is surprisingly useful for
future results, is the following:
\begin{theorem}With $\theta$ given in radians, we have the following
limit:
\begin{equation}\lim_{\theta\to0}\frac{\sin \theta}{\theta}=1.
\label{SinX/XLimitTheoremEquation}
\end{equation}\label{SinX/XLimitTheorem}\end{theorem}
\begin{proof}

The proof relies upon the Sandwich Theorem and a geometric observation
which is given in Figure~\ref{SinX/X->1FigureI}.  In that figure,
$\theta$ is the radian measure of the angle which terminates in the
first quadrant.  The observation involves three areas defined by
this angle $\theta$: a right triangle, contained within a circular wedge,
which is in turn contained in another right triangle.  The 
smaller triangle has ``base'' $\cos \theta$ and ``height'' $\sin \theta$,
and thus has area $\frac12\cos \theta\sin \theta$.  For the circular wedge,
recall that a wedge with radius $r$ and radian-measure angle
$\theta$ has area $\frac12r^2\theta$.\footnote%
%%% FOOTNOTE
{To help remember this formula, think of what this means
if $\theta=2\pi$.%%
%%% END FOOTNOTE
}  The other triangle has base 1 and height $\tan \theta$.
To see this, note that it is similar to the smaller triangle,
and so we have the proportion of sides:
$\sin \theta/\cos \theta=h/1$, where $h$ is the height of the
larger triangle.  It follows that $h=\tan \theta$.  Thus the larger
triangle has area $\frac12\cdot1\cdot\tan \theta$.  Now for 
$\theta\in[0,\pi/2)$, we have 
$$\frac12\cos \theta\sin\theta \le\frac12\theta\le\frac12\tan \theta.$$
As $\theta\to0^+$, we have $\sin \theta>0$ so we can not only
multiply by  $2$, but also then divide by $\sin \theta$, 
giving us
\begin{equation}
\cos\theta\le\frac{\theta}{\sin \theta}\le\frac1{\cos\theta}.
\label{InequalityForBasicTrigLimitProof}
\end{equation}
This gives us a Sandwich Theorem type of argument as $\theta\to0^+$:

\begin{center}
\begin{pspicture}(-2.5,0)(4.5,2.2)
  \rput(-2.2,2){As $\theta\to0^+$\,:}
  \rput(0,1.85){$\ds{
\underbrace{\cos\theta\vphantom{\frac{\theta}{\sin\theta}}}}$}
  \rput(1,2){$\le$}
  \rput(2,2){$\ds{\frac{\theta}{\sin \theta}}$}
  \rput(3,2){$\le$}
  \rput(4,1.9){$\ds{\underbrace{\frac{1}{\cos \theta}}}$}
\psline{->}(0,1.2)(0,.5)
  \rput(0,0){$1$}
\psline{->}(4,1.25)(4,.5)
  \rput(4,0){$1$}
\end{pspicture}
\end{center} 
giving us ${\frac{\theta}{\sin \theta}\longrightarrow 1}$ as 
$\theta\to0^+$, i.e.,
\begin{equation}
\lim_{\theta\to0^+}\frac{\theta}{\sin \theta}=1.
\label{Right-SidedTheta/SineThetaLimit}
\end{equation}
Next we use dispatch with the left-side limit.
In fact the same inequality (\ref{InequalityForBasicTrigLimitProof})
holds as $\theta\to0^-$, because all three expressions
are the same if we replace $\theta$ with $-\theta$.
This follows because all three functions are ``even,''
i.e., $\cos(-\theta)=\cos\theta$, $(-\theta)/\sin(-\theta)=\theta/\sin\theta$,
and $1/\cos(-\theta)=1/\cos\theta$, and $\theta\to0^+\iff(-\theta)\to0^-$.
With this one can perform the above computations with $(-\theta)\to0^+$,
and thus $\theta\to0^-$.

Perhaps a less convoluted approach is to more explicitly
borrow the substitution method from upcoming
Subsection~\ref{LimitsBySubstitutionSubsection}.
Here we let $\phi=-\theta$ so that $\theta\to0^-\iff\phi\to0^+$.
Thus
\begin{equation}
\lim_{\theta\to0^-}\frac{\theta}{\sin\theta}
=\lim_{\phi\to0^+}\frac{-\phi}{\sin(-\phi)}
=\lim_{\phi\to0^+}\frac{-\phi}{-\sin\phi}
=\lim_{\phi\to0^+}\frac{\phi}{\sin\phi}=1,
\label{Left-SidedTheta/SineThetaLimit}
\end{equation}
the last limit being, of course, 
(\ref{Right-SidedTheta/SineThetaLimit}) with the variable renamed.
Putting (\ref{Right-SidedTheta/SineThetaLimit}) together with
(\ref{Left-SidedTheta/SineThetaLimit}), of course, gives us
\begin{equation}\lim_{\theta\to0}\frac{\theta}{\sin \theta}=1.
\label{Theta/SinThetaLimit}\end{equation}
Finally, we can then get our result based upon the above limit,
looking at the reciprocal function:
$$\lim_{\theta\to0}\frac{\sin \theta}{\theta}=\lim_{\theta\to0}
 \frac1{\left(\frac{\theta}{\sin \theta}\right)}
\overset{1/1}{\longeq}1,\qquad\text{q.e.d.}$$
\end{proof}



Notice that the limit we proved, (\ref{SinX/XLimitTheoremEquation}),
says something about how fast $\sin \theta$ approaches zero
as $\theta$ approaches zero: that $\sin \theta$ and $\theta$ approach
zero at approximately the same rate.  In fact, many
physics problems use the approximation $\sin\theta\approx\theta$
(following from $(\sin\theta)/\theta\approx 1$)
for $|\theta|$ small and in radians.  This  approximation  is graphed
in Figure~\ref{GraphOfSinXAndX}, there using $x$ instead
of $\theta$ as the independent (domain) variable. We will see how this 
very important approximation, and the underlying limit,
arise from other calculus techniques
in later chapters.%\footnote{%
%\begin{center}
%\begin{pspicture}(-6,-2)(6,2)
%\psset{xunit=.75,yunit=.75}
%\psaxes[labels=none,Dx=3.1415926536,Dy=1]{<->}(0,0)(-7,-2)(7,2)
%\psplot[plotpoints=1000]{-7}{7}{x 180 mul 3.1415926536 div sin}
%\psplot{-2}{2}{x}
%\rput(-6.28,-.5){$-2\pi$}
%\rput(-3.14,-.5){$-\pi$}
%\rput(3.14,-.5){$\pi$}
%\rput(6.28,-.5){$2\pi$}
%\rput(-.4,1){$1$}
%\rput(-.5,-1){$-1$}
%\end{pspicture}
%\end{center}}
\footnote{%%
%%% FOOTNOTE
While (\ref{Theta/SinThetaLimit}) is the immediate result of our
analysis, and is interesting in its own right,
most texts (as here) go ahead and present the reciprocal
limit (\ref{SinX/XLimitTheoremEquation}).  The reason
is that $\lim_{\theta\to0}(\sin\theta/\theta)$ 
gives a (perhaps) more intuitive comparison of the behavior
of $\sin\theta$ {\it versus} that of the independent variable
$\theta$.  We have already had many limits of ratios of 
functions $f(x)/g(x)$ which, in a sense, compare the two
functions' behaviors in the sense of limits.  A very
useful way to analyze a function is to compare it to its
input variable by  ratios $f(x)/x$,  $f(x)/(x-a)$, or
$(f(x)-f(a))/(x-a)$, 
for examples.  Though
this can often be accomplished instead by looking the
reciprocals of these, it is less intuitive to do so.
}
%%%% END FOOTNOTE
\begin{figure}
\begin{center}
\begin{pspicture}(-6,-2)(6,2)
\psset{xunit=.75,yunit=.75}
\psaxes[labels=none,Dx=3.1415926536,Dy=1]{<->}(0,0)(-7,-2)(7,2)
\psplot[plotpoints=1000]{-7}{7}{x 180 mul 3.1415926536 div sin}
\psplot{-2}{2}{x}
\rput(-6.28,-.5){$-2\pi$}
\rput(-3.14,-.5){$-\pi$}
\rput(3.14,-.5){$\pi$}
\rput(6.28,-.5){$2\pi$}
\rput(-.4,1){$1$}
\rput(-.5,-1){$-1$}
\end{pspicture}
\end{center}

\caption{Partial graphs of $y=x$ and $y=\sin x$.  
Since $(\sin x)/x\longrightarrow 1$ as $x\to 0$, 
we get $(\sin x)/x\approx 1$ for $x$ near zero,
and thus $\sin x\approx 1\cdot x$ for small $x$.
In the graph above we see how quickly $\sin x$ 
and $x$ become close enough that the limited resolution
of the graphic rendering device makes it difficult
to distinguish the two functions for small $x$.
(However, it should be noticed that the two functions
$x$ and $\sin x$ only agree at $x=0$.  Indeed,
a closer examination of Figure~\ref{SinX/X->1FigureI}
on page~\pageref{SinX/X->1FigureI}
shows that for $\theta>0$ we have $\theta>\sin\theta$, 
and for $\theta<0$ we have $\theta<\sin\theta$.)}
\label{GraphOfSinXAndX}
\end{figure}








Many other interesting limits follow from this limit 
(\ref{SinX/XLimitTheoremEquation}), as we can see in the following example.
Note that the second limit computation below utilizes
the trigonometric identities $(1-\cos x)(1+\cos x)=1-\cos^2x=\sin^2x$.
\bex Consider the following limits, which require
both our basic trigonometric limit (\ref{SinX/XLimitTheoremEquation})
and our omnibus limit theorem, Theorem~\ref{UsualLimitTheorems}
we began the section with, on page~\pageref{UsualLimitTheorems}.
\begin{itemize}
\item $\ds{\lim_{x\to0}\frac{\tan x}x=\lim_{x\to0}\frac{\sin x}{x\cos x}
=\lim_{x\to0}\left[\frac{\sin x}{x}\cdot\frac1{\cos x}\right]
\overset{1\cdot\frac11}{\longeq}1}$.
\item $\ds{\lim_{x\to0}\frac{1-\cos x}{x}
\overset{0/0}{\longeq}\lim_{x\to0}\left[\frac{1-\cos x}{x}
 \cdot\frac{1+\cos x}{1+\cos x}\right]
=\lim_{x\to0}\frac{1-\cos^2x}{x(1+\cos x)}
=\lim_{x\to0}\frac{\sin^2x}{x(1+\cos x)}}$

\qquad\qquad
$\ds{=\lim_{x\to0}\left[\frac{\sin x}{x}\cdot\frac{\sin x}{1+\cos x}\right]
\overset{1\cdot\frac02}{\longeq}1\cdot\frac02=0}$.
\end{itemize}
\eex
The first limit is also used in physics in the form
$\tan\theta\approx\theta$ for $|\theta|$ small.
The second limit occurs enough to warrant being set aside as its own
theorem, though as we see above it is easily derived
from the more basic $\lim_{\theta\to0}\frac{\sin\theta}\theta=1$. 
\begin{theorem}The following limit (proved above) holds:
\begin{equation}\lim_{\theta\to0}\frac{1-\cos \theta}{\theta}=0.
\label{(1-CosX)/(X)Limit}\end{equation}
\end{theorem}
In other words, $1-\cos \theta$ shrinks to zero faster than
$\theta$ does, as $\theta\to0$.  This is reasonable when we see the
graphs of $y=1-\cos x$ and $y=x$, given (as darker curves) in
Figure~\ref{GraphOf1-CosXAndX}.\footnote{%%%
%%%%%%%%%% FOOTNOTE
One could also say the $\cos \theta\to 1$ very rapidly as $\theta\to0$,
but of course neither description is as precise as (\ref{(1-CosX)/(X)Limit}).
%%%%%%%%%% END FOOTNOTE
}

\begin{figure}
\begin{center}
\begin{pspicture}(-6,-2)(6,2)
\psset{xunit=.75,yunit=.75}
\psaxes[labels=none,Dx=3.1415926536,Dy=1]{<->}(0,0)(-7,-2)(7,2)
\psplot[plotpoints=1000]{-7}{7}{1 x 180 mul 3.1415926536 div cos sub}
\psplot{-2}{2}{x}
\parabola[linewidth=.3pt](-2,2)(0,0)
%\psplot[linewidth=.3pt]{-2}{2}{x dup mul 2 div}
\rput(-6.28,-.5){$-2\pi$}
\rput(-3.14,-.5){$-\pi$}
\rput(3.14,-.5){$\pi$}
\rput(6.28,-.5){$2\pi$}
\rput(-.4,1){$1$}
\rput(-.5,-1){$-1$}
\end{pspicture}
\end{center}

\caption{Partial graphs of $y=x$ and $y=1-\cos x$,
showing how $1-\cos x$ approaches zero faster than $x$ as 
$x\to 0$---so
much so that $(1-\cos x)/x\longrightarrow0$ (see (\ref{(1-CosX)/(X)Limit})).
The graph of $y=\frac12x^2$ is also given (thinner curve),
illustrating how $(1-\cos x)/x^2\approx\frac12$, i.e., 
$\cos x\approx1-\frac12x^2$ for $x$ small, as 
derived in Example~\ref{(1-CosX)XX->1/2Example}.}
\label{GraphOf1-CosXAndX}
\end{figure}




For the rest of this section, we will assume (\ref{SinX/XLimitTheoremEquation})
and (\ref{(1-CosX)/(X)Limit}) and compute other trigonometric limits
based upon these, the work from previous sections, and
Theorem~\ref{UsualLimitTheorems}.  As with all limits, it is 
important to be careful and not jump to incorrect conclusions;
our basic trigonometric limits 
(\ref{SinX/XLimitTheoremEquation}) and (\ref{(1-CosX)/(X)Limit}),
$$\lim_{\theta\to0}\frac{\sin\theta}\theta=1,
\qquad\qquad
\lim_{\theta\to0}\frac{1-\cos\theta}\theta=0,$$
are very specific in their scopes.  Moreover, with trigonometric limits,
it is sometimes still necessary to exploit the algebraic identities among
the functions.  Consider the following (perhaps surprising) 
trigonometric limit calculation:


\bex Compute $\ds{\lim_{x\to0}\frac{1-\cos x}{x^2}}$.

\underline{Solution}: A first, perhaps more obvious attempt is quickly
seen to be a dead-end:
$$\lim_{x\to0}\frac{1-\cos x}{x^2}=
\lim_{x\to0}\left[\frac{1-\cos x}x\cdot\frac1x\right]
\overset{0\cdot(\pm\infty)}{\lllongeq}?,$$
of the indeterminate form $0\cdot(\pm\infty)$.
As happens so frequently with limits, 
we look for some other way of rewriting the function.
The usual method of computing this limit is to again exploit the fact
that 
$$(1-\cos x)(1+\cos x)=1-\cos^2x=\sin^2x.$$
By multiplying the function inside the limit by
$(1+\cos x)/(1+\cos x)$, we can compute the limit as follows:
\begin{align*}\lim_{x\to0}\frac{1-\cos x}{x^2}&
 =\lim_{x\to0}\left[\frac{1-\cos x}{x^2}
 \cdot\frac{1+\cos x}{1+\cos x}\right]=
\lim_{x\to0}\frac{1-\cos^2x}{x^2(1+\cos x)}
=\lim_{x\to0}\frac{\sin^2x}{x^2(1+\cos x)}\\
&=\lim_{x\to0}\left[\frac{\sin x}x\cdot\frac{\sin x}{x}\cdot\frac1{1+\cos x}
 \right]
=1\cdot1\cdot\frac1{1+1}=\frac12.
\end{align*}
\label{(1-CosX)XX->1/2Example}\eex
In the last step of the above example, we used 
Theorem~\ref{UsualLimitTheorems} (the limit of a product being the product
of the limits, when they exist), and the fact that the factor $1/(1+\cos x)$
is continuous at $x=0$.


One could argue using this limit that, for $|x|$ small,
$1-\cos x\approx\frac12x^2$, which is also illustrated in 
Figure~\ref{GraphOf1-CosXAndX}.  This fact
we will derive later in the form
$\cos x\approx 1-\frac12x^2$, which is sometimes used in applications.
It is more accurate than the earlier approximation that
$\cos x\approx 1$ for $x$ small.

We will compute many more trigonometric limits in this section, but
first we need a new limit technique which we introduce next.

\subsection{Limits by Substitution\label{LimitsBySubstitutionSubsection}}
To bring our analytical methods of computing limits to the next level,
we now develop some substitution techniques.
These techniques require delicacy, but with care they are quite
powerful and sophisticated.
To motivate the discussion, we first give two examples below:
\bex Compute $\ds{\lim_{x\to0}\frac{\sin5x}{x}}$.

\underline{Solution}: The usual method is to multiply by $\frac55$
as below.
$$\lim_{x\to0}\frac{\sin5x}x=\lim_{x\to0}\frac{5\sin5x}{5x}
   =\lim_{x\to0}\left[5\cdot\frac{\sin5x}{5x}\right]=5\cdot1=5.$$
\label{FirstSineSubstitionLimitExample}\eex
Notice that the original limit was of the form ``$(\sin0)/0$''
(i.e., $0/0$) which is indeterminate.  It is important that 
in our basic trigonometric limit (\ref{SinX/XLimitTheoremEquation})
the two ``zeros'' are terms approaching zero at the same rate
(though even that is not always quite enough, as we will eventually see).
By multiplying the fraction by 5/5, we were able to get a form
``$5\cdot[(\sin0)/0]$'' where the rates of the ``zeros'' were
the same.  Most presentations of the computation of the above 
limit are exactly as given above, but it is to be understood that
we are transforming this by way of a substitution.  One might 
instead write
$$\lim_{x\to0}\frac{\sin5x}x=\lim_{x\to0}\left[5\cdot\frac{\sin5x}{5x}\right]
  =\lim_{(5x)\to0}\left[5\cdot\frac{\sin5x}{5x}\right]
  =5\cdot1=5,$$
or
$$\lim_{x\to0}\frac{\sin5x}x=\lim_{x\to0}\left[5\cdot\frac{\sin5x}{5x}\right]
=\lim_{\theta\to0}\left[5\cdot\frac{\sin\theta}{\theta}\right]=5\cdot1=5,$$
where $\theta=5x$, and $\theta\to0\iff x\to0$.  The nature of the 
mechanism whereby $\theta\to0\iff x\to0$ is crucial, but we will 
explain this in due course.  The next example displays a slightly more
sophisticated argument.
\bex Compute $\ds{\lim_{x\to0}\frac{\cos x^2-1}{x^4}}$.  (Compare
to Example~\ref{(1-CosX)XX->1/2Example},
page~\pageref{(1-CosX)XX->1/2Example}.)

\underline{Solution}: Here we will make a substitution $\theta=x^2$,
so that $x\to0\implies\theta=x^2\to0^+$.  Then we can write
\begin{align*}\lim_{x\to0}\frac{\cos x^2-1}{x^4}
&\overset{0/0}{\longeq}\lim_{\theta\to0^+}\frac{\cos\theta-1}{\theta^2}
 =\lim_{\theta\to0^+}\left[\frac{\cos\theta-1}{\theta^2}\cdot
\frac{\cos\theta+1}{\cos\theta+1}\right]
=\lim_{\theta\to0^+}\frac{\cos^2\theta-1}{\theta^2(\cos\theta+1)}\\
&=\lim_{\theta\to0^+}\frac{-\sin^2\theta}{\theta^2(\cos\theta+1)}
=\lim_{\theta\to0^+}\left[-\frac{\sin\theta}\theta
 \cdot\frac{\sin\theta}\theta\cdot\frac1{\cos\theta+1}\right]
=-1\cdot1\cdot\frac1{1+1}=-\frac12.
\end{align*}\label{FirstCosineSubstitutionLimitExample}
\eex
Notice that in the above example we used the fact that
full limits imply one-sided limits.  Specifically, 
above we used that
$$\lim_{\theta\to0}\frac{\sin \theta}\theta
=1\implies \lim_{\theta\to0^+}\frac{\sin \theta}{\theta}=1.$$

%The following describes a few situations in which variable substitution
%within limit computations are valid.  
%We will have more situations shortly thereafter.
%The definition  is very technical, but the jist
%of it is simpler:  we can make
%variable substitutions in limits as long as the original
%``path'' of approach implies a new, legitimate path
%of approach in the substituted variable.
%%
%
%\begin{definition}
%Suppose that $\ds{\lim_{x\to a}u(x)=\beta}$.  Then 
%we say $x\to a\implies u\to\beta$ {\bf properly} if and only if, furthermore, 
%the following three criteria hold:
%\begin{enumerate}
% \item $u(x)$  is continuous (as a function of $x$) 
%               on the path for which $x\to a$:
%      \begin{enumerate}
%      \item If $a$ and $\beta$ are finite, this  means $u(x)$ is continuous on
%             $(a-d,a)$ and $(a,a+d)$ for some $d>0$.
%       \item If $a=\infty$, this means $u(x)$ is continuous on some
%             interval $(M,\infty)$.
%       \item If $a=-\infty$, this means $u(x)$ is continuous on some
%             interval $(-\infty,N)$.
%       \end{enumerate}
% \item $u(x)\ne \beta$ for all $x$ 
%       on at least one such path (where we may need to 
%       take a smaller $d$, greater $M$ or lesser $N$ to guarantee this).
% \item If $a$ and $\beta$ are finite, we also require that,
%       $(\forall\epsilon,\delta>0))
%                      (\exists x_1,x_2\in(a-\delta,a+\delta)-\{a\})$ such
%         that
%                       $$\left[
%                       \left(\vphantom{\frac11}
%                           u(x_1)\in(\beta-\epsilon,\beta)\right)
%                           \bigwedge\left(\vphantom{\frac11}
%                           u(x_2)\in(\beta,\beta+\epsilon)\right)\right].$$%
%%
%
%\end{enumerate}\label{DefOfX->A=>U->BProperly}
%\end{definition} 

Now we consider circumstances where we can make a substitution
to compute a limit.  First we take another look at
what it means for $x\to a$. 
(Subsection~\ref{SubsectionOnIdeaOfApproach} began this discussion.)
When we write $x\to a$ under ``lim,'', we understand this to mean that 
$x$ gets arbitrarily close to {\bf but not equal to} the
value $a$.  But we also assume that $x$ does not
``skip over'' any values as we approach $a$ either, as we 
see from the definition of $\lim_{x\to a}f(x)$,
as for example in the case this limit is a finite number $L$:
$$(\forall\epsilon>0)(\exists\delta>0)
  (\forall x)[\underbrace{0<|x-a|<\delta}_{x\in(a-\delta,a)\cup(a,a+\delta)}
\longrightarrow|f(x)-L|<\epsilon].$$
In order to substitute algebraically to produce
another limit, say ${\lim_{u\to\beta}F(u)}$
and claim it is the same as ${\lim_{x\to a}f(x)}$,
we would like to be sure that
$x\to a\implies u\to\beta$, and that the latter ``approach''
is still somehow a ``proper'' approach.  
Usually what is obvious is only that
$x\to a\implies u\to \beta$ in the
sense that $\lim_{x\to a}u=\beta$, which allows for the approach
of $u$ to $\beta$ to be quite sloppy.
It may be that the approach
$u$ takes to $\beta$ is one-sided, or has gaps as $x\to a$,
or actually {\it achieves} $u=\beta$ while we {\it require}
$x\ne a$.  Indeed when we developed the convention
that $\lim_{x\to a}u=\beta$ would also be written
$x\to a\implies u\to\beta$, we interpreted the approach
of $u$ to $\beta$ quite loosely, while
that of $x$ to $a$ was more strict.
To force $u\to\beta$ to occur  in the same way that
$x\to a$ requires much more structure in the relationship 
between $x$ and $u$ than we usually wish  to have to
accommodate.  One notable example where this does happen
is when $u=mx+b$, where $m\ne0$, giving that $x\to a\iff u\to(ma+b)$,
and both approaches are proper in every way.  Another example
is $x\to0\iff x^2\to0^+$. From there it can get quite complicated.

What we can do to produce a useful theorem
is to not make a strong statement about the relationship between $x$ and $u$,
but rather qualify the result in a different way
(which also makes a proof is easier to formulate), still yielding
a useful result.  What we settle on here is the following,
the proof of which is similar to that of 
Theorem~\ref{LimitOfCompositionOfFunctionsTheorem},
page~\pageref{LimitOfCompositionOfFunctionsTheorem},
and is left as an exercise for the interested reader.
\begin{theorem}{\bf (Limit Substitution Theorem)}
Suppose that the variables $x$ and $u$ are related is such a way that
\begin{enumerate}[(a)]
\item $\ds{\lim_{x\to a}u=\beta}$,
\item $(\exists d>0)(\forall x)[0<|x-a|<d\longrightarrow (u\ne\beta)]$,
\item $(\exists d>0)(\forall x)[0<|x-a|<d\longrightarrow (f(x)=F(u))]$.
\end{enumerate}
Then 
\begin{equation}
\lim_{x\to a}f(x)=\lim_{u\to\beta}F(u)\qquad\qquad\text{if this second
limit exists.}\label{EqForTheoremOnSubForLimits}\end{equation}
\label{TheoremOnSubForLimits}\end{theorem}
There are many theorems we will come across where we have an equality
like (\ref{EqForTheoremOnSubForLimits})
which is qualified by the criterion that the second quantity 
exists, or otherwise makes sense in the context.  To remove that
criterion would require a much more complicated set of conditions
than (a)--(c) above.
That the second limit exists is key, but also that
$u\to\beta$ to be 
an approach of a similar manner in the sense that
not only should $u\to\beta$, but $u\ne \beta$
as $x\to a$ according to (b).\footnote{%
%%%%% FOOTNOTE
 Later in the subsection we will 
have an example to show why (b) is necessary.
In that example,  $x\to a\implies u\to\beta$, but
$u$ oscillates, passing through the value $\beta$
infinitely many times as $x\to a$.  In that
example the na\"ive substitution
is invalid:  the new limit exists but the original does not.
%%%%% END FOOTNOTE
}
In fact, the validity of (a) and (c) usually are clear from the actual
algebraic substitution; it is (b) that requires a bit more scrutiny but
is also usually not difficult to see.
\bex Compute $\ds{\lim_{x\to\frac{\pi}{2}}\frac{\sin\left(x-\frac{\pi}2
                      \right)}{x-\frac{\pi}2}}$.

Here we make the substitution $u=x-\frac{\pi}2$, so that
$x\to\frac{\pi}2\implies u\to0$ in the sense of the hypotheses
(a)--(c) of the theorem.  Thus we can write (as long as the final 
limit exists!)
$$\lim_{x\to\frac{\pi}2}\frac{\sin\left(x-\frac{\pi}2\right)}
        {x-\frac{\pi}2}=\lim_{u\to0}\frac{\sin u}u=1.$$
\eex

In the earlier Examples \ref{FirstSineSubstitionLimitExample}
and \ref{FirstCosineSubstitutionLimitExample}
 above we used $\theta$ to play the role of $u$
in the theorem, but that is mostly a matter of taste.  We will usually use
$u$ because it is the traditional variable of substitution
later in the calculus.\footnote{%
%%%%% FOOTNOTE
Actually $\theta$ is becoming increasingly common as a variable
of substitution, and we will have occasion
to use it as we did in our first substitution examples.
%%%%% END FOOTNOTE
} 



The theorem can be extended in obvious ways to cases
such as
\begin{alignat*}{2}
&x\to a&&\implies u\to\infty\\
&x\to a&&\implies u\to\beta^+\\
&x\to a^+&&\implies u\to\beta^+
\end{alignat*}
and so on.%\footnote{%
%%% FOOTNOTE
%Note that we would  replace criterion (3) for these other 
%cases.  For instance, if $\beta$ is finite and $x\to a^\pm$,
%the $u\to\beta^+$ properly would mean only the
%existence of the $x_2$ is required.  If $a,\beta=\infty$,
%5we would have
%$$(\forall M,N)(\exists x_1)\left[(x_1>M)\longrightarrow(u(x_1)>N)
% \vphantom{X_X^X}\right].$$  We will still require continuity of $u(x)$
%as $x$ approaches $a$ in the prescribed manner. (Though there are
%cases where continuity is not required, but they are not of interest
%to us in this text.)
%%% END FOOTNOTE
%}



It should be pointed out that if $x\to a$ implies a 
``proper'' one-sided approach, for instance $u\to\beta^+$,
then we can perform a substitution based upon that,
except then we would compute the one-sided
limit $\lim_{u\to\beta^+}F(u)$. This was the case
in Example~\ref{FirstCosineSubstitutionLimitExample},
page~\pageref{FirstCosineSubstitutionLimitExample}. Furthermore, 
a one-sided approach in $x$ to $a$ may yield a 
proper approach in a variable $u$ of some kind.
Infinite ``approaches'' can also arise from substitutions,
or give rise to substitutions.



%  It should also be pointed out that the theorem's conclusion
%(\ref{SubstitutionForLimitsEquation}) also holds in many 
%one-sided cases, as in Example~\ref{FirstCosineSubstitutionLimitExample}, 
%and ``at infinity'' cases, as case of
%the latter being represented by an example
%below.  The keys to being able to make the substitution in the
%general case are
%\begin{itemize}
%\item that the algebraic substitution is valid, so the original expression,
%      along with the substitution, implies the substitute expression
%      algebraically, and that
%\item the approach of the limit point in the original, being an approach
%      which does not allow the original variable to actually equal
%      the limit point value, implies that the substitution variable
%      {\bf approach but not achieved} the implied approached value
%      of the new limit point.
%\end{itemize}
%The method is ultimately intuitive, but its application is a skill
%which requires development.  In the next example the substitute limit
%variable blows up, so an infinity is approached but of course never 
%achieved.

\bex Consider $\ds{\lim_{x\to\frac{\pi}2^+}\frac{2\tan^2x+3\tan x+7}
                  {\tan^2 x-6\tan x+30}}$.

Here we let $u=\tan x$. Then $x\to\frac{\pi}2^+\implies u\to-\infty$.
(Because we will never have $u=-\infty$, we do not need an analog
to (b) in the theorem.)  Thus
$$\lim_{x\to\frac{\pi}2^+}\frac{2\tan^2x+3\tan x+7}
                  {\tan^2 x-6\tan x+30}
=\lim_{u\to-\infty}\frac{2u^2+3u+7}{u^2-6u+30}
=\lim_{u\to-\infty}\frac{\not{\!\!u^2}\left(2+\frac3u+\frac7{u^2}\right)}
                        {\not{\!\!u^2}\left(1-\frac6u+\frac{30}{u^2}\right)}
=2.$$\label{ExampleWhereTanX->-InftyW/Substitution}
\eex

The next example illustrates that if one type of indeterminate form
is not easily dealt with, an algebraic manipulation can likely
give one which is more easily computed.
\bex Compute $\ds{\lim_{x\to\infty}x\sin\frac1x}$.

\underline{Solution}: Note that $\frac1x\longto0^+$ as $x\to\infty$, so the 
form here is essentially $\infty\cdot\sin0=\infty\cdot0$ (more precisely,
$\infty\cdot\sin0^+=\infty\cdot0^+$), which
is indeterminate (see Example~\ref{InfinityTimesZeroExample},
page~\pageref{InfinityTimesZeroExample}).
However we can rewrite the limit with a power of $x$ in
the denominator, instead of having $x$ as a multiplicative factor.
Then we will perform a substitution and use 
(\ref{SinX/XLimitTheoremEquation}) for the final computation.
$$\lim_{x\to\infty}x\sin\frac1x
\underset{\ALG}{\overset{\infty\cdot0}{\llongeq}}
\lim_{x\to\infty}\frac{\sin\frac1x}{\frac1x} \qquad
  \text{(form $\sin0^+/0^+$)}.$$
Now we let $u=1/x$, so that $x\to\infty\implies u\to0^+$ properly,
so that
$$\lim_{x\to\infty}x\sin\frac1x
\underset{\ALG}{\overset{\infty\cdot0}{\llongeq}}
\lim_{x\to\infty}\frac{\sin\frac1x}{\frac1x}
=\lim_{u\to0^+}\frac{\sin u}u=1.$$
\eex

Substitution is a very powerful method, but sometimes the mechanics
of it become needlessly complicated and a certain amount of 
``hand-waving'' becomes appropriate.  For instance, depending upon the
author and the audience the $u$-limit above might be omitted,
but the substitution principle should be understood.
When we think of the limits
$$\lim_{\theta\to0}\frac{\sin\theta}{\theta}=1,
\qquad\qquad
\lim_{\theta\to0}\frac{1-\cos\theta}{\theta}=0,$$
what is important is that the ``$\theta$''  inside the sine and cosine
functions approaches (but never achieves!) zero at the same rate
as the ``$\theta$'' in the denominator.  Thus one may just write
$$\lim_{x\to0}\frac{\sin(\sin x)}{\sin x}
=1$$
since the substitution $\theta=\sin x$ gives us
$x\to0\implies\theta\to0$ properly, and $\lim_{\theta\to0}
\frac{\sin\theta}{\theta}=1$ is known.  
To be cautious one can explicitly write this substitution step:
$$\lim_{x\to0}\frac{\sin(\sin x)}{\sin x}
=\lim_{\theta\to0}\frac{\sin\theta}{\theta}=1,$$
where $\theta=\sin x\to0$ is a manner consistent with 
our theorem (as $x\to0$), as an examination of the graph (or just the nature)
of the sine curve indicates.

The next example shows how we can save some effort
by just noting the approaches to zero are at the same rate.
Still we should have the limit substitution theorem, and its
criteria (a)--(c) in mind.
We will show the careful substitution method, and then the
more terse argument.

\bex Consider the limit $\ds{\lim_{x\to0}\frac{1-\cos x^2}{x}}$.  Again
we know what this limit would be if we had $x^2$ in the denominator,
so we will rewrite the function in a form where that is the case,
and compensate in the numerator:
$$\lim_{x\to0}\frac{1-\cos x^2}{x}
  =\lim_{x\to0}\frac{x(1-\cos x^2)}{x^2}
  =\lim_{x\to0}\left[x\cdot\frac{1-\cos x^2}{x^2}\right].$$
At this point we could use a substitution, say $u=x^2$,
and so $u\to0\implies u\to0^+$, but we have different
expressions for our function as $x\to0^+$ and $x\to0^-$:
\begin{alignat*}{2}
\lim_{x\to0^+}\left[x\cdot\frac{1-\cos x^2}{x^2}\right]
 &=\lim_{u\to0^+}\left[\sqrt{u}\cdot\frac{1-\cos u}u\right]
  &&\overset{0^+\cdot0}{\llongeq}0,\\
\lim_{x\to0^-}\left[x\cdot\frac{1-\cos x^2}{x^2}\right]
 &=\lim_{u\to0^+}\left[-\sqrt{u}\cdot\frac{1-\cos u}u\right]
  &&\overset{-0^+\cdot0}{\llongeq}0.
\end{alignat*}
This is all correct, but instead we will simply rewrite the 
function so that we get the same rate of approach to zero
inside the cosine and in the denominator:
$$\lim_{x\to0}\frac{1-\cos x^2}{x}
  =\lim_{x\to0}\left[x\cdot\frac{1-\cos x^2}{x^2}\right]
  \overset{0\cdot0}{\longeq}0.$$
Rather than making the substitution, we rewrote the function
and noticed we have matching rates of approach to zero
in the $(1-\cos x^2)/x^2$ term.  We see that $x^2\to0^+$
as in our limit substitution theorem so we can just site the result
$(1-\cos\theta)/\theta\to0$ as $\theta\to0$ (which includes
left and right limits).
\eex

As we saw in the above example, sometimes substitution requires
us to consider cases, where instead we could
do some hand-waving (based upon anticipating what would happen
if we did perform the substitution).  The next example perhaps makes
the case for selective, ``informed handwaving'' more strongly:

\bex Consider $\ds{\lim_{x\to0}\frac{\sin2x}{\sin5x}}$.

\underline{Solution}: We need a $2x$ to oppose the $\sin2x$,
and $5x$ to oppose the $\sin5x$, all the while not actually 
changing the value of the function:
$$
\lim_{x\to0}\frac{\sin2x}{\sin5x}
  =\lim_{x\to0}\frac{2x\cdot\frac{\sin2x}{2x}}{5x\cdot\frac{\sin5x}{5x}}
  =\lim_{x\to0}\frac{2\cdot\frac{\sin2x}{2x}}{5\cdot\frac{\sin5x}{5x}}
\overset{\frac{2\cdot1}{5\cdot1}}{\longeq}2/5.$$
\eex
To actually use a verbose substitution method, we would have to 
factor the function first into three factors,
$\frac{2}5\cdot\frac{\sin2x}{2x}\cdot\frac{5x}{\sin5x}$ and
invoke two separate substitutions, one each for the second and
third factors, and use our omnibus limit
theorem, namely Theorem~\ref{UsualLimitTheorems}.  Such an approach 
would be correct, but quite cumbersome. 



When we have $x\to a\implies u\to\beta$, it is the exceptional
cases when the $u$-variable approach to $\beta$ is
problematic.  We always need to be aware that we require $u\ne\beta$
as $x\to a$, but again it is rare that there is a problem
when the substitutions are routine.\footnote{%
%%% FOOTNOTE
In fact it is not
necessary for $u\ne\beta$ if $f$ is continuous at $x=a$,
but then the value of the limit is just $f(a)$.  These more
advanced limit techniques such as substitution are for 
dealing with the cases that continuity is ``broken,'' or the
quantities are not all finite.}
%%% END FOOTNOTE
  The next two examples
give an idea of what kind of substitutions to avoid.

\bex Consider the limit $\ds{\lim_{x\to0}\frac{\sin\left[x\sin\frac1x\right]}
{\left[x\sin\frac1x\right]}}$.

Now the function $x\sin\frac1x$ is plotted in Figure~\ref{XSin1/X},
page~\pageref{XSin1/X}
and has two relevant features for our discussion here:
\begin{enumerate}
\item $\ds{x\sin\frac1x\longto0}$ as $x\to 0$, which was proved by
      the Sandwich Theorem.
\item $\ds{x\sin\frac1x}$ has infinitely-many zeroes (that is, 
      points $x$ where the function is zero) as $x\to 0$.
\end{enumerate}
From the first point, we see that if we let $\theta=x\sin\frac1x$,
then $x\to0\implies\theta\to0$.  Unfortunately, $\theta=0$
infinitely-many times as $x\to0$.  Thus, even though
$$\lim_{\theta\to0}\frac{\sin\theta}{\theta}=1,$$
we cannot say that the original limit is the same value.
Indeed, the original limit does not exist, because as we have $x\to0$
there are infinitely many points where the original function
is not even defined, forcing us to conclude
$$\lim_{x\to0}\frac{\sin\left[x\sin\frac1x\right]}
{\left[x\sin\frac1x\right]}\qquad\text{does not exist}.$$
\eex

The reason the above limit does not exist compares to 
the reason $\lim_{x\to5}\sqrt{x^2-25}$ does not exist,
though the latter is more obvious: that $\sqrt{x^2-25}$ is
{\it undefined} for part of the path of approach, in particular
for $x\in(-5,5)$ so that $\sqrt{x^2-25}$ is undefined
as $x\to5^-$.  With our example's limit function above, the function
does not exist everywhere that the denominator, $x\sin\frac1x=0$
i.e., wherever
$1/x=n\pi$, or $x=\pi/n$ where $n\in\mathbb{Z}-\{0\}$, and 
this happens infinitely many times inside of any interval
$(-\delta,0)$ or $(0,\delta)$ if $\delta>0$.  As with
$\lim_{x\to5}\sqrt{x^2-25}$, we cannot 
{\it approach} zero and stay in the domain of the function,
and thus we are forced to conclude the limit does not exist.
For a less subtle example, consider the following.

\begin{figure}
\begin{center}
\begin{pspicture}(-3,-4)(3,4)
\psaxes{<->}(0,0)(-3,-4)(3,4)
\psline[linewidth=1.2pt](-3,-4)(-1,0)(1,0)(3,4)
\end{pspicture}
\end{center}
\caption{Graph of $y=g(x)$ from Example~\ref{FunkyLimitWhereSubNoGood}.}
\label{FigureForFunkyLimitWhereSubNoGood}
\end{figure}




\bex Suppose $\ds{g(x)=\left\{\begin{array}{ccl}
     x-1&\quad\text{if}\quad&x\in(1,\infty)\\
     0&\text{if} &x\in[-1,1]\\
     x+1&\text{if}& x\in(-\infty,-1)\end{array}\right..}$
\noindent Next consider 
$$\lim_{x\to0}\frac{\sin(g(x))}{g(x)}.$$
If we let $u=g(x)$, then one could say $x\to0\implies u\to0$,
but not properly, because $u=0$ for all $x\in[-1,1]$ (not just
at the limit point $x=0$).  In other words,
$u$ is not {\it approaching} zero for $x$ near zero, but rather
$u$ is {\it constant} and zero for such $x$.  Here
$(\sin g(x))/g(x)$ is undefined for  $x\in[-1,1]$, which
contains the final path of $x$ as $x\to0$.
Thus we {\bf cannot} say $\lim_{x\to0}(\sin g(x))/g(x)=
\lim_{u\to0}(\sin u)/u$, as the former limit DNE while the latter is just 1. 

\label{FunkyLimitWhereSubNoGood}
\eex
\newpage
\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\begin{multicols}{2}
\begin{enumerate}
\item Compute $\ds{\lim_{x\to0}\frac{\sin9x}{x}}$.
\item Compute $\ds{\lim_{x\to0}\frac{\sin9x}{\sin7x}}$.
\item Compute $\ds{\lim_{x\to0}\frac{\sin x^2}{x}}$.
\item Compute $\ds{\lim_{x\to0}\frac{\sin x}{x^2}}$.
\item Compute $\ds{\lim_{x\to0}\frac{\sin^35x}{x^3}}$.
\item Compute $\ds{\lim_{x\to0}\sqrt[3]{\frac{\sin x}{x}}}$.
\item Compute $\ds{\lim_{x\to0}\sqrt{\frac{\sin x}{x}}}$.
\item Compute $\ds{\lim_{x\to0}\frac{\tan 2x}{x}}$.
\item Compute $\ds{\lim_{x\to0}\frac{1-\cos2x}{x}}$.
\item Compute $\ds{\lim_{x\to0}\frac{1-\cos2x}{x^2}}$.
\item Compute $\ds{\lim_{x\to\frac{\pi}2}\frac{1-\cos2x}{x^2}}$.
\item Compute $\ds{\lim_{x\to0}\frac{1-\cos x}{x^4}}$.
\item Compute $\ds{\lim_{x\to0}\frac{\sin(\tan x)}{\tan x}}$.
\item Compute $\ds{\lim_{x\to{\frac{\pi}2}^+}\frac{\sin(\tan x)}{\tan x}}$.
\item Compute $\ds{\lim_{x\to0}\frac{\sin|x|}{|x|}}$.
\item Compute $\ds{\lim_{x\to0}\frac{x}{\sin x}}$.
\item Compute $\ds{\lim_{x\to0}\frac{x^2}{\sin x}}$.
\item Recompute the limit of 
Example~\ref{ExampleWhereTanX->-InftyW/Substitution},
page~\pageref{ExampleWhereTanX->-InftyW/Substitution},
this time by multiplying the numerator and denominator of the 
function by $\cos^2x$.
\item Compute 
$\ds{\lim_{x\to0^+}\frac{2\csc^2x+3\csc x+11}{5\csc^2x+4\csc x+7}}$
using a substitution argument.
\item Compute 
$\ds{\lim_{x\to0}\frac{2\csc^2x+3\csc x+11}{5\csc^2x+4\csc x+7}}$
without a substitution argument.
\item Compute $\ds{\lim_{x\to\infty}
  \left[\frac{2x-9}{3x+5}\cdot\frac{6x^2-9x+10}{x^2-7x+8}
          \right.}$
$\ds{\left.+\frac{7x^2+6}{3x^3+4x-3}\cdot\cos\left(\frac1x\right)\right]}$.

\end{enumerate}
\end{multicols}







\newpage
\section{Limits of Sequences: A First Look}


Sequences offer a different set of challenges than
functions on intervals, and so this section and the next are
devoted to the nuances particular to sequences.  In fact, 
a whole course could be devoted to sequences, but the
amount required for this text is more modest.
What we need for Riemann Sums in Chapter~\ref{FirstIntegrationChapter}
is very similar to some earlier concepts
(in particular, limits as $x\to\infty$) and can be
quickly dispatched here. Some of our study of
sequences here will be required 
to prepare for the development
of series, introduced in Chapter~\ref{FirstSeriesChapter}
and continued in Chapter~\ref{TaylorSeriesChapter}.
\subsection{Definitions and First Examples}
Here we give a formal definition of an infinite sequence.
\begin{definition}
An {\bf infinite sequence} is a function whose domain is
$\mathbb{N}$, or a similar (bounded from below)
infinite subset of $\mathbb{Z}$, and whose 
range is a subset of $\Re$.  For instance, any function
$$f:\mathbb{N}\longrightarrow \Re$$
will define a sequence.
\end{definition}
In such a case, for $n\in\mathbb{N}$ we usually write,
for instance, $f(n)=a_n$;
the {\it subscript} $n$ is used in place of the argument
of the function, and the letter $a$ is used to 
``name'' the sequence.  Another notation used to denote
such a sequence is as follows:
\begin{equation}\left\{a_n\right\}_{n=1}^\infty
=a_1,a_2,a_3,\cdots.\label{SequenceNotation}\end{equation}
The notation on the left is read, ``the sequence (of numbers)
$a_n$ as $n$ ranges from $1$ to $\infty$.''  The 
notation on the right is useful only to show whatever pattern
may be contained in the sequence, and though common,
is not ideal (since it is open to misinterpretation).  A simple example 
where a sequence is ``named,'' a formula is given for 
each term, and the pattern is established as in 
the right hand side of (\ref{SequenceNotation}) is
\begin{equation}\left\{a_n\right\}_{n=1}^\infty=
  \left\{\frac1n\right\}_{n=1}^\infty
  =1,\frac12,\frac13,\frac14,\cdots.\label{FirstSequenceExample}\end{equation}
So here $a_n=1/n$ defines each term of the sequence.

For a sequence as in (\ref{FirstSequenceExample}), we can
see immediately that the terms are shrinking in size, 
and we would naturally enough want to describe this by 
stating something to the effect that
$$\lim_{n\to\infty}a_n=\lim_{n\to\infty}\frac1n
\overset{1/\infty}{\llongeq}0.$$
First we need definitions for such a statement to make sense.
Consider the following definition for a finite limit of a 
sequence:
\begin{definition}
For a sequence $\{a_n\}_{n=1}^\infty$ and a finite number $L\in\Re$,
we define $\ds{\lim_{n\to\infty}a_n=L}$ by the following:
\begin{equation}
\lim_{n\to\infty}a_n=L\iff
(\forall \epsilon>0)(\exists N\in{\mathbb{N}})
(\forall n)\left[\vphantom{\frac11}n>N\longrightarrow
\left|a_n-L\right|<\epsilon\right].
\label{FiniteLimitOfASequence}\end{equation}
Furthermore, in such a case we say the sequence 
$\left\{a_n\right\}_{n=1}^\infty$ {\bf converges} to $L$.
\end{definition}

Compare this definition to (\ref{Lim_xToInfty=L}).  In fact, this
is nearly identical to the definition for
$\lim_{x\to\infty}f(x)=L$, except that the part of the
{\it continuous} variable $x$ is now played by the {\it discrete}
variable $n$.  An illustration of what (\ref{FiniteLimitOfASequence})
prescribes is given below:
$$a_1,a_2,a_3,\cdots,a_N,\underbrace{a_{N+1},a_{N+2},a_{N+3},\cdots}_{%
\in(L-\epsilon,L+\epsilon)}.$$
Thus we can find a ``tail end'' of the sequence to be within $\epsilon$
of $L$ if we travel far enough down the sequence.
Another common illustration of this is given in 
Figure~\ref{SequenceDefOnCartesianPlane}.
\begin{figure}
\begin{center}
\begin{pspicture}(-1,-2)(10,4.4)
\psaxes[labels=none]{<->}(0,0)(-1,-2)(10,4)
\pspolygon[linecolor=white,fillstyle=solid,fillcolor=white]%
(3.3,-.3)(3.3,.3)(4.7,.3)(4.7,-.3)(3.3,-.3)
\psline[linestyle=dotted,linewidth=2pt](3.4,0)(4.6,0)
\psline(-.3,2.3)(.3,2.3)
 \rput(-.6,2.3){$L$}
  \psline[linestyle=dotted](.3,2.3)(10,2.3)
\psline(-.2,2.5)(.2,2.5)
  \psline{->}(-.7,3.2)(0,2.5)
  \rput(-1,3.4){$L+\epsilon$}
\psline[linestyle=dashed](.2,2.5)(10,2.5)
\psline(-.2,2.1)(.2,2.1)
  \psline{->}(-.7,1.6)(0,2.1)
  \rput(-1,1.45){$L-\epsilon$}
\psline[linestyle=dashed](.2,2.1)(10,2.1)

\rput(1,-.5){$1$}
\rput(2,-.5){$2$}
\rput(3,-.5){$3$}
\psline[linestyle=dotted,linewidth=2pt](3.4,-.5)(4.6,-.5)
\rput(5,-.5){\small$N$}
\rput(6,-.5){\small$N+1$}
\rput(7,-.5){\small$N+2$}
\rput(8,-.5){\small$N+3$}
\rput(9,-.5){\small$N+4$}
\psline[linestyle=dotted,linewidth=2pt](9.6,-.5)(10,-.5)

\pscircle[fillstyle=solid,fillcolor=black](1,.6){.07}
  \rput(1,.9){$a_1$}
\pscircle[fillstyle=solid,fillcolor=black](2,1.6){.07}
  \rput(2,1.2){$a_2$}
\pscircle[fillstyle=solid,fillcolor=black](3,3.0){.07}
  \rput(3,3.3){$a_3$}
%\pscircle[fillstyle=solid,fillcolor=black](4,2){.07}
\pscircle[fillstyle=solid,fillcolor=black](5,2.8){.07}
  \rput(5,3.1){$a_N$}
\pscircle[fillstyle=solid,fillcolor=black](6,2.4){.07}
  \rput(6,2.75){$a_{N+1}$}
\pscircle[fillstyle=solid,fillcolor=black](7,2.2){.07}
  \rput(7,1.8){$a_{N+2}$}
\pscircle[fillstyle=solid,fillcolor=black](8,2.33){.07}
  \rput(8,2.68){$a_{N+3}$}
\pscircle[fillstyle=solid,fillcolor=black](9,2.27){.07}
  \rput(9,1.85){$a_{N+4}$}

\psline[linestyle=dashed](5,-2)(5,4)
  \rput(5.7,4){$n>N$}
\rput(10,.2){$n$}
\rput(0,4.2){$a_n$}


\end{pspicture}
\end{center}
\caption{Illustration of the definition of a finite limit
of a sequence, (\ref{FiniteLimitOfASequence}).  In this
type of graph, $a_n$ versus $n$ is plotted. If the
sequence converges to $L$, then 
once a tolerance $\epsilon>0$ is chosen, we can find
$N$ (depending upon $\epsilon$) so that $n>N\longrightarrow
\left|a_n-L\right|<\epsilon$, i.e., $a_n\in(L-\epsilon,L+\epsilon)$.
Here the points are labeled by their heights, i.e., the values
of the respective sequence elements $a_n$.}
\label{SequenceDefOnCartesianPlane}
\end{figure}



Other definitions from Section~\ref{LimitsAtInfinitySection}
have analogs for infinite sequences.  
For instance the case where $f(x)\longto\infty$ as $x\to\infty$,
 (\ref{EqForDefOfLimX->Infty=Infty}), becomes the following definition:
\begin{definition}
For an infinite sequence $\left\{a_n\right\}_{n=1}^\infty$,
we say the sequence {\bf diverges to infinity}, and
write $\ds{\lim_{n\to\infty}a_n=\infty}$, according to
the following:
\begin{equation}
\lim_{n\to\infty}a_n=\infty
\iff
(\forall M)(\exists N)(\forall n)(n>N\longrightarrow a_n>M).
\label{DefineLimSequenceToBeInfinity}\end{equation}
\end{definition}
The vocabulary of limits of sequences is slightly different
from that of limits of functions on intervals.  
If $a_n\longto L\in\Re$, we say the
sequence {\it converges to }$L$, as we mentioned before.
If no such real (and therefore {\it finite}) $L$ exists,
we say the sequence {\it diverges}.  If, however, 
we can say $a_n\longto\infty$, we say the series 
{\it diverges to  $\infty$}.\footnote{%
%%%%%%%% FOOTNOTE
It would seem strange to say a sequence {\it converges} to 
$\infty$, since the verb {\it to converge}
indicates getting close (or {\it approaching}).  
Of course we can not really ``get close'' to infinity.}  
%%%%%%%%% END FOOTNOTE
(Of course we similarly say $a_n$ diverges to $-\infty$
when $a_n\longto -\infty$.)


We can employ all the relevant theorems 
for limits in $x$ with analogs in $n$.  The theorem which 
shows earlier theorems imply their sequence counterparts is
the following:
\begin{theorem}Suppose that $\ds{\lim_{x\to\infty}f(x)=L}$,
where $L$ is either a real number, $\infty$ or $-\infty$, 
and $a_n=f(n)$ for $n\in\mathbb{N}$.  Then
$\ds{\lim_{n\to\infty}a_n=L}$ as well.  In symbolic logic,
we can write
\begin{equation}
\left(\lim_{x\to\infty}f(x)=L\right)
\wedge
\left(\vphantom{\lim_{x\to\infty}}(\forall n\in\mathbb{N})\ a_n=f(n)\right)
\implies \left(\lim_{n\to\infty}a_n=L\right).
\label{FunctionCarriesSequence}\end{equation}
\label{FunctionCarriesSequenceTheorem}\end{theorem}
We will not prove this since first of all, it is intuitive on its face
upon reflection, and second, because it is not difficult to
see that it should be the case based upon the similarities 
of the limit definitions with functions $f:[1,\infty)\longrightarrow\Re$
and sequences $\left\{a_n\right\}_{n=1}^\infty$.
Figure~\ref{FigureShowingFunctionCarryingSequence}
shows the mechanism in action for a particular example
(Example~\ref{FirstExampleFunctionCarriesSequence}  below).
A nice way to summarize Theorem~\ref{FunctionCarriesSequence}
is the phrase ``the function carries the sequence.'' 
In fact there is much more information in the statement
$f(x)\longto L$ than in $a_n\longto L$, since the
function includes the values between the positive
integer values and so, as we will eventually see,
the sequence can not ``carry'' the function.  But for now
let us look at a simple example of the theorem.
\bex Suppose $\ds{a_n=1+\frac{\cos n\pi}{n}}$.  Then,
just as 
$$\lim_{x\to\infty}\left[1+\frac{\cos \pi x}{x}\right]
\overset{1+\frac{B}\infty}{\llongeq}1+0=1,$$
we have the sequence $\left\{a_n\right\}_{n=1}^\infty$
converges to $1$ also, i.e.,
$$\lim_{n\to\infty}a_n=\lim_{n\to\infty}
 \left[1+\frac{\cos\pi n}{n}\right]
\overset{1+\frac{B}\infty}{\llongeq}1+0=1.$$
This is illustrated in Figure~\ref{FigureShowingFunctionCarryingSequence}.
(Recall that the ``$B$'' refers to a term which is ``bounded,''
in this case referring to the fact that $|\cos\pi x|\le 1$,
and so $B/\infty$ is a determinate form which yields zero in the
limit.)
\label{FirstExampleFunctionCarriesSequence}
\eex
\begin{figure}
\begin{center}
\begin{pspicture}(-.5,-2)(11,2)
\psaxes{<->}(0,0)(0,-2)(11,2)
\psplot[plotpoints=550]{1}{11}{x 180 mul cos x div 1 add}
\psline[linestyle=dashed](0,1)(11,1)
\pscircle[fillstyle=solid,fillcolor=black](1,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](2,1.5){.07}
\pscircle[fillstyle=solid,fillcolor=black](3,.666666){.07}
\pscircle[fillstyle=solid,fillcolor=black](4,1.25){.07}
\pscircle[fillstyle=solid,fillcolor=black](5,.8){.07}
\pscircle[fillstyle=solid,fillcolor=black](6,1.1666666){.07}
\pscircle[fillstyle=solid,fillcolor=black](7,.857143){.07}
\pscircle[fillstyle=solid,fillcolor=black](8,1.125){.07}
\pscircle[fillstyle=solid,fillcolor=black](9,.888888){.07}
\pscircle[fillstyle=solid,fillcolor=black](10,1.1){.07}
\rput(3,-1.2){$\ds{a_n=1+\frac{\cos n\pi}{n}}$}
\rput(3,-2){(dots)}
\rput(8,-1.2){$\ds{f(x)=1+\frac{\cos \pi x}{x}}$}
\rput(8,-2){(curve)}
\end{pspicture}\end{center}
\caption{Illustration of a sequence $\left\{a_n\right\}_{n=1}^\infty$
(the dots)
where $\ds{a_n=1+\frac{\cos n\pi}n}$, along with the function (the curve)
$\ds{f(x)=1+\frac{\cos \pi x}x}$.  Since $f(x)\longrightarrow 1$
as $x\to\infty$, that behavior carries the sequence,
i.e., implying $a_n\longrightarrow 1$ as $n\to\infty$.}
\label{FigureShowingFunctionCarryingSequence}\end{figure}
In the above example, we assumed that $B/\infty$ is
a determinate form for sequences, which is the case with functions of
a continuous variable (such as our usual $x$).
Theorem~\ref{FunctionCarriesSequenceTheorem} guarantees
that this does, indeed, work with sequences as with 
functions defined on $[1,\infty)$.  We will not bother to
chase through the details here, but with what we have developed
earlier in the chapter, it should ring true.\footnote{%
%%%%%% FOOTNOTE
It is interesting to modify earlier proofs for functions of $x$
to the language of sequences and thus actually {\it prove}
the same theorems for sequences, but we will not 
do so here.  In fact, earlier in the chapter we skipped many of the 
proofs for the cases $x\to\infty$ because they produced forms
we analyzed for limits with $x\to a$ where $a$ was a finite 
number.}
%%%%%% END FOOTNOTE
The limits of other sequences can also be found
using earlier methods (though later we will see
the limitations of Theorem~\ref{FunctionCarriesSequenceTheorem}).
\bex Consider the sequence $\ds{\left\{a_n\right\}_{n=1}^\infty
=\left\{\frac{n^3-n}{n^2+1}\right\}_{n=1}^\infty}$.  Now
$$
\lim_{n\to\infty}a_n=
\lim_{n\to\infty}\frac{n^3-n}{n^2+1}
=\lim_{n\to\infty}\frac{n^2\left(n-\frac1n\right)}{n^2\left(1+\frac1{n^2}
\right)}
=\lim_{n\to\infty}\frac{n-\frac1n}{1+\frac1{n^2}}
\overset{\frac{\infty-0}{1+0}}{\llongeq}\infty.$$
Thus the sequence $\left\{a_n\right\}$ diverges to $\infty$.
\eex




Anytime we can meaningfully replace $n\in\mathbb{N}$ with
$x\in[1,\infty)$ (or a similar interval, unbounded from above), 
and the limits as $x\to\infty$ exists, we
can use the methods of earlier sections.  However, there
are examples where the sequence is better behaved than the
function.
\bex Define $\left\{a_n\right\}_{n=1}^\infty$
so that $a_n=n\sin n\pi$.  Now
$$\lim_{x\to\infty}x\sin(x\pi) \text{ does not exist,}$$
since the function $f(x)=x\sin(x\pi)$
oscillates in an unbounded way as $x\to\infty$.
This behavior is illustrated in
Figure~\ref{SequenceCan'tCarryFunctionFigure}.
However, a closer look at $\left\{a_n\right\}_{n=1}^\infty$
shows that
$$\left\{a_n\right\}_{n=1}^\infty=0,0,0,0,0,\cdots,$$
so clearly $$a_n\longto 0$$
as $n\to\infty$.

\begin{figure}
\begin{center}
\begin{pspicture}(-1,-3)(12.5,3)
\psset{yunit=.25cm}
\psaxes[Dy=2]{<->}(0,0)(-1,-12)(12.5,12)
\psplot[plotpoints=1000]{1}{12.5}{x x 180 mul sin mul}
\pscircle[fillstyle=solid,fillcolor=black](1,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](2,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](3,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](4,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](5,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](6,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](7,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](8,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](9,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](10,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](11,0){.07}
\pscircle[fillstyle=solid,fillcolor=black](12,0){.07}

\rput(1,1){$a_1$}
\rput(2,1){$a_2$}
\rput(3,1){$a_3$}
\rput(4,1){$a_4$}
\rput(5,1){$a_5$}
\rput(6,1){$a_6$}
\rput(7,1){$a_7$}
\rput(8,1){$a_8$}
\rput(9,1){$a_9$}
\rput(10,1){$a_{10}$}
\rput(11,1){$a_{11}$}
\rput(12,1){$a_{12}$}



\end{pspicture}
\end{center}
\caption{The sequence $\ds{\left\{a_n\right\}_{n=1}^\infty
=\left\{n\sin n\pi\right\}_{n=1}^\infty}$ is
just a sequence of zeros (given by the dots above),
while the function $f(x)=\sin(x\pi)$ oscillates
with growing distance between peaks and adjacent troughs.
As $x\to\infty$, there is no limit for $f(x)$, though
$a_n\longrightarrow 0$ as $n\to\infty$.  This does not
contradict Theorem~\ref{FunctionCarriesSequenceTheorem},
since that states that the function can carry the sequence,
not that the sequence can carry the function.}
\label{SequenceCan'tCarryFunctionFigure}
\end{figure}
\label{SequenceCan'tCarryFunctionExample}
\eex


The example above
 does not contradict Theorem~\ref{FunctionCarriesSequenceTheorem};
the theorem is of the form $P\longrightarrow Q$, while here we have
$(\sim P)$, a case the theorem does not address. 





Because we can often replace $a_n=f(n)$ with a function
$f:[1,\infty)\longrightarrow\Re$ which has an existing limit
as $x\to\infty$, many of the theorems 
which were available to us for functions on the continuum
have relevance here as well.  For example, the Sandwich Theorem
(page~\pageref{SandwichTheoremStatement}) and its variants
apply to sequences as well (just replacing $x$ with $n$).  
Consider for example the following:
\bex Consider $\ds{\left\{\frac{n^2\sin (n^2+1)}{n^3+1}\right\}}$.
     Using algebraic methods we can write
     $$\lim_{n\to\infty}\frac{n^2\sin (n^2+1)}{n^3+1}
             =\lim_{n\to\infty}\frac{n^2\sin (n^2+1)}
                   {n^3\left(1+\frac1{n^3}\right)}
             =\lim_{n\to\infty}
                 \left[\sin(n^2+1)\cdot\frac1{n\left(1+\frac1{n^3}\right)}
                            \right]
             \overset{B\cdot0}\llongeq0.$$
\eex
The form $B\cdot0=0$, recall, representing a bounded function
times one which approached zero implied the product approached zero,
but the argument was essentially a sandwich theorem argument.
Here one could write $-\frac{n^2}{n^3+1}\le a_n\le \frac{n^2}{n^3+1}$,
and both functions $\pm\frac{n^2}{n^3+1}\longrightarrow0$ as $n\to\infty$.
Other more explicitly sandwich theorem applications will occur
as we proceed.

\bex Consider the sequence $\ds{\left\{a_n\right\}_{n=1}^\infty=
            \left\{\sqrt{\frac{6n-1}{n}}\right\}_{n=1}^\infty}$.
\label{SequenceW/Sqrt(6n-1)/(n)}
$$\lim_{n\to\infty}a_n=
\lim_{n\to\infty}\sqrt{\frac{n\left(6-\frac1n\right)}{n}}
=\lim_{n\to\infty}\sqrt{6-\frac1n}=\sqrt{6-0}=\sqrt6.$$
\eex

\bex  Consider the sequence $\ds{\left\{a_n\right\}_{n=1}^\infty
=\left\{n^2\cos\frac1n\right\}_{n=1}^\infty}$.
$$\lim_{n\to\infty}a_n=\lim_{n\to\infty}n^2\cos\frac1n
\overset{\infty\cdot1}{\llongeq}\infty.$$
In such a case we would say that $a_n$ diverges to $\infty$ (or
just diverges, to be less descriptive).\eex
\begin{theorem}
If $a_n\longrightarrow L$ and 
$f(x)$ is continuous at $L$, then $f(a_n)\longrightarrow f(L)$.
\label{ContFunctCarriesSequenceToF(Limit)}
\end{theorem}

This theorem can often be avoided because of other methods.
For instance, it was not necessary in
Example~\ref{SequenceW/Sqrt(6n-1)/(n)}, but it could have been
used with $f(x)=\sqrt{x}$, and the sequence 
$a_n=\frac{6n-1}n\longrightarrow6$ implying the sequence
$\sqrt{a_n}=f(a_n)\longrightarrow\sqrt6$, since $f(x)=\sqrt{x}$
is continuous at $x=6$.  In the next example the theorem is
more useful.
\bex Consider $a_n=\cos\left(n\sin\frac1n\right)$.

Since $\cos x$ is continuous for all $x\in\Re$, we can first work 
``inside'' that function to compute (as we have done before):
$$\lim_{n\to\infty}n\sin\frac1n\overset{\infty\cdot0}{\llongeq}
\lim_{n\to\infty}\frac{\sin\frac1n}{\frac1n}
=\lim_{\theta\to0^+}\frac{\sin\theta}{\theta}
=1,$$
where we made the substitution $\theta=\frac1n\to0^+$ as $n\to\infty$.
Thus $\cos\left(n\sin\frac1n\right)\to\cos1\approx0.540302306$
as $n\to\infty$.
\eex

We usually do not mention such a theorem as we make these computations,
but its statement provides a useful fact to call upon in abstract
arguments.\footnote{%%%
%%% FOOTNOTE
In fact its continuum analog had much to do with
our ``limits by substitution'' methods.
%%% END FOOTNOTE
}
A professional mathematician might phrase the
theorem something like, ``continuous functions preserve
convergence of a sequence,'' or ``continuous functions take (or map)
convergent sequences to convergent sequences.''  Still, an example like
the above may be summarized without direct reference to
the theorem:
$$\lim_{n\to\infty}\cos\left(n\sin\frac1n\right)
\overset{\cos(\infty\cdot0)}{\lllongeq}
\lim_{n\to\infty}\cos\left(\frac{\sin\frac1n}{\frac1n}\right)
\overset{\cos1}{\llongeq}\cos1.$$
In doing so recall that we have to be sure that the argument
of the sine function approached zero at the same rate as the
denominator, as occurs here.




\subsection{Subsequences}
As Example~\ref{SequenceCan'tCarryFunctionExample}
(page~\pageref{SequenceCan'tCarryFunctionExample})
showed, there is more to studying sequences
than just a rephrasing of our earlier study of limits ``at infinity''
that we began in Section~\ref{LimitsAtInfinitySection}.
In fact the ability to easily assign a function on $[1,\infty)$
with the same limiting behavior as $\left\{a_n\right\}_{n=1}^\infty$
is a rather special (though very common) case.  
Consider the following example.
\bex Define $\ds{a_n=(-1)^n+1}$, for $n=1,2,3,\cdots.$  

First note that it is impossible to have $n$ replaced
by $x\in[1,\infty)$ in the formula, since $(-1)^x$ is undefined for
$x$ of the form $p/q$, where $p,q\in\mathbb{N}$,
$p/q$ is simplified and $q$ is even.  It ($(-1)^x$) is 
also undefined for $x\in\Re-\mathbb{Q}$, i.e., irrational
values of $x$.  For this sequence we really do have to analyze
it on its face.  One method is to list the terms and 
see the pattern:
\begin{alignat*}{8}
\left\{a_n\right\}_{n=1}^\infty
&=&\quad-1+1,&&\quad1+1,&&\quad -1+1,&&\quad 1+1,&&\quad-1+1,&&\ 
     \quad1+1,&&\ \cdots\\
&=&0,&&2,&&0,&&2,&&0,&&2,&&\ \cdots.\end{alignat*}
We see that the sequence never converges to a unique number, and
therefore the limit does not exist, and so the sequence is divergent.
\label{SeqDivByOscill--NotTalkAboutOscillSeqYet--Example}\eex

The example above shows more than just the fact that 
there are sequences which are best analyzed on their faces.
It also shows that sequences diverge in ways other than
towards $\infty$ or $-\infty$.  Finally we see that
the sequence is really a union of two sequences, one
which is all zeros and the other is all twos.
These can be listed as $\left\{a_{2n}\right\}_{n=1}^\infty$
and $\left\{a_{2n-1}\right\}_{n=1}^\infty$:
\begin{alignat*}{2}
\left\{a_{2n}\right\}_{n=1}^\infty&=a_2,a_4,a_6,a_8,\cdots&&=2,2,2,2,\cdots,\\
\left\{a_{2n-1}\right\}_{n=1}^\infty&=
    a_1,a_3,a_5,a_7,\cdots&&=0,0,0,0,\cdots.
\end{alignat*}
What we have above are two examples of {\it subsequences}
of a given sequence $\left\{a_n\right\}_{n=1}^\infty$.
Now we give the formal definition.
\begin{definition}
Given an infinite sequence $\left\{a_n\right\}_{n=1}^\infty$ and
a set of natural numbers $n_1<n_2<n_3<n_4<\cdots$, another
sequence $\left\{b_k\right\}_{k=1}^\infty=\left\{a_{n_k}\right\}_{k=1}^\infty$
is called a {\bf subsequence} of the original
sequence $\left\{a_n\right\}_{n=1}^\infty$.
\end{definition}
Thus the sequence $\ds{b_k=a_{n_k}}$ is gotten by 
moving along the sequence $a_n$ and picking out the terms
$\ds{a_{n_1}}$, $\ds{a_{n_2}}$, $\ds{a_{n_3}}$, etc.

The following theorem contains three results which
partially explain the convergence relationships among a sequence
and its subsequences.  Though all three results
are very closely related, their emphases are somewhat
different and so we list them separately.
The final result, Theorem~\ref{Sequences<=>Subsequences}c,
will be the most useful.




\begin{theorem} Given a sequence $\ds{\left\{a_n\right\}_{n=1}^\infty}$.
\begin{enumerate}[\bf (a)]
\item If $a_n\longrightarrow L$, then for any subsequence 
$\ds{\left\{a_{n_k}\right\}_{k=1}^\infty}$, we also have
$\ds{a_{n_k}\longrightarrow L}$ as well (as $k\to\infty$).
\item  Moreover, $a_n\longto L$ if and only if for every
       subsequence $\left\{a_{n_k}\right\}_{k=1}^\infty$,
       we have $a_{n_k}\longto L$.
\item  Finally, suppose that $n_{k_1}<n_{k_2}<n_{k_3}<\cdots$ and
       $m_{j_1}<m_{j_2}<m_{j_3}<\cdots$, where
       $\{n_k\}\cup\{m_j\}=\{1,2,3,4,\cdots\}$,
       and that $b_k=a_{n_k}$, $c_j=a_{m_j}$.  In other 
       words, $\left\{b_k\right\}$ and $\left\{c_j\right\}$
       are subsequences of $\{a_n\}$ which exhaust that
       whole sequence.  Then (as $k,j,n\to\infty$)  
       $$\left(b_k\longto L\right)\wedge\left(c_j\longto L\right)
         \iff\left(a_n\longto L\right).$$
       Rephrased, if we have two subsequences who
       collectively contain the whole original sequence,
       then the convergence of the original sequence to $L$ is 
       equivalent to the convergence of the subsequences also to $L$.

\end{enumerate}\label{Sequences<=>Subsequences}
\end{theorem}
The first (a) can be rephrased to state that ``the sequence carries
all subsequences.''  The second statement (b) needs no rephrasing,
and is mostly useful for junior or senior real analysis courses.
The last one (c) is the most useful here, stating
that if we want to check for a limit
of the full sequence, it is enough to check two subsequences whose
members exhaust the full sequence.  For completeness
we include a proof below, but the truths of these should 
be apparent on their faces upon reflection.\footnote{
%%% FOOTNOTE
Indeed the reader
should not let the proof distract, but can in good conscience bypass
the proof for the moment, and return later when more familiar with
sequences in general.
%%% END FOOTNOTE
}

\begin{proof}
We will prove all of these for the case that the limit in question is some
finite $L\in\Re$.  Simple modifications of the proof given
here will cover the cases $L=\pm\infty$.

\begin{enumerate}[\bf(a)]
\item
First assume $a_n\longto L$ and $b_k=a_{n_k}$ is any subsequence.
Now we make the observation that $n_k\ge k$, since the
$k$th choice as we move down the original sequence cannot happen 
before we come to the $k$th term of that sequence.  Put another
way, if $n_1,n_2,n_3,\cdots\in\mathbb{N}$, and $n_1<n_2<n_3<\cdots$,
then  $n_k\ge k$.  By the convergence of the original
sequence to $L$ we have
\begin{equation}(\forall\epsilon>0)(\exists N)(\forall n)\left[n>N
\longrightarrow\left|a_n-L\right|<\epsilon\right].\label{a_nConvergesEx}
\end{equation}
But then once $\epsilon$ and $N$ are chosen
so that (\ref{a_nConvergesEx}) holds true, we have
$$k>N\implies n_k\ge k>N\implies \left|a_{n_k}-L\right|<\epsilon
\iff\left|b_k-L\right|<\epsilon.$$
In other words, for any $\epsilon>0$, the $N$ from (\ref{a_nConvergesEx})
gives us $k>N\longrightarrow\left|b_k-L\right|<\epsilon$.  Thus
the definition for $\ds{a_{n_k}=b_k\longto L}$ holds.
This shows that every subsequence of $\{a_n\}_{n=1}^\infty$
also converges to $L$, q.e.d.
\item By (a), we know that $a_n\longto L\implies a_{n_k}\longto L$.
We need to show the converse ($\Longleftarrow$), i.e., that if every
every subsequence converges  to $L$, this forces the sequence
to also converge to $L$.  But this
is trivial, since, if {\it every} subsequence
of $\left\{a_n\right\}_{n=1}^\infty$ converges to $L$, then
the subsequence $a_{n_k}$ defined by $n_1=1,n_2=2,n_3=3,\cdots$ 
must converge to $L$.  But that is just the statement 
$\left\{a_n\right\}_{n=1}^\infty$ converges to $L$, q.e.d.
(In other words, the sequence is itself a subsequence, so 
if every subsequence converges to $L$, then so must the sequence
itself, q.e.d.) 
\item By (a) (and, for that matter, (b)), we have ($\Longleftarrow$).
To show ($\implies$), suppose $b_k,c_j\longto L$ and that
the union of these subsequences is the full sequence 
$\left\{a_n\right\}_{n=1}^\infty$.
For $\epsilon>0$, choose $n_b$ and $n_c$ so that
\begin{align*}
n>n_b&\longrightarrow\left|b_n-L\right|<\epsilon,\\
n>n_c&\longrightarrow\left|c_n-L\right|<\epsilon.\end{align*}
Now choose $N_b,N_c$ so that $a_{N_b}$ is the term chosen from
the original sequence to represent $b_{n_b}$ in the first subsequence,
and $a_{N_c}$ from the original is the term $c_{n_c}$ in the
second subsequence.  In other words, the $n_b$th term in 
$\left\{b_k\right\}_{k=1}^\infty$ is the $N_b$th term in 
$\left\{a_n\right\}_{n=1}^\infty$, and the $n_c$th term in
$\left\{c_j\right\}_{j=1}^\infty$ is the chosen to be 
the $N_c$th term in $\left\{a_n\right\}_{n=1}^\infty$.
Now let $N=\max\left\{N_b,N_c\right\}$.  Then
\begin{align*}
n>N&\implies\left(a_n=b_k, \text{ some }k>n_b\right)
       \vee\left(a_n=c_k, \text{ some }k>n_c\right)\\
   &\implies\left(\left|a_n-L\right|=\left|b_k-L\right|<\epsilon\right)
       \vee\left(\left|a_n-L\right|=\left|c_k-L\right|<\epsilon\right)\\
   &\implies\left|a_n-L\right|<\epsilon,\text{ q.e.d.}\end{align*}
\end{enumerate}
\end{proof}
Note where the proof of (c) required that the subsequences
$\left\{b_k\right\}_{k=1}^\infty,\left\{c_j\right\}_{j=1}^\infty$
exhaust the original sequence $\left\{a_n\right\}_{n=1}^\infty$
(two lines up from ``q.e.d.'').
A quick look at the proof indicates the following corollary
can be proved the same way:
\begin{corollary} Given a sequence and any finite set of 
subsequences whose entries exhaust the original sequence
(in the sense of Theorem~\ref{Sequences<=>Subsequences}c),
we then have the limit of the original sequence is $L$ if and only if 
each subsequence also has limit $L$.
\end{corollary}
It sometimes occurs that we analyze a sequence 
$\left\{a_n\right\}_{n=1}^\infty$ by looking at 
the odd- and even-indexed
subsequences separately, 
since together they exhaust the original sequence.  This
is especially useful when the original sequence can
be simplified differently for odd and even terms.
Note how
$$\left\{a_n\right\}_{n=1}^\infty
=\left\{a_{2n-1}\right\}_{n=1}^\infty\cup
\left\{a_{2n}\right\}_{n=1}^\infty.$$
If instead we wish to look at three subsequences, each of every third term,
we could write
$$\left\{a_{n}\right\}_{n=1}^\infty
=\left\{a_{3n-2}\right\}_{n=1}^\infty\cup
\left\{a_{3n-1}\right\}_{n=1}^\infty\cup
\left\{a_{3n}\right\}_{n=1}^\infty,$$
and so on.
\bex Discuss the limiting behavior of the sequence
$\ds{\left\{\frac{(-1)^nn}{n+1}\right\}}$.

\underline{Solution}: Because this sequence alternates signs,
we will look at the even and odd terms 
separately.
\begin{align*}
a_{2n-1}&=\frac{(-1)^{2n-1}(2n-1)}{(2n-1)+1}
         =\frac{(-1)(2n-1)}{2n}=\frac{(-1)n\left(2-\frac1n\right)}
           {n(2)}\\&=\frac{(-1)\left(2-\frac1n\right)}{2}
        \longrightarrow -1\cdot\frac22=-1;\\
a_{2n}&=\frac{(-1)^{2n}(2n)}{(2n)+1}=\frac{2n}{2n+1}
       =\frac{n(2)}{n\left(2+\frac1n\right)}\\
       &=\frac{2}{2+\frac1n}\longrightarrow \frac22=1.
\end{align*}
Thus the subsequence $\left\{a_{2n-1}\right\}_{n=1}^\infty$
of odd terms approaches $-1$ while
the subsequence $\left\{a_{2n}\right\}_{n=1}^\infty$
of even terms approaches $1$.
Since two subsequences have different limits, we
conclude the original sequence diverges.\footnote{%
%%%%%%%%%%%  FOOTNOTE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
This is a case one can say the sequence diverges ``by oscillation,''
meaning one subsequence goes to $L$, another to $M\ne L$,
and these subsequences exhaust the original sequence.
See also 
Example~\ref{SeqDivByOscill--NotTalkAboutOscillSeqYet--Example},
page~\pageref{SeqDivByOscill--NotTalkAboutOscillSeqYet--Example}.}
%%%%%%%%%%   END FOOTNOTE %%%%%%%%%%%%%%%%%%%%%%%%%
\eex
In the example above we used the fact that odd powers of $(-1)$
(e.g., $(-1)^{2n-1}$)  yield $(-1)$, and even 
powers (e.g., $(-1)^{2n}$) yield $1$.  Some other ways to achieve
alternation of signs use trigonometric functions, which have
the conceptual advantage that they are continuous on all of $\Re$:
\begin{align*}
\cos n\pi&=\left\{\begin{array}
   {rl}-1,\qquad&n\ \text{odd}\\
    1,\qquad&n\ \text{even},\end{array}\right.\\ \\
\sin\frac{(2n-1)\pi}{2}&=
     \left\{\begin{array}{rl}
    1,\qquad &n\ \text{odd}\\
   -1,\qquad &n\ \text{even}.\end{array}
            \right.
\end{align*}



\begin{center}
\underline{\Large{\bf Exercises}}\end{center}
\begin{multicols}{2}
\begin{enumerate}
\item Show that an alternating sequence $\{a_n\}$ converges
if and only if $\left|a_n\right|\longrightarrow0$, and
thus $\{a_n\}$ converges if and only if $a_n\longrightarrow0$.
\end{enumerate}
\end{multicols}




\newpage
\section{Sequences II}
Here we examine some of the more sophisticated arguments 
regarding sequences.  In particular we will revisit
the least upper bound property of $\Re$
(page~\pageref{LUBPropDefinition}), and its 
implications for bounded and so-called {\bf monotonic}
sequences.  These will be of crucial importance theoretically
for many of the convergence theorems for series in
Chapter~\ref{FirstSeriesChapter} (and thus
Chapter~\ref{TaylorSeriesChapter}).  First we need some
definitions.

\begin{definition}
We call a sequence $\ds{\left\{a_n\right\}_{n=1}^\infty}$
  \begin{description}
  \item[\qquad nondecreasing] 
      if and only if $a_1\le a_2\le a_3\le\cdots$, i.e,
   $$(\forall n\in\mathbb{N})\left[ a_{n}\le a_{n+1}\right];$$
  \item[\qquad nonincreasing]
      if and only if $a_1\ge a_2\ge a_3\ge\cdots$, i.e.,
   $$(\forall n\in\mathbb{N})\left[ a_{n}\ge a_{n+1}\right];$$
  \item[\qquad increasing] if and only if $a_1<a_2<a_3<\cdots$, i.e.,
   $$(\forall n\in\mathbb{N})\left[a_n<a_{n+1}\right];$$
  \item[\qquad decreasing] if and only if $a_1>a_2>a_3>\cdots$, i.e.,
   $$(\forall n\in\mathbb{N})\left[a_n>a_{n+1}\right].$$
  \end{description}
\end{definition}
Note that 
\begin{align*}
   \{a_n\}\text{ increasing }&\implies \{a_n\}\text{ nondecreasing,}\\
   \{a_n\}\text{ decreasing }&\implies \{a_n\}\text{ nonincreasing.}\\
\end{align*}
We will often have increasing or decreasing sequences, but it turns
out that our important theorems only require that the sequences
are either nondecreasing or nonincreasing, and so these two 
weaker categories (and thus all four categories) above are
collected into one concept:
\begin{definition}
Any sequence $\ds{\left\{a_n\right\}_{n=1}^\infty}$ which
is either nondecreasing or nonincreasing is called
{\it monotonic}.\end{definition}
Again we point out that any of the four categories of sequences
from the first definition are therefore monotonic.\footnote{%%%
%%% FOOTNOTE
It should be pointed out that there are two camps of writers
when it comes to classifying monotonic sequences.
Some writers---from the other camp---use ``increasing'' more loosely to mean
what we call ``nondecreasing'' (meaning
``never decreasing'') here, and similarly use
``decreasing'' for our ``nonincreasing.''  On its face this
seems inaccurate, but one can argue from negations that
these uses make perfect sense.  For example, if one
thinks of an increasing sequence as one which 
``never decreases,'' we need the definition
$$\sim\left[(\exists n\in\mathbb{N})\left(a_n>a_{n+1}\right)\right]
\equiv\left[(\forall n\in\mathbb{N})\left(a_n\le a_{n+1}\right)\right],$$
the right-hand side of which is exactly this other camp's definition
of ``increasing.''

Using these different definitions of ``increasing'' and ``decreasing,''
this other camp (which will not coincide with this text's
terminology) can say a monotonic sequence is thus one which
is increasing (throughout the entire sequence), or decreasing
(throughout the entire sequence).

In order to distinguish the cases where $a_n<a_{n+1}$ and
$a_n\le a_{n+1}$, this other camp calls the former case
``strictly increasing,'' and the latter (again) simply ``increasing.''
%%% END FOOTNOTE
}

We also need to recall some definitions regarding boundedness of
a set of numbers, except this time the set will be a sequence.

\begin{definition}
A sequence $\ds{\left\{a_n\right\}_{n=1}^\infty}$ is called
\begin{itemize}
\item {\bf bounded from above} if and only if 
      $(\exists M\in\Re)(\forall n\in\mathbb{N})
        \left[a_n\le M\right]$;
\item {\bf bounded from below} if and only if
      $(\exists m\in\Re)(\forall n\in\mathbb{N})
         \left[m\le a_n\right]$.
\item {\bf bounded} if and only if it is bounded from above and
       below, i.e., if and only if\\
       $(\exists m,M\in\Re)(\forall n\in\mathbb{N})
        \left[m\le a_n\le M\right]$.
\end{itemize}
\end{definition}

Our crucial theorem---and main result of this section---is the
following:
\begin{theorem}
A bounded, monotonic sequence converges.
\end{theorem}

The proof we give here contains many smaller results which 
are interesting in their own rights.  For instance,
we have
\begin{enumerate}
\item A nondecreasing function which is bounded from above
      necessarily converges.
\item A nonincreasing function which is bounded from below
      necessarily converges.
\end{enumerate}

For this particular theorem we will defer the proof until the end of
the section, to avoid distraction from the
usual  intuition, which is quite visual.




